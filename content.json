{"pages":[{"title":"","text":"html {overflow-x: initial !important;}:root { --bg-color: #ffffff; --text-color: #333333; --select-text-bg-color: #B5D6FC; --select-text-font-color: auto; --monospace: \"Lucida Console\",Consolas,\"Courier\",monospace; --title-bar-height: 20px; } .mac-os-11 { --title-bar-height: 28px; } html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; } body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857143; overflow-x: hidden; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; tab-size: 4; background-position: inherit; background-repeat: inherit; } iframe { margin: auto; } a.url { word-break: break-all; } a:active, a:hover { outline: 0px; } .in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); } #write { margin: 0px auto; height: auto; width: inherit; word-break: normal; word-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; } #write.first-line-indent p { text-indent: 2em; } #write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; } #write.first-line-indent li { margin-left: 2em; } .for-image #write { padding-left: 8px; padding-right: 8px; } body.typora-export { padding-left: 30px; padding-right: 30px; } .typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; } .typora-export .task-list-item input { pointer-events: none; } @media screen and (max-width: 500px) { body.typora-export { padding-left: 0px; padding-right: 0px; } #write { padding-left: 20px; padding-right: 20px; } .CodeMirror-sizer { margin-left: 0px !important; } .CodeMirror-gutters { display: none !important; } } #write li > figure:last-child { margin-bottom: 0.5rem; } #write ol, #write ul { position: relative; } img { max-width: 100%; vertical-align: middle; image-orientation: from-image; } button, input, select, textarea { color: inherit; font-family: inherit; font-size: inherit; font-style: inherit; font-variant-caps: inherit; font-weight: inherit; font-stretch: inherit; line-height: inherit; } input[type=\"checkbox\"], input[type=\"radio\"] { line-height: normal; padding: 0px; } *, ::after, ::before { box-sizing: border-box; } #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; } #write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; } p { line-height: inherit; } h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; } p { orphans: 4; } h1 { font-size: 2rem; } h2 { font-size: 1.8rem; } h3 { font-size: 1.6rem; } h4 { font-size: 1.4rem; } h5 { font-size: 1.2rem; } h6 { font-size: 1rem; } .md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; } .hidden { display: none; } .md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; } a { cursor: pointer; } sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-top-left-radius: 4px; border-top-right-radius: 4px; border-bottom-right-radius: 4px; border-bottom-left-radius: 4px; cursor: pointer; } sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; } #write input[type=\"checkbox\"] { cursor: pointer; width: inherit; height: inherit; } figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; } figure > table { margin: 0px; } tr { break-inside: avoid; break-after: auto; } thead { display: table-header-group; } table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; } table.md-table td { min-width: 32px; } .CodeMirror-gutters { border-right-width: 0px; background-color: inherit; } .CodeMirror-linenumber { } .CodeMirror { text-align: left; } .CodeMirror-placeholder { opacity: 0.3; } .CodeMirror pre { padding: 0px 4px; } .CodeMirror-lines { padding: 0px; } div.hr:focus { cursor: none; } #write pre { white-space: pre-wrap; } #write.fences-no-line-wrapping pre { white-space: pre; } #write pre.ty-contain-cm { white-space: normal; } .CodeMirror-gutters { margin-right: 4px; } .md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; position: relative !important; background-position: inherit; background-repeat: inherit; } .md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; } #write .md-fences.mock-cm { white-space: pre-wrap; } .md-fences.md-fences-with-lineno { padding-left: 0px; } #write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; } .md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; } .CodeMirror-line, twitterwidget { break-inside: avoid; } .footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; } .footnotes + .footnotes { margin-top: 0px; } .md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; background-position: 0px 0px; } li div { padding-top: 0px; } blockquote { margin: 1rem 0px; } li .mathjax-block, li p { margin: 0.5rem 0px; } li blockquote { margin: 1rem 0px; } li { margin: 0px; position: relative; } blockquote > :last-child { margin-bottom: 0px; } blockquote > :first-child, li > :first-child { margin-top: 0px; } .footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; } #write .footnote-line { white-space: pre-wrap; } @media print { body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; } #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; } .typora-export * { -webkit-print-color-adjust: exact; } .typora-export #write { break-after: avoid; } .typora-export #write::after { height: 0px; } .is-mac table { break-inside: avoid; } .typora-export-show-outline .typora-export-sidebar { display: none; } } .footnote-line { margin-top: 0.714em; font-size: 0.7em; } a img, img a { cursor: pointer; } pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background-color: rgb(204, 204, 204); display: block; overflow-x: hidden; } p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; } #write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; } p > .md-image:only-child { display: inline-block; width: 100%; } #write .MathJax_Display { margin: 0.8em 0px 0px; } .md-math-block { width: 100%; } .md-math-block:not(:empty)::after { display: none; } .MathJax_ref { fill: currentcolor; } [contenteditable=\"true\"]:active, [contenteditable=\"true\"]:focus, [contenteditable=\"false\"]:active, [contenteditable=\"false\"]:focus { outline: 0px; box-shadow: none; } .md-task-list-item { position: relative; list-style-type: none; } .task-list-item.md-task-list-item { padding-left: 0px; } .md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; } .math { font-size: 1rem; } .md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-top-left-radius: 10px; border-top-right-radius: 10px; border-bottom-right-radius: 10px; border-bottom-left-radius: 10px; } .md-toc-content { position: relative; margin-left: 0px; } .md-toc-content::after, .md-toc::after { display: none; } .md-toc-item { display: block; color: rgb(65, 131, 196); } .md-toc-item a { text-decoration: none; } .md-toc-inner:hover { text-decoration: underline; } .md-toc-inner { display: inline-block; cursor: pointer; } .md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; } .md-toc-h2 .md-toc-inner { margin-left: 2em; } .md-toc-h3 .md-toc-inner { margin-left: 4em; } .md-toc-h4 .md-toc-inner { margin-left: 6em; } .md-toc-h5 .md-toc-inner { margin-left: 8em; } .md-toc-h6 .md-toc-inner { margin-left: 10em; } @media screen and (max-width: 48em) { .md-toc-h3 .md-toc-inner { margin-left: 3.5em; } .md-toc-h4 .md-toc-inner { margin-left: 5em; } .md-toc-h5 .md-toc-inner { margin-left: 6.5em; } .md-toc-h6 .md-toc-inner { margin-left: 8em; } } a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; } .footnote-line a:not(.reversefootnote) { color: inherit; } .md-attr { display: none; } .md-fn-count::after { content: \".\"; } code, pre, samp, tt { font-family: var(--monospace); } kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background-color: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-top-left-radius: 3px; border-top-right-radius: 3px; border-bottom-right-radius: 3px; border-bottom-left-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; } .md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); } code { text-align: left; } a.md-print-anchor { white-space: pre !important; border: none !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; text-shadow: initial !important; background-position: 0px 0px !important; } .os-windows.monocolor-emoji .md-emoji { font-family: \"Segoe UI Symbol\", sans-serif; } .md-diagram-panel > svg { max-width: 100%; } [lang=\"flow\"] svg, [lang=\"mermaid\"] svg { max-width: 100%; height: auto; } [lang=\"mermaid\"] .node text { font-size: 1rem; } table tr th { border-bottom-width: 0px; } video { max-width: 100%; display: block; margin: 0px auto; } iframe { max-width: 100%; width: 100%; border: none; } .highlight td, .highlight tr { border: 0px; } mark { background-color: rgb(255, 255, 0); color: rgb(0, 0, 0); } .md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; } .md-expand mark .md-meta { opacity: 0.3 !important; } mark .md-meta { color: rgb(0, 0, 0); } @media print { .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; } } .md-diagram-panel .messageText { stroke: none !important; } .md-diagram-panel .start-state { fill: var(--node-fill); } .md-diagram-panel .edgeLabel rect { opacity: 1 !important; } .md-fences.md-fences-math { font-size: 1em; } .md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; } .md-fences-advanced:not(.md-focus) { background-image: inherit; background-size: inherit; background-attachment: inherit; background-origin: inherit; background-clip: inherit; background-color: inherit; background-position: inherit; background-repeat: inherit; } .typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; } .typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; } .typora-export-show-outline #write { --webkit-flex: 2; flex: 2 1 0%; } .typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; } @media screen and (max-width: 1024px) { .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; } } @media screen and (max-width: 800px) { .typora-export-sidebar { display: none; } } .outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; } .outline-content ul { margin-top: 0px; margin-bottom: 0px; } .outline-content strong { font-weight: 400; } .outline-expander { width: 1rem; height: 1.428571429rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; } .outline-expander::before { content: ''; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; } .outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; } .outline-expander:hover::before { content: ''; } .outline-h1 > .outline-item { padding-left: 0px; } .outline-h2 > .outline-item { padding-left: 1em; } .outline-h3 > .outline-item { padding-left: 2em; } .outline-h4 > .outline-item { padding-left: 3em; } .outline-h5 > .outline-item { padding-left: 4em; } .outline-h6 > .outline-item { padding-left: 5em; } .outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; } .outline-label:hover { text-decoration: underline; } .outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); } .outline-item:hover { margin-left: -28px; margin-right: -28px; border-left-width: 28px; border-left-style: solid; border-left-color: transparent; border-right-width: 28px; border-right-style: solid; border-right-color: transparent; } .outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; } .outline-item-open > .outline-item > .outline-expander::before { content: ''; } .outline-children { display: none; } .info-panel-tab-wrapper { display: none; } .outline-item-open > .outline-children { display: block; } .typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; } .typora-export .outline-item:hover { margin-right: -8px; border-right-width: 8px; border-right-style: solid; border-right-color: transparent; } .typora-export .outline-expander::before { content: \"+\"; font-family: inherit; top: -1px; } .typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: '−'; } .typora-export-collapse-outline .outline-children { display: none; } .typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; } .typora-export-no-collapse-outline .outline-expander::before { content: \"\" !important; } .typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; } .md-inline-math-container mjx-container { zoom: 0.95; } :root { --side-bar-bg-color: #fafafa; --control-text-color: #777; } @include-when-export url(https://fonts.loli.net/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext); /* open-sans-regular - latin-ext_latin */ /* open-sans-italic - latin-ext_latin */ /* open-sans-700 - latin-ext_latin */ /* open-sans-700italic - latin-ext_latin */ html { font-size: 16px; -webkit-font-smoothing: antialiased; } body { font-family: \"Open Sans\",\"Clear Sans\", \"Helvetica Neue\", Helvetica, Arial, 'Segoe UI Emoji', sans-serif; color: rgb(51, 51, 51); line-height: 1.6; } #write { max-width: 860px; margin: 0 auto; padding: 30px; padding-bottom: 100px; } @media only screen and (min-width: 1400px) { #write { max-width: 1024px; } } @media only screen and (min-width: 1800px) { #write { max-width: 1200px; } } #write > ul:first-child, #write > ol:first-child{ margin-top: 30px; } a { color: #4183C4; } h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; } h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; } h1 tt, h1 code { font-size: inherit; } h2 tt, h2 code { font-size: inherit; } h3 tt, h3 code { font-size: inherit; } h4 tt, h4 code { font-size: inherit; } h5 tt, h5 code { font-size: inherit; } h6 tt, h6 code { font-size: inherit; } h1 { font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid #eee; } h2 { font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid #eee; } /*@media print { .typora-export h1, .typora-export h2 { border-bottom: none; padding-bottom: initial; } .typora-export h1::after, .typora-export h2::after { content: \"\"; display: block; height: 100px; margin-top: -96px; border-top: 1px solid #eee; } }*/ h3 { font-size: 1.5em; line-height: 1.43; } h4 { font-size: 1.25em; } h5 { font-size: 1em; } h6 { font-size: 1em; color: #777; } p, blockquote, ul, ol, dl, table{ margin: 0.8em 0; } li>ol, li>ul { margin: 0 0; } hr { height: 2px; padding: 0; margin: 16px 0; background-color: #e7e7e7; border: 0 none; overflow: hidden; box-sizing: content-box; } li p.first { display: inline-block; } ul, ol { padding-left: 30px; } ul:first-child, ol:first-child { margin-top: 0; } ul:last-child, ol:last-child { margin-bottom: 0; } blockquote { border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777; } blockquote blockquote { padding-right: 0; } table { padding: 0; word-break: initial; } table tr { border: 1px solid #dfe2e5; margin: 0; padding: 0; } table tr:nth-child(2n), thead { background-color: #f8f8f8; } table th { font-weight: bold; border: 1px solid #dfe2e5; border-bottom: 0; margin: 0; padding: 6px 13px; } table td { border: 1px solid #dfe2e5; margin: 0; padding: 6px 13px; } table th:first-child, table td:first-child { margin-top: 0; } table th:last-child, table td:last-child { margin-bottom: 0; } .CodeMirror-lines { padding-left: 4px; } .code-tooltip { box-shadow: 0 1px 1px 0 rgba(0,28,36,.3); border-top: 1px solid #eef2f2; } .md-fences, code, tt { border: 1px solid #e7eaed; background-color: #f8f8f8; border-radius: 3px; padding: 0; padding: 2px 4px 0px 4px; font-size: 0.9em; } code { background-color: #f3f4f4; padding: 0 2px 0 2px; } .md-fences { margin-bottom: 15px; margin-top: 15px; padding-top: 8px; padding-bottom: 6px; } .md-task-list-item > input { margin-left: -1.3em; } @media print { html { font-size: 13px; } table, pre { page-break-inside: avoid; } pre { word-wrap: break-word; } } .md-fences { background-color: #f8f8f8; } #write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: #f7f7f7; border: 0; border-radius: 3px; color: #777777; margin-top: 0 !important; } .mathjax-block>.code-tooltip { bottom: .375rem; } .md-mathjax-midline { background: #fafafa; } #write>h3.md-focus:before{ left: -1.5625rem; top: .375rem; } #write>h4.md-focus:before{ left: -1.5625rem; top: .285714286rem; } #write>h5.md-focus:before{ left: -1.5625rem; top: .285714286rem; } #write>h6.md-focus:before{ left: -1.5625rem; top: .285714286rem; } .md-image>.md-meta { /*border: 1px solid #ddd;*/ border-radius: 3px; padding: 2px 0px 0px 4px; font-size: 0.9em; color: inherit; } .md-tag { color: #a7a7a7; opacity: 1; } .md-toc { margin-top:20px; padding-bottom:20px; } .sidebar-tabs { border-bottom: none; } #typora-quick-open { border: 1px solid #ddd; background-color: #f8f8f8; } #typora-quick-open-item { background-color: #FAFAFA; border-color: #FEFEFE #e5e5e5 #e5e5e5 #eee; border-style: solid; border-width: 1px; } /** focus mode */ .on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.12); } header, .context-menu, .megamenu-content, footer{ font-family: \"Segoe UI\", \"Arial\", sans-serif; } .file-node-content:hover .file-node-icon, .file-node-content:hover .file-node-open-state{ visibility: visible; } .mac-seamless-mode #typora-sidebar { background-color: #fafafa; background-color: var(--side-bar-bg-color); } .md-lang { color: #b4654d; } /*.html-for-mac { --item-hover-bg-color: #E6F0FE; }*/ #md-notification .btn { border: 0; } .dropdown-menu .divider { border-color: #e5e5e5; opacity: 0.4; } .ty-preferences .window-content { background-color: #fafafa; } .ty-preferences .nav-group-item.active { color: white; background: #999; } .menu-item-container a.menu-style-btn { background-color: #f5f8fa; background-image: linear-gradient( 180deg , hsla(0, 0%, 100%, 0.8), hsla(0, 0%, 100%, 0)); } mjx-container[jax=\"SVG\"] { direction: ltr; } mjx-container[jax=\"SVG\"] > svg { overflow: visible; min-height: 1px; min-width: 1px; } mjx-container[jax=\"SVG\"] > svg a { fill: blue; stroke: blue; } mjx-assistive-mml { position: absolute !important; top: 0px; left: 0px; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0px 0px 0px !important; border: 0px !important; display: block !important; width: auto !important; overflow: hidden !important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; } mjx-assistive-mml[display=\"block\"] { width: 100% !important; } mjx-container[jax=\"SVG\"][display=\"true\"] { display: block; text-align: center; margin: 1em 0; } mjx-container[jax=\"SVG\"][display=\"true\"][width=\"full\"] { display: flex; } mjx-container[jax=\"SVG\"][justify=\"left\"] { text-align: left; } mjx-container[jax=\"SVG\"][justify=\"right\"] { text-align: right; } g[data-mml-node=\"merror\"] > g { fill: red; stroke: red; } g[data-mml-node=\"merror\"] > rect[data-background] { fill: yellow; stroke: none; } g[data-mml-node=\"mtable\"] > line[data-line], svg[data-table] > g > line[data-line] { stroke-width: 70px; fill: none; } g[data-mml-node=\"mtable\"] > rect[data-frame], svg[data-table] > g > rect[data-frame] { stroke-width: 70px; fill: none; } g[data-mml-node=\"mtable\"] > .mjx-dashed, svg[data-table] > g > .mjx-dashed { stroke-dasharray: 140; } g[data-mml-node=\"mtable\"] > .mjx-dotted, svg[data-table] > g > .mjx-dotted { stroke-linecap: round; stroke-dasharray: 0,140; } g[data-mml-node=\"mtable\"] > g > svg { overflow: visible; } [jax=\"SVG\"] mjx-tool { display: inline-block; position: relative; width: 0; height: 0; } [jax=\"SVG\"] mjx-tool > mjx-tip { position: absolute; top: 0; left: 0; } mjx-tool > mjx-tip { display: inline-block; padding: .2em; border: 1px solid #888; font-size: 70%; background-color: #F8F8F8; color: black; box-shadow: 2px 2px 5px #AAAAAA; } g[data-mml-node=\"maction\"][data-toggle] { cursor: pointer; } mjx-status { display: block; position: fixed; left: 1em; bottom: 1em; min-width: 25%; padding: .2em .4em; border: 1px solid #888; font-size: 90%; background-color: #F8F8F8; color: black; } foreignObject[data-mjx-xml] { font-family: initial; line-height: normal; overflow: visible; } mjx-container[jax=\"SVG\"] path[data-c], mjx-container[jax=\"SVG\"] use[data-c] { stroke-width: 3; } g[data-mml-node=\"xypic\"] path { stroke-width: inherit; } .MathJax g[data-mml-node=\"xypic\"] path { stroke-width: inherit; } mjx-container[jax=\"SVG\"] path[data-c], mjx-container[jax=\"SVG\"] use[data-c] { stroke-width: 0; } @media print { @page {margin: 0 0 0 0;} body.typora-export {padding-left: 0; padding-right: 0;} #write {padding:0;}} Time-Frequency Uncertainty TheoremGiven a window function w(t)w(t), define the time and frequency bandwidth as:Time&nbsp;BW:σt(w)=∫t2|w(t)|2dtFreq&nbsp;BW:σu(w)=∫u2|W(u)|2duThen, σt(w)⋅σu(w)≥116π2Proofσt(w)⋅σu(w)=[∫t2|w(t)|2dt][∫u2|W(u)|2du]=[∫t2|w(t)|2dt][∫|1j2πddtw(t)|2dt]=14π2∥tw(t)∥2⋅∥dw(t)dt∥2Explanation:(1)1j2πddtx(t)⟷uX(u)(2)Norm is defined as:∥x∥=⟨x,x⟩⇒∥x∥2=⟨x,x⟩Where ⟨x,x⟩\\langle x, x\\rangle is the inner product, and:a(t)⟷A(u)b(t)⟷B(u)⟨a,b⟩=∫a(t)b∗(t)dt⟨a,b⟩=⟨A,B⟩Where b∗b^* is the conjugation vector of bb.Now back to the proof...σt(w)⋅σu(w)=14π2∥tw(t)∥2⋅∥dw(t)dt∥2≥14π2[∫tw(t)dw(t)dtdt]2=14π2[∫−∞+∞t⋅d(w2(t)2)]2=14π2[tw2(t)2|−∞+∞−∫w2(t)2dt]=116π2Explanation:(3)Cauchy–Schwarz Inequality:⟨a,b⟩=∥a∥∥b∥cosθ≤∥a∥∥b∥(4)Chain Rule:∫d(ab)=∫adb+∫bda⇒∫adb=∫d(ab)−∫bda=ab−∫bda(5)We have some assumptions of w(t). First, w(t) is unit normalized. Second, w(t) is centered at zero. Third, w(t) decays fast enough.tw2(t)2|−∞+∞=0As w(t) decays fast enough (faster than t\\sqrt{t}), this term is zero.(6)∫w2(t)2dt=12As w(t) is unit normalized:∫|w(t)|2dt=∥w(t)∥=1&nbsp;&nbsp;","link":"/img/time-freq-uncer/tfu.html"},{"title":"Contact Me","text":"联系我欢迎通过电子邮箱与我取得联系。 我的个人邮箱： e@wangluyuan.cc","link":"/contact/index.html"},{"title":"About Me","text":"关于欢迎访问我的个人网站。 Welcome to my personal website for more information. www.wangluyuan.cc","link":"/about/index.html"}],"posts":[{"title":"2020年12月OKR","text":"2020 年 12 月 OKR2020 年是很不平凡的一年。于我个人而言，我决定离开字节跳动，跳出舒适圈，开始新的征程。虽然离开了公司，但设定目标的好习惯还是要坚持下去～ O1 - 入门深度学习，能够上手做实验 KR 1 - 看完 CS231N，并完成 assignment 2 &amp; assignment 3 KR 2 - 了解 ResNet50 等常用网络结构 KR 3 - 阅读论文，补齐数字信号处理等基础知识，并做一次串讲 KR 4 - 成功复现论文，并探索改进方式 打分：0.6 未加快进度没有完成 CS231N 作业，但是成功入门了 DL，也能够上手做实验了。 O2 - 加深对计算机基础知识的理解 KR 1 - 阅读《自我修养》前两章 打分：0.1 完成得不好，几乎没有进度。主要是还没有找到最合适的学习节奏。 O3 - 保持总结 / 分享习惯，完善博客建设 KR 1 - 撰写 CV 相关博客 1+ KR 2 - 计算机系统博客 1+ 打分：0.5 KR 2 未完成，但是本月仍写了两篇博客。 O4 - 劳逸结合，调整状态 KR 1 - 旅行 1 次 打分：1.0 不仅旅行了，而且还开始规律健身。果然娱乐方向的目标总是最好达成的……","link":"/2020/11/29/2020-12-okr/"},{"title":"2021-2023 Objectives","text":"2021 - 2023 年 OKRNote为避免 OKR 相关的文章太多污染博客，因此将全年目标汇总。 20211-2 双月O1 - DL 进阶 0.6 KR 1：接手现有代码，理解并复现实验结论 0.8 KR 2：实现新想法，产生对比数据 0.5 KR 3：认真完成 CMU 课程作业，巩固基础知识 0.6 KR 4：完成一个除分类外的其他 project，如分割等 0.0 Progress: 对 THU 项目整体比较熟悉，可以独立开展研究，且有了一些进展。撰写了一篇 MobileNet 的博客。 CMU 课程目前完成得不错，符合预期。除分类任务外的其他 project 未能开展。 O2 - 加深对计算机系统的理解 0.2 KR 1：阅读完《自我修养》前两章 0.2 KR 2：产生博客 1+ 0.4 Progress: 完成度不高。书籍仅阅读了一章，产生了一篇下载 m3u8 格式视频的博客，但是和系统并不是很相关。 O3 - 提高听力水平 0.4 KR 1：每周听 &gt; 4 次美剧，每次 &gt; 1h Progress： 有在看美剧，但是仅循环听了一集，不符合预期，需要改进。 O4 - 劳逸结合 0.8 KR 1：旅行 2+ 0.8 KR 2：单板熟练换刃🏂 0.6 KR 3：规律健身 0.8 Progress： 健身比较规律，单板单侧换刃较为熟练了。 3-4 双月由于 5 月本学期结课、6 月 THU 已满半年需要有所产出，project、作业、research 压力较大，因此本双月非常重要。预计需要大幅提高 DL 相关能力，因此重点放置在 DL 相关上，计算机系统等暂时搁置。 O1 - THU 项目有产出 0.6 KR 1：在 100 类上复现出 30 类上的实验效果 0.6 KR 2：在 ImageNet 上拿到最终结论 0.5 KR 3：持续投入，每周有进度报告 0.6 Progress： 完整 ImageNet 因算力不足较难调参，但是在更小的数据集上拿到了结论。 O2 - DL 进阶 0.6 KR 1：保持跟住 CMU 课程进度，作业、quiz 均在 A 的水平 0.8 KR 2：积极学习新技术，为 project 奠定基础。包括 RNN、LSTM、Transformer、GAN 等 0.6 KR 3：project 雏形基本完成，冲击 publish 0.2 Progress： 课程节奏基本跟住了，作业、quiz 分数尚可。对新技术都有所了解。因时间关系，project 参与度不及预期。 O3 - 提升听力水平 0.2 KR 1：保持看美剧 0.4 KR 2：Success Center 预约 1 次以上 0.0 Progress： 时间管理不善。 O4 - 劳逸结合 0.8 KR 1：规律健身 0.8 Progress： 5 月前突击减脂 2 周，效果不错。 5-6 双月O1 - THU 项目完成 0.4 KR 1：跑完所有实验，拿到满意的结果 0.5 KR 2：五月底 / 六月初写完论文初稿 0.4 Progress： 结果基本满意，文章有进展，但未完成初稿。 O2 - 完成赴美准备工作 0.5 KR 1：拿到 i20，预约签证面谈，拿到签证 0.4 KR 2：完成其他琐碎事务，如成绩单寄送等 0.6 Progress： 签证被 check；其他事情完成。 O3 - 技术能力提升 0.0 KR 1：找到实习 / 科研项目 0.0 Progress： THU 项目未完成 O4 - 劳逸结合 0.8 KR 1：规律健身 0.6 KR 2：幸福生活 0.8 Progress： 生活幸福指数较高 7-8 双月O1 - 顺利赴美 0.8 KR 1：拿到签证、准备好所有手续 0.8 KR 2：布置新家 0.6 Progress： 人在美国，刚下飞机～ O2 - 论文投出 0.6 反复修改至满意 0.6 厘清投稿流程 0.6 Progress： 论文已投出 9-10 双月O1 - 适应环境 0.8 KR 1：跟上课程节奏，所有作业达到 A 的水平 0.8 KR 2：熟悉学校和周边地点，找到生活节奏 0.8 KR 3：规律健身 0.5 Progress: 环境基本适应 O2 - 提升科研能力 0.6 KR 1：找到合适的实验室 0.6 KR 2：博客产出 &gt; 2 0.4 Progress: 找到了实验室；平时作业太多，博客几乎没有时间写，仅完成了 1 篇 O3 - 提升英语能力 0.5 KR 1：Success Center 预约 &gt; 1 0.5 Progress: SC 已预约，但是能力提升不大，需要加强 O4 - 完成实习面试准备工作 0.6 KR 1：完成简历撰写，并在 Success Center 修改 0.6 KR 2：LeetCode 超过 60 题 0.4 KR 3：收到面试邀约 / 开始面试流程 0.6 Progress: LeetCode 未达预期，仅 53 题，但比较接近目标；已收到两个面试邀约，希望能通过 11-12 双月O1 - 夯实基础，完成学业 0.8 KR 1: Computer System 和 Image Processing 课程拿到 A 0.8 KR 2: 了解 Research Project 评分规则，拿到 A 0.8 KR 3: 选到 2022 Spring 学期目标课程（CV、SLAM）0.5 Progress: 所有课程均拿到 A，且成绩比较满意。22 Spring 已选到和 research 更相关的 CV 课程，SLAM 在 waitlist 中。 O2 - 找到实习 1.0 KR 1: 拿到额外面试邀请 &gt;= 2 0.5 KR 2: 通过 RH、APPL 两家面试，进入二面 0.8 KR 3: LeetCode 超过 100 题 0.4 KR 4: 拿到一个实习 offer 1.0 Progress: 虽然 LeetCode 只刷了 70 题，但已经拿到了 Apple 的实习 offer，因此给出满分。 O3 - Research 步入正轨 0.6 KR 1: 熟悉实验室，确认下学期是否继续 0.6 KR 2: 开启一个感兴趣的课题，有成果产出 0.5 KR 3: SLAM 书进度 &gt;= 50% 0.5 Progress: 确认下学期继续，且找到了一些可以做的点。正在持续学习 SLAM。 O4 - 提升英语 0.4 KR 1: 提高日常说英语频率 0.5 KR 2: 规律看美剧 0.4 Progress: 还是没能养成规律学习的习惯，提升不大。 O5 - 劳逸结合 0.5 KR 1: 探索匹兹堡 1 次（Down Town / 动物园）0.4 KR 2: 规律健身，每周 &gt;= 2 次 0.5 Progress: 休息上做的不够好，需要找时间放松。 2021 年度总结N/A 20221-2 双月O1 - 进入学习状态，成绩稳定 0.5 KR 1: 所有课程作业均在 A 的水平 0.5 KR 2: 所有作业提前 DDL 较长时间完成（不赶 due）0.5 KR 3: 开始准备 project，预防最后突击 0.5 Progress： 一切符合预期。 O2 - 确保 Research 进度 0.8 KR 1: 算出机器人定位精度 0.6 KR 2: 拿到 Blaser4iOS 初代硬件，完成激光检测、三角化代码 0.0 KR 3: 熟悉 VINS 整体算法，PipeBlaser 激光线解耦 0.8 KR 4: 更多的与其他项目组的同学交流 0.8 KR 5: THU 论文被接收 0.8 Progress： Blaser4iOS 未按计划完成，其他均顺利完成。额外完成了 GripperBlaser，整体超过预期。 O3 - 提升英语 0.4 KR 1: 每天规律听力 0.4 Progress： 前期保持得不错，但是后期没能坚持住。 O4 - 保证身体健康 0.5 KR 1: 成功打完 2 针 Pfizer 0.5 KR 2: 每周健身房 &gt;= 2 次 0.6 KR 3: 大保健 1 次 0.0 Progress： 因为疫情在减退，因此没有打第二针 Pfizer，继续观察。健身比较规律。 3-4 双月O1 - 所有课程拿到 A 0.4 KR 1: 不赶 due，所有作业提前较久完成（3 天以上）0.8 KR 2: 追赶 SLAM 课程进度，弥补 HW 1 成绩 0.3 KR 3: 按时保质完成所有 project （特别是 3DV）0.5 Progress: SLAM 对 report 要求较高，没能追上成绩，未避免影响 GPA 已改为 P/NP。其余课程比较正常。 O2 - 完成实习准备工作 0.8 KR 1: 确认是否 in-person，完成租房准备 1.0 KR 2: 完成申请 CPT 1.0 KR 3: 了解 relocation 流程，订好机票等事务 1.0 KR 4: 规律听力 0.5 Progress: 已确认 in person，准备工作基本完成。 O3 - Research 有明显进度 0.5 KR 1: Fix 掉 VIO 现有问题，表现追平 VINS 0.4 KR 2: 拿到 iOS Blaser 硬件 0.5 KR 3: Image Inpainting 完成可行性验证，找到创新点 0.5 KR 4: THU 论文见刊 1.0 KR 5: 明确双机器人 roadmap 0.2 KR6：与其他项目组同学更多交流 1.0 Progress: VIO 代码彻底检查一遍，未发现明显问题。调节几个参数后性能和 VINS 很接近，但稳定性仍有差距待查。iOS blaser 硬件准备完成。Image Inpainting 方向比较明确，需要进一步明确创新点。双机器人暂缓，待更熟悉 SLAM 后开始。与其他国家同学交流明显更多。 O4 - 劳逸结合 0.6 每周健身 &gt;= 2 次 0.6 一项以上的额外活动 0.6 Progres: 健身较为规律，且增加了各种球类运动。认识了新朋友。 5-6 双月O1 - 适应工作节奏，明确实习目标 0.6 KR 1: 入职前探索旧金山 / 湾区 0.8 KR 2: 熟悉周边环境、公司文化，规律化工作 / 生活节奏 0.6 KR 3: 明确一个可行且有意义的实习 project，有所产出 0.6 KR 4: 和同事建立良好关系 0.5 Progress： 整体节奏保持的还不错，实习项目进度快过预期，甚至需要寻找第二个项目。 O2 - Research 产出成果 0.5 KR 1: 阅读 MML Book 50%，写读书笔记 0.5 KR 2: iOS Blaser 实现扫描，开始集成后端 0.0 KR 3: Image Inpainting 拿到对比实验数据，开始开发新算法，明确论文大体内容 0.5 KR 4 (optional)：入门深度强化学习 0.0 KR 5: 博客突破 100 篇 0.4 Progress： MML Book 在坚持读，虽然没到 50% 但比较接近了。iOS Blaser 没有硬件暂时搁置，放到下学期开学完整学习 VINS 时做。Inpainting 取得阶段性进展，虽然算法本身创新性有限。目前准备结合管道扫描一起，目标一篇专利一篇论文。RL 暂时搁置，下学期开学时争取和实验室同学合作。博客 99 篇。 O3 - 丰富生活 0.6 KR 1: 打卡 WWDC 0.5 KR 2: 和朋友多探索湾区、结识新朋友 0.6 KR 3: 规律健身 0.5 KR 4: 和实验室同学保持联系 0.6 Progress： WWDC 遗憾不允许围观。其余各项均完成不错，每周规律打球。 7-8 双月O1 - 拿到 return，顺利返校 0.5 KR 1: 除现有项目外，再做一个相对较为完整的小型项目 0.5 KR 2: 现有项目收尾，达成预期目标 0.5 KR 3: 和同事保持紧密交流 0.4 KR 4: 做好实习 presentation 0.6 KR 5: 返回匹兹堡，搬家入住 OOC 0.8 Progress： 项目中规中矩，因 hiring freeze，return offer 不确定。 O2 - Research 项目进入落地状态，自身能力得到提高 0.3 KR 1: Inpainting 算法在新数据上验证 0.5 KR 2: 和同学完成新 sensor 设计（无盲区 RGBD）0.0 KR 3: 起草专利 0.0 KR 4: 论文形成大体轮廓 0.0 KR 5: 算法性能大幅优化，达到准实时（20 fps 以上）0.5 KR 6: 算法本身有明确创新点 0.2 KR 7: MML Book 读完 0.4 KR 8: 讲好 ML 课程，得到学生认可 0.5 Progress： Research 进度不好，主要是分配的时间过少。 O3 - 进入开学状态 0.4 KR 1: 和 Prof 沟通，注册到 OS 课程 0.0 KR 2: 开始系统学习 VINS 0.4 KR 3: 开始合作 Deep RL 项目 0.0 KR 4: 更新简历，开始恢复刷题手感 0.5 Progress： OS 课强制要求先修两门 system 课程，因此未选到。Deep RL 项目未开始。 O4 - 丰富生活 0.5 KR 1: 旅行一次 0.5 KR 2: 见更多朋友 0.4 KR 3: 规律健身、打球 0.5 KR 4: 保持和实验室同学联系 0.4 Progress： 勉强达到目标。 9-10 双月O1 - 秋招有进展 0.1 KR 1: Leetcode 刷到 180 题量级 0.2 KR 2: 收到 return offer 0.0 KR 3: 投递公司达 30 家，至少 5 家进入面试流程 0.2 Progress: 大环境导致几乎所有头部公司都冻结招聘。因没有面试，leetcode暂时搁置在 120+ 量级。Return offer 没有消息，感觉机会不大。仅收到 AIM 面试，offer 仍未发。 O2 - 学好 VINS 理论，Inpainting 进入实验状态 0.4 KR 1: 坚持完成 VINS paper workshop，开始代码重构 0.2 KR 2: 解决部分管道光流效果较差的问题，完善算法，开始设计实验 0.5 KR 3: 顺利完成 9 月底 sponsor demo 0.6 KR 4: Deep RL 项目开始合作 0.0 Progress： VINS paper workshop 完成，但离理解全部细节仍有较大差距。自监督学习效果较好，算法进入收尾阶段。Sponsor demo 顺利完层。Deep RL 仍未开始。 O3 - 学业顺利 0.6 KR 1: 所有作业提前 DDL 较久完成（不赶 due）0.6 KR 2: DS 课程作业达 A 水平并成功 enroll 0.6 Progress： DS 顺利 enroll，midterm 成功 regrade，目前处于 A 的水平但余量不多。 O4 - 劳逸结合 0.5 KR 1：规律健身 0.5 KR 2：多和 lab 同学交流 0.5 Progress： 每周户外跑步 1-2 次，坚持得不错。 11-12 双月O1 - 找到工作 0.5 KR 1: 完成 AIM 面试，拿到 offer 1.0 KR 2: TikTok 进入下一步 0.0 KR 2: 准备完成不同版本的简历（AI / Mobile 等）0.5 KR 3: 直接接触多家公司 manager，拿到面试机会 0.0 Progress: 拿到 AIM offer，薪资正常水平，焦虑值 -1。然而其他公司没有进展。找工作地狱难度的一年。 O2 - Research 收尾，进入新阶段 0.5 KR 1: Inpainting 算法定型，实验初步完成 0.6 KR 2: 论文 / 专利形成初稿 0.5 KR 3: Deep RL 开始合作 0.3 Progress： 算法基本定型，论文初稿完成。RL 合作了几天，然而算法整体架构需要推倒，因此合作暂停。 O3 - 学业顺利 0.6 KR 1: DS 拿 A，选到 OS 0.5 KR 2: 不赶 due 0.6 KR 3: 高质量完成 projects 0.6 Progress： 全部课程拿到 A，但是还没有选到 OS，需要联系 advisor。 O4 - 劳逸结合 0.4 KR 1: 坚持健身 0.5 KR 2: 去一次博物馆 0.0 KR 3: 和 lab 同学多交流 0.5 Progress： 一切正常，跑步仍在坚持。 20231-2 双月O1 - Offer 多多 0.2 KR 1: 骚扰 manager，拿到 return offer 0.0 KR 2: 至少另外一家公司开始面试 0.0 KR 3: 提交 OPT 申请 0.5 Progress： 没有时间准备工作相关的事情。OPT 顺利拿到 EAD 卡。 O2 - 调整状态，准备开学 0.5 KR 1: 选到 OS，注册 research 学分，只上两门课防止 workload 过大 0.6 KR 2: 要到 research 工资 0.0 KR 3: 认真学懂课程内容，所有作业达到 A 的水平 0.4 KR 4: 作业提早开始，不赶 due 0.5 Progress： 顺利选到 OS，然而因为太忙作业分数一般。 O3 - Research 结题，开新坑 0.5 KR 1: 一月底完成所有实验，并绘图 0.5 KR 2: 二月中论文定稿 0.4 KR 3: 顺利投出 IROS 0.6 KR 4: 新坑立项（双机器人 / 腐蚀预测）0.5 KR 5: 额外合作其他项目 0.0 Progress： 论文需要的工作量超出预期，度过了非常繁忙的一个月…… 但是最终顺利投稿了，期待结果。准备开坑双机器人项目。 O4 - 劳逸结合 0.5 KR 1: 旅行一次，为开学调整心情 0.6 KR 2: 坚持健身 0.4 KR 3: 和 lab 同学多交流 0.5 Progress： 一月去了波士顿。二月底因为论文太忙，基本没时间健身。 3-4 双月O1 - 准备毕业 0.5 KR 1: 提前较久完成 OS 大作业，不赶 due 0.5 KR 2: 充分准备考试，避免出现期中复习不足的情况 0.4 Progress： 基本没赶 due。期中考试虽然复习不充分，但是成绩尚可。 O2 - 找工作有新进展 0.0 KR 1: 完成 OS P3 后，尝试投递操作系统相关岗位 0.0 KR 2: 开始恢复刷题 0.0 KR 3: 骚扰更多 manager，争取面试机会 0.0 Progress： 找工毫无进展，哭泣。 O3 - Research 做出 prototype 0.2 KR 1: 调研双机器人方案 0.5 KR 2: 完成标定，分析误差，验证可行性 0.2 KR 3: 做出原型机 0.0 KR 4: 写专利（旧项目）0.0 Progress： 带小朋友调研，但是因为只有大一，进度较慢。主要是我自己全程犯懒。 O4 - 保持身心愉悦 0.4 恢复规律运动 0.5 多和人交流 0.4 5-6 双月O1 - 顺利毕业 0.5 KR 1: 充分准备期末考试 0.0 KR 2: 参加毕业典礼，拿到毕业证 0.6 KR 3: 完成卖东西、退租等琐事，准备回国 0.6 Progress： 因为要毕业了心不在焉，考试稀烂。但好在不影响毕业。参加了很多毕业典礼，和朋友们玩得很开心。 O2 - 准备反美 KR 1: 在 6 月底之前拿到签证 KR 2: 订机票 O3 - 找工作有进展 KR 1: APPL 继续面试，拿到 offer KR 2: 恢复刷题 O4 - 亲友团聚、锻炼身体 KR 1: 去超过 5 个城市，多见老朋友 KR 2: 规律参加体育活动 KR 3: 恢复规律健身 KR 4: 多爬山 O5 - lab 收尾工作 KR 1: IROS paper 都录用，准备 camera ready 版本 KR 2: Google drive 资料整理完毕 O6 - 完成其他琐事 KR 1: 洗牙、体检 KR 2: 办理港澳通行证 KR 3: 驾照、身份证 renew KR 4: 坚持制作科普视频 7-8 双月TBA","link":"/2021/01/02/2021-okr/"},{"title":"AFNetworking设置HTTP的Header和Body","text":"AFNetworking 设置 HTTP Header / Body多数情况下，我们并不需要特别设置 HTTP 的 header 和 body，使用 AFNetworking 的 paramters 参数就够了。但是有些时候，我们需要用 Header 来放置一些授权码，或者 Body 来放置二进制数据，这个时候就要自己设置 Header 和 Body 了。 如何设置 Header设置 Header 较为简单，只需要： 12AFHTTPSessionManager *manager = [AFHTTPSessionManager manager];[manager.requestSerializer setValue:@&quot;Fri, 13 Jul 2018 07:28:11 GMT&quot; forHTTPHeaderField:@&quot;Date&quot;]; 就可以了。之后，就可以按照我们熟悉的方式来发送请求，比如： 12345[manager GET:@&quot;https://your.url&quot; parameters:nil progress:nil success:^(NSURLSessionDataTask * _Nonnull task, id _Nullable responseObject) { //... } failure:^(NSURLSessionDataTask * _Nullable task, NSError * _Nonnull error) { //... }]; 如何设置 Body如果你想故伎重演，就会发现刚刚的 setValueForHeader 方法并没有对应 setValueForBody 的方法。但是，AFNetworking 的请求函数里是提供了这样的参数的： 1234567[self.manager POST:@&quot;http://your.url&quot; parameters:nil constructingBodyWithBlock:^(id&lt;AFMultipartFormData&gt; _Nonnull formData) { [formData appendPartWithFormData:yourData name:@&quot;yourDataName&quot;]; //设置form-data } progress:nil success:^(NSURLSessionDataTask * _Nonnull task, id _Nullable responseObject) { //... } failure:^(NSURLSessionDataTask * _Nullable task, NSError * _Nonnull error) { //... }]; 它可以让你用一个 block 来设置 body 的 form-data，这当然是没问题的。但是，一旦你通过这种方式设置了 form-data，那么你的 HTTP Header 中 Content-Type 属性就会被设置为 multipart/form-data （否则，服务端怎么解析呢？）。而有些场景下，我们需要指定自己的 Content-Type。 比如，在腾讯云的有些接口中，需要使用 protobuf 来交互数据。那就需要我们把 Content-Type 设置为 application/x-protobuf，并把 protobuf 生成的二进制数据放倒 body 中。按照上述的操作，自己设置的 Content-Type 就会被覆盖，导致上传失败。有没有什么办法能干干净净地设置 body 呢？ 1234567self.manager = [[AFURLSessionManager alloc] initWithSessionConfiguration:[NSURLSessionConfiguration defaultSessionConfiguration]];NSMutableURLRequest *request = [AFHTTPRequestSerializer.serializer requestWithMethod:@&quot;POST&quot; URLString:@&quot;http://your.url&quot; parameters:nil error:nil];[request setValue:@&quot;application/x-protobuf&quot; forHTTPHeaderField:@&quot;Content-Type&quot;]; //设置Header，和之前的方法类似[request setHTTPBody:protoBufData]; //设置Body[[self.manager dataTaskWithRequest:request uploadProgress:nil downloadProgress:nil completionHandler:^(NSURLResponse * _Nonnull response, id _Nullable responseObject, NSError * _Nullable error) { //... }] resume]; //发送请求，注意一定要调用 resume 方法来开始。 这样就可以啦！","link":"/2018/07/13/AFNetworking%E8%AE%BE%E7%BD%AEHTTP-Header-Body/"},{"title":"JS调用Swift造成卡顿问题","text":"JS调用Swift造成卡顿问题最近正在构思一个新的项目，是一个控制蓝牙外设的 App，主要目标用户是电子爱好者，或者是做课程设计的大学生。这部分人群往往有一定的编程能力，但学习开发一款移动应用的成本又太高了。比如，如果希望用手机控制蓝牙小车，在这个小众场景下，这款 App 就会有用武之地了。 背景鉴于目标用户是有一定编程能力的（毕竟蓝牙外设端还需要自己编程），为了增加 App 控制的灵活性，我就考虑增加一个通过 JavaScript 脚本自定义蓝牙收发逻辑的功能。这个想法也是受到钟大 JSBox 的启发。但有一个问题就是，如果用户编写的脚本包含耗时很久的循环，甚至死循环，比如用户想让蓝牙小车永远沿矩形运动，就可能会编出这样的代码： 1234567while (true) { send_message(&quot;move forward&quot;); //通过蓝牙发送前进指令，小车接收到之后前进 //注意非浏览器环境没有setTimeOut函数 for (var i=0; i&lt;10000000000; i++); //通过空循环延迟一段时间 send_message(&quot;turn left&quot;); //左转 for (var i=0; i&lt;10000000000; i++); //延迟，并不断重复} 一旦写出了这样的死循环，那么 App 的主线程就全部用来执行 JavaScript 代码，从而完全卡死。用户当然能达到他的需求——毕竟蓝牙消息在不断发送，但是完全卡死的 App 就再也无法使用了，用户体验极差。在当前版本的 JSBox 中，运行死循环也会造成卡死现象，只能强制退出 App。 开辟后台线程既然死循环会把主线程卡死，那么我们在后台执行 JavaScript 不就解决这个问题了么？这是一个非常直观的想法，我也很快写出了这样的代码： 123456work = DispatchWorkItem { [unowned self] in self.jsvm = JSVirtualMachine() self.context = self.generateJSContext(vm: self.jsvm!) self.context?.evaluateScript(code)}DispatchQueue.global().async(execute: work!) 这里要注意的一点是，如果需要在多线程中使用 JavaScriptCore，则需要给每个线程一个自己的 JS 虚拟机。否则，JS 虚拟机永远都会执行完上一次的程序，再来执行新加入的程序。 然后，我编写了这样的 JavaScript 代码来测试效果，看是不是不会卡死主线程了： 1234while (true) { for (var i=0; i&lt;10000000000; i++); //延时一段时间 toast(&quot;Hello JS!&quot;); } toast 函数会回调 Swift 代码，从而在屏幕上弹出一段消息。当然，UIKit 不是线程安全的，所以在回调函数中必须回到主线程操作 UI： 12345func toast(_ msg: JSValue) { DispatchQueue.main.async { Toast.show(string: msg.toString(), type: .js) }} 写完这段天衣无缝的程序，我就很开心的去执行上面的那段测试代码了。果然，程序运行那段耗时空循环的时候，ScrollView 还可以顺畅的滚动，看来真的不会卡顿了。“我是天才！”，我心里默想。 但是好景不长！当 App 第一次展示了那条 toast 之后，主线程瞬间变得非常卡顿——没有完全卡死，偶尔还能相应输入，但是反应速度慢到了完全不可操作的地步。这是为什么呢？ 分析问题原因第一个想法当然是要看看卡顿的点在哪里，我首先在主线程的代码块里加入了一些调试代码。别忘了 print 不是线程安全的，这里最好使用 NSLog，而且 NSLog 还自带线程 id 号，很适合调试多线程程序。 1234567func toast(_ msg: JSValue) { DispatchQueue.main.async { //NSLog Toast.show(string: msg.toString(), type: .js) //NSLog }} 这时我发现，两次 Log 之间间隔了很久，显然是这里发生了卡顿。而第二次 Log 结束后，很快就又打印出了第一条 Log，仿佛 JS 里面那条空循环不耗时一样，问题变得蹊跷起来。 会不会是 Toast.show 函数用时太久了呢？我干脆把这个函数注释成了空函数，但完全没有影响。看来是有什么隐蔽的操作在耗时，而不是这个函数本身。而奇怪的是，当我把 JS 里空循环的循环次数增加后，两次 Log 的间隔竟然也跟着变长了，这就有点让我摸不到头脑。毕竟，JS 代码是在另一个线程里面运行的，怎么会影响到我这短短两行的主线程代码块呢？ 为了找到原因，我干脆监听了 RunLoop 状态。毕竟这段代码块是给主线程这个串行队列队尾的，如果主线程在忙于处理什么事情，这段代码执行的时间就会变晚。结果发现卡顿点确实发生在 RunLoop 处理 source0 的阶段，但这并没有给我什么启发。 调试现在 Swift 级别的代码调试已经看不出来问题在哪了，只好进入汇编级别调试一下，看看这段时间主线程到底在忙些什么。Xcode 用的编译器是 llvm，调试器自然就是 lldb。lldb 的命令和 gdb 很像（毕竟当时就是为了替换 gdb 才搞出来的），使用 stepi 命令可以 step into 到下一个指令。 很快我就发现，我调用的 toString 函数中，有些加锁的操作。这里就非常值得警惕了。好在，JSCore 其实是开源的，我们可以去 Github 上看一下 JSCore 的源代码： 123456789id valueToString(JSGlobalContextRef context, JSValueRef value, JSValueRef* exception){ ASSERT(!*exception); if (id wrapped = tryUnwrapObjcObject(context, value)) { if ([wrapped isKindOfClass:[NSString class]]) return wrapped; } //...} 上面是 JSCore 源码中，toString 函数调用的一个函数。我们可以看到，它果然继续调用了刚刚汇编代码中 tryUnwrapObjcObject 函数。我们继续找到 tryUnwrapObjcObject 函数的源码： 1234567id tryUnwrapObjcObject(JSGlobalContextRef context, JSValueRef value){ //... JSC::JSLockHolder locker(toJS(context)); //... return nil;} 可以看到，这个函数中给 JS 的上下文环境加了锁。 继续阅读源码，有一段注释解释了为什么要给 context 加锁： 123456789// This is fairly nasty. We allow multiple threads to run on the same// context, and we do not require any locking semantics in doing so -// clients of the API may simply use the context from multiple threads// concurently, and assume this will work. In order to make this work,// We lock the context when a thread enters, and unlock it when it leaves.// However we do not only unlock when the thread returns from its// entry point (evaluate script or call function), we also unlock the// context if the thread leaves JSC by making a call out to an external// function through a callback. 可以看到，这是为了保证线程安全而做的工作，而且，在线程切换的时候也会加锁/解锁！ 原理（猜测）所以对于发生卡顿的原因，我做如下猜测（不敢 100% 确定）： 最开始，JS 执行延时循环的时候，是正常在子线程里运行的，所以主线程不卡顿，一切都相安无事。 在调用 toast 函数的时候，发生了线程切换。这个时候，JSCore 会给 context 加锁，然后瞬间返回，解锁继续给 JS 代码使用。接着，代码块被闲下来的主线程执行了。由于 toString 函数在主线程运行，所以它必须要等到 JSCore 把 context 解锁才能执行。这个时候，由于代码块是异步执行的，所以子线程又开始回去执行耗时循环了。而正在执行的 JavaScript 是不会释放锁的，所以主线程只好等待——造成了卡顿现象。 终于，JS 代码跑完了耗时循环，JS 代码释放了锁，主线程终于能运行了。主线程很快执行完显示 toast 的函数，然后释放，让 JS 能继续跑。这也解释了为什么增加循环次数也会影响卡顿时间。但是，这个时候主线程执行的还是上一次的 toast 请求，而这已经是第二次 JS 完成耗时循环了。所以，JS 又会把一个代码块加到主队列中…而只有第三次的时候，主线程才能等到资源，完成第二次的请求……如此反复，主线程虽然总有一点机会执行代码而不至于被饿死，但是多数时间都处于等待资源的状态，导致异常的卡顿。 验证我写了一段 JS 代码来验证我的猜测： 12345678var count = 0;while (true) { for (var i=0; i&lt;10000000000; i++); //延时一段时间 if (count == 0) { toast(&quot;Hello JS!&quot;); count++; }} 这样，只调用主线程一次。按照上面的分析，一直再次发生线程切换，JS 就一直持有锁而不释放，主线程就永远没有机会执行。经验证，主线程确实完全卡死，等再久也没有反应。主线程被饿死，验证成功。 我又把 Swift 代码块改成同步代码块。这样，JS 要等待主线程执行完才能继续执行，而主线程又需要 JS 线程再次调用才能完成，因此会发生死锁。经验证，主线程完全卡死，再次验证成功。 改正与总结有了以上分析，改正变得非常容易： 123456func toast(_ msg: JSValue) { let str = msg.toString() DispatchQueue.main.async { Toast.show(string: str, type: .js) }} 只需要把 toString 放在子线程中执行，就不存在主线程等待资源的问题了。可见，写代码时的一念之差，就会需要我花很久来调试、分析。如果最开始随手一写就写成正确的样子，就能省下大把的时间了。但话说回来，也就规避了问题。问题暴露出来，才能让我有机会深入学习。这也正是经验的来源吧。","link":"/2019/02/15/JS%E8%B0%83%E7%94%A8Swift%E9%80%A0%E6%88%90%E5%8D%A1%E9%A1%BF%E9%97%AE%E9%A2%98/"},{"title":"JavaScript基础分享","text":"JavaScript 基础分享 Any application that can be written in JavaScript, will eventually be written in JavaScript. JS 简介JavaScript 是一门动态的、弱类型的、基于原型（而不是基于类）的解释型（或 JIT 编译型）语言。它是一门多范式语言，支持命令式、面向对象，以及函数式编程。语言本身不支持 I/O 操作，而是依赖于宿主环境。现在，JS 不仅可以在浏览器中运行，也可以运行在 Node 等非浏览器环境中。 JS 是一门单线程语言，这意味着在浏览器中，JS 代码只能在 JS 引擎线程中执行。但这并不意味着耗时操作（如 HTTP 请求）会把界面卡死，因为浏览器本身是可以开启多线程的。在 HTML 5 中，可以通过 Web Workers 来在多个线程中执行 JS 代码，但这和“JS 是单线程语言”并不冲突。因为多个 worker 之间并不共享资源，而只能通过 message 来通信。 JavaScript 已由 ECMA 进行了标准化，这个标准被称为 ECMAScript。JavaScript 是 ECMAScript 的一种实现，但在绝大多数情况下，这两个词是可以互换的。每年的 6 月，ECMA 都会发布一个新标准，不过大家通常使用 ES6 来指代 ES2015 及以后的版本，泛指“下一代 JavaScript”。在《JavaScript 高级程序设计》这本书中，讲解的是 ES5。 基本概念变量JavaScript 的变量是松散类型的，一个变量可以用来保存任意类型的值。如果没有被初始化，那么变量就会保存一个特殊的值 undefined。 123456var a;console.log(a); //undefineda = 5;console.log(a); //5a = 'hello world!';console.log(a); //hello world! 声明变量需要使用 var 操作符，但是如果不使用，不仅不会报错，反而变量会变成全局变量，不鼓励这种行为。 数据类型JavaScript 中有 5 种基本数据类型： Undefined Null Boolean Number String 和一种复杂类型： Object 之前提到，JavaScript 不是基于类的，因此它也不支持创建自定义的类型。所有值都将是上述的 6 种类型之一。虽然在 ES6 中引入了 class，但这只是语法糖而已。 可以使用 typeof 操作符来判断类型。typeof 操作符会返回一些字符串： “undefined” “boolean” “string” “number” “object” “function” 函数在 JS 中也是对象，但是 typeof 操作符还是会把函数和普通对象作出区分。 还有比较神奇的一点是，虽然 Null 类型只有一个特殊的值 null，但是 typeof null 返回的却是 &quot;object&quot;，这是因为 null 表示一个空对象指针。 123456console.log(typeof &quot;hello?&quot;); //&quot;string&quot;function foo() {}console.log(typeof foo); //&quot;function&quot;console.log(typeof(null)); //&quot;object&quot; 关系操作符关系操作符遇到非数值类型时，会发生一些比较神奇的事情，比如： 1234&quot;23&quot; &lt; &quot;3&quot; //true&quot;23&quot; &lt; 3 //false&quot;a&quot; &lt; 3 //false&quot;a&quot; &gt;= 3 //false 首先，两个字符串比较的是字符编码值。字符”2”的编码值小于”3”，因此是 true。 但是，如果一边是数值，则另一边会被转化成数值再做比较。”23” 会被转化成 23，所以返回 false。 但是第三行和第四行中，”a” 转化成数值会变成 NaN。NaN 与任何数值比较都会返回 false，所以会出现既不大于，也不等于，还不小于的情况。 如果操作数是对象，则会先调用 valueOf() 方法。如果没有这个方法，则会调用 toString() 再根据之前的标准比较。 相等操作符JavaScript 中有两种比较：== 和 ===。 使用 ==，会在比较前先做类型转换，而 === 直接比较。由于 JS 臭名昭著的蜜汁类型转换会带来各种各样的奇怪现象，强烈建议经常使用 === 做全等判断。 123455 == '5' //truenull == undefined //truetrue == 1 //truetrue == 2 //falseNaN === NaN //false 想彻底搞懂？ 123[{}] + [] === &quot;[object Object]&quot; //true 😊25[[[+[] == +[]][0] + []][0][0] + [[{}] + []][0][1]+ [[] + []][0][([[{}] + []][0][5]) + ([[{}] + []][0][1]) + ([[][0]+[]][0][1]) + ([[[] == []][0] + []][0][3]) + ([[+[] == +[]][0] + []][0][0]) + ([[+[] == +[]][0] + []][0][1]) + ([[][0]+[]][0][0]) + ([[{}] + []][0][5]) + ([[+[] == +[]][0] + []][0][0]) + ([[{}] + []][0][1]) + ([[+[] == +[]][0] + []][0][1])][[[][0]+[]][0][1] + [[[] == []][0] + []][0][1] + [0[([[{}] + []][0][5]) + ([[{}] + []][0][1]) + ([[][0]+[]][0][1]) + ([[[] == []][0] + []][0][3]) + ([[+[] == +[]][0] + []][0][0]) + ([[+[] == +[]][0] + []][0][1]) + ([[][0]+[]][0][0]) + ([[{}] + []][0][5]) + ([[+[] == +[]][0] + []][0][0]) + ([[{}] + []][0][1]) + ([[+[] == +[]][0] + []][0][1])]+[]][0][11] + [[[] == []][0] + []][0][4]]](30) //&quot;p&quot; for-in和其他语言不一样，我们可以使用 for-in 循环来遍历对象的属性名，比如： 12345678910var person = new Object();person.name = &quot;Luyuan Wang&quot;;person.age = 20;person.school = &quot;Huazhong University of Science and Technology&quot;;for (var propName in person) { console.log(propName);}//name//age//school 这个顺序是不保证的。 如果遍历的对象是数组，那么取出来的是数组下标，而不是元素，这个跟 Objective-C 或者 Swift 等语言都不一样： 1234567var list = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;];for (var each in list) { console.log(each);}//0//1//2 因此，上面代码的 each 更应该被命名为 index。 函数JavaScript 的函数不用定义返回值类型，甚至有没有返回值都不是确定的。 1234567function divide(a, b) { if (b === 0) { return; } return a / b;}console.log(divide(1, 0)); //undefined JavaScript 函数的参数是通过数组来访问的（只是类似数组，但并不是 Array 的实例），因此它并不关心你传入多少个变量，更不关心变量的类型。你甚至可以通过 arguments + 下标来访问参数，参数名其实只是一种便利： 1234function foo() { console.log(arguments[0]); //很像数组}foo('hello world!'); 1234567var array = [];console.log(Array.isArray(array)); //truefunction foo() { console.log(Array.isArray(arguments)); //false 并不是Array的实例}foo(); 这和 OC 中用函数参数名、参数类型等作为函数签名有很大区别。需要注意的是，JavaScript 的参数传递的永远是值，而不是引用（这点在后面会再次提及）。 JavaScript 中的函数不支持重载，但是可以利用 arguments.length 判断参数个数，从而表现出不同的行为。 变量、作用域和内存问题基本类型和引用类型的值尽管 JavaScript 是松散类型的，但变量的值还是分为基本类型的值和引用类型的值。前面提到的 5 种基本类型是按值访问的，而 Object 类型操作的是引用。和许多其他的语言不同，String 是基本类型值，而不是引用，这和 Swift 很像。 12345var num = 5;var num2 = num;num2 += 1;console.log(num); //5console.log(num2); //6 123456var obj = new Object();obj.value = 5;var obj2 = obj;obj2.value += 1;console.log(obj.value); //6console.log(obj2.value); //6 12345var str = &quot;123&quot;;var str2 = str;str2 += &quot;4&quot;;console.log(str); //&quot;123&quot;console.log(str2); //&quot;1234&quot; 和Swift一样，String不是引用类型 函数参数之前提到，JavaScript 中函数的参数是以值来传递的，而永远不是引用。那么，下面这个例子应该输出什么呢？ 12345678function changeSchool(person) { person.school = &quot;Mizzou&quot;;}var luyuanwang = { school: &quot;HUST&quot;}changeSchool(luyuanwang);console.log(luyuanwang.school); 答案是“Mizzou”。看起来很奇怪，似乎不符合我们说传递的是值，而更像是在传递引用？其实，这里传递的值，是指把“对象”复制一遍。这里的对象是一个引用，那么就把这个指针复制了，因此这里是两个不同的、指向同一个地址的引用。所谓的传递的是值，并不是指把内存中的对象复制一遍，这里要搞清楚。 没有块级作用域虽然函数会创建局部的执行环境，但是花括号封闭的代码块并没有自己的执行环境： 12345var flag = true;if (flag) { var num = 10;}console.log(num); //10 仍有定义 这和一般的语言都不同。如果想要“正常一点”，可以使用 ES6 中引入的关键字 let： 12345var flag = true;if (flag) { let num = 10;}console.log(num); //ReferenceError: num is not defined 垃圾收集JavaScript 是有 GC 的，通过“标记清除“的方式，周期性地回收垃圾。有些浏览器也曾经使用过引用计数，不过发现有循环引用的问题后，后来就又放弃了。所以一般情况下，我们都不必操心内存的事情。 通过标记清除算法，GC 将会从根对象开始（根对象是一个全局对象），开始寻找根对象引用的对象，并递归地寻找下去。那些无法触达的对象，将被认为是垃圾对象，会被 GC 回收。从 2012 年开始，所有现代浏览器都使用了标记清除或其改进型算法，即使产生循环引用，照样可以被清除掉。 原型链之前提到过，JavaScript 是基于原型的语言，这和我们所熟悉的其他语言都不一样。 构造函数在 JS 中，可以使用原型模式来创建一个对象（尽管这不是唯一的方法）： 1234567891011function Employer() {}Employer.prototype.name = &quot;Lei, Jun&quot;;Employer.prototype.company = &quot;Xiao Mi&quot;;Employer.prototype.makeSpeech = function() { console.log(&quot;Are u ok?&quot;);}var person = new Employer();person.makeSpeech(); //Are u ok? Employer 和普通的方法没有任何区别，但是如果在调用的时候使用了 new 关键字，就会成为一个构造函数。每个函数都有一个 prototype 属性，这个属性指向的就是创造出来的实例的原型对象。 原型对象原型最初会包含一个 constructor，指向它的构造函数。也就是 Employer.prototype.constructor 就是 Employer。每个对象也都有一个 [[Prototype]] 属性来指向原型对象，但这个属性是私有的，不能通过外界访问。不过在有一些浏览器（比如 Safari 和 Chrome 中），提供了一个 __proto__ 属性来访问原型。 如果你修改属性的值，其实只是对变量创建了一个新的属性，屏蔽掉了在对象原型中查找的操作。在多数情况下，这都没什么问题，但如果原型对象中放置了一个引用类型的属性，那么原型共享的特性就会导致问题了。为了解决这个问题，可以用普通的构造函数构造属性，而用原型构造方法。 12345678910function Employer(name) { this.name = name;}Employer.prototype = { constructor: Employer, makeSpeech: () =&gt; {console.log('Are u ok?')}}var person = new Employer('Lei, Jun');person.makeSpeech(); 终于来到原型链如果我们修改掉 prototype，把它指向一个实例，那么在搜索属性和方法的时候，就会一层一层地搜索下去，也就间接地实现了继承。每个对象都有原型对象，原型对象又有自己的原型对象，从而构成了一个原型链。原型链的最后一环是 null，null 没有原型。 12345678910111213function Father() { this.sex = &quot;male&quot;;}function Son() { this.job = &quot;programmer&quot;;}Son.prototype = new Father();var person = new Son();console.log(person.sex); //male 通过查找原型的属性找到console.log(person.job); //programmer 自己的属性 不过直接使用原型链是有缺陷的。首先，由于原型是共享的，那么含有引用类型属性的原型就会出问题。而且，不能在子类中向父类的构造函数中传递参数。为了解决这些问题，程序员们想出了很多方法。不过，现在我们有个 ES6，可以使用 ES6 的新关键字 class 来定义类了。但这只是语法糖，并没有改变 JS 基于原型的事实。 12345678910111213141516class Father { constructor() { this.sex = &quot;male&quot;; }}class Son extends Father { constructor(job) { super(); this.job = job; }}var person = new Son(&quot;programmer&quot;);console.log(person.sex); //maleconsole.log(person.job); //programmer","link":"/2018/07/26/JavaScript%E5%9F%BA%E7%A1%80%E5%88%86%E4%BA%AB/"},{"title":"Flutter for iOS devs 翻译","text":"Flutter for iOS Developers 翻译官方文档原文链接：https://flutter.io/flutter-for-ios/ 此翻译文档已被 Flutter 中文网 收录。 本文档适用那些希望将现有 iOS 经验应用于 Flutter 的开发者。如果你拥有 iOS 开发基础，那么你可以使用这篇文档开始学习 Flutter 的开发。 开发 Flutter 时，你的 iOS 经验和技能将会大有裨益，因为 Flutter 依赖于移动操作系统的众多功能和配置。Flutter 是用于为移动设备构建用户界面的全新方式，但它也有一个插件系统用于和 iOS（及 Android）进行非 UI 任务的通信。如果你是 iOS 开发专家，则你不必将 Flutter 彻底重新学习一遍。 你可以将此文档作为 cookbook，通过跳转并查找与你的需求最相关的问题。 ViewsUIView 相当于 Flutter 中的什么？在 iOS 中，构建 UI 的过程中将大量使用 view 对象。这些对象都是 UIView 的实例。它们可以用作容器来承载其他的 UIView，最终构成你的界面布局。 在 Flutter 中，你可以粗略地认为 Widget 相当于 UIView 。Widget 和 iOS 中的控件并不完全等价，但当你试图去理解 Flutter 是如何工作的时候，你可以认为它们是“声明和构建 UI 的方法”。 然而，Widget 和 UIView 还是有些区别的。首先，widgets 拥有不同的生存时间：它们一直存在且保持不变，直到当它们需要被改变。当 widgets 和它们的状态被改变时，Flutter 会构建一颗新的 widgets 树。作为对比，iOS 中的 views 在改变时并不会被重新创建。但是与其说 views 是可变的实例，不如说它们被绘制了一次，并且直到使用 setNeedsDisplay() 之后才会被重新绘制。 此外，不像 UIView，由于不可变性，Flutter 的 widgets 非常轻量。这是因为它们本身并不是什么控件，也不会被直接绘制出什么，而只是 UI 的描述。 Flutter 包含了 Material 组件库。这些 widgets 遵循了 Material 设计规范。MD 是一个灵活的设计系统，并且为包括 iOS 在内的所有系统进行了优化。 但是用 Flutter 实现任何的设计语言都非常的灵活和富有表现力。在 iOS 平台，你可以使用 Cupertino widgets 来构建遵循了 Apple’s iOS design language 的界面。 我怎么来更新 Widgets？在 iOS 上更新 views，只需要直接改变它们就可以了。在 Flutter 中，widgets 是不可变的，而且不能被直接更新。你需要去操纵 widget 的 state。 这也正是有状态的和无状态的 widget 这一概念的来源。一个 StatelessWidget 正如它听起来一样，是一个没有附加状态的 widget。 StatelessWidget 在你构建初始化后不再进行改变的界面时非常有用。 举个例子，你可能会用一个 UIImageView 来展示你的 logo image 。如果这个 logo 在运行时不会改变，那么你就可以在 Flutter 中使用 StatelessWidget 。 如果你希望在发起 HTTP 请求时，依托接收到的数据动态的改变 UI，请使用 StatefulWidget。当 HTTP 请求结束后，通知 Flutter 框架 widget 的 State 更新了，好让系统来更新 UI。 有状态和无状态的 widget 之间一个非常重要的区别是，StatefulWidget 拥有一个 State 对象来存储它的状态数据，并在 widget 树重建时携带着它，因此状态不会丢失。 如果你有疑惑，请记住以下规则：如果一个 widget 在它的 build 方法之外改变（例如，在运行时由于用户的操作而改变），它就是有状态的。如果一个 widget 在一次 build 之后永远不变，那它就是无状态的。但是，即便一个 widget 是有状态的，包含它的父亲 widget 也可以是无状态的，只要父 widget 本身不响应这些变化。 下面的例子展示了如何使用一个 StatelessWidget 。一个常见的 StatelessWidget 是 Text widget。如果你查看 Text 的实现，你会发现它是 StatelessWidget 的子类。 1234Text( 'I like Flutter!', style: TextStyle(fontWeight: FontWeight.bold),); 阅读上面的代码，你可能会注意到 Text widget 并不显示地携带任何状态。它通过传入给它的构造器的数据来渲染，除此之外再无其他。 但是，如果你希望 I like Flutter在点击 FloatingActionButton 时动态的改变呢？ 为了实现这个，用 StatefulWidget 包裹 Text widget，并在用户点击按钮时更新它。 举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { // Default placeholder text String textToShow = &quot;I Like Flutter&quot;; void _updateText() { setState(() { // update the text textToShow = &quot;Flutter is Awesome!&quot;; }); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: Center(child: Text(textToShow)), floatingActionButton: FloatingActionButton( onPressed: _updateText, tooltip: 'Update Text', child: Icon(Icons.update), ), ); }} 我怎么对 widget 布局？我的 Storyboard 在哪？在 iOS 中，你可能会用 Storyboard 文件来组织 views，并对它们设置约束，或者，你可能在 view controller 中使用代码来设置约束。在 Flutter 中，你通过编写一个 widget 树来声明你的布局。 下面这个例子展示了如何展示一个带有 padding 的简单 widget： 1234567891011121314151617@overrideWidget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: Center( child: CupertinoButton( onPressed: () { setState(() { _pressedCount += 1; }); }, child: Text('Hello'), padding: EdgeInsets.only(left: 10.0, right: 10.0), ), ), );} 你可以给任何的 widget 添加 padding，这很像 iOS 中约束的功能。 你可以在 widget catalog 中查看 Flutter 提供的布局。 我怎么在我的约束中添加或移除组件？在 iOS 中，你在父 view 中调用 addSubview() 或在子 view 中调用 removeFromSuperview() 来动态地添加或移除子 views。在 Flutter 中，由于 widget 不可变，所以没有和 addSubview() 直接等价的东西。作为替代，你可以向 parent 传入一个返回 widget 的函数，并用一个布尔值来控制子 widget 的创建。 下面这个例子展示了在点击 FloatingActionButton 时如何动态地切换两个 widgets： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { // Default value for toggle bool toggle = true; void _toggle() { setState(() { toggle = !toggle; }); } _getToggleChild() { if (toggle) { return Text('Toggle One'); } else { return CupertinoButton( onPressed: () {}, child: Text('Toggle Two'), ); } } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: Center( child: _getToggleChild(), ), floatingActionButton: FloatingActionButton( onPressed: _toggle, tooltip: 'Update Text', child: Icon(Icons.update), ), ); }} 我怎么对 widget 做动画？在 iOS 中，你通过调用 animate(withDuration:animations:) 方法来给一个 view 创建动画。在 Flutter 中，使用动画库来包裹 widgets，而不是创建一个动画 widget。 在 Flutter 中，使用 AnimationController 。这是一个可以暂停、寻找、停止、反转动画的 Animation&lt;double&gt; 类型。它需要一个 Ticker 当 vsync 发生时来发送信号，并且在每帧运行时创建一个介于 0 和 1 之间的线性插话（interpolation）。你可以创建一个或多个的 Animation 并附加给一个 controller。 例如，你可能会用 CurvedAnimation 来实现一个 interpolated 曲线。在这个场景中，controller 是动画过程的“主人”，而 CurvedAnimation 计算曲线，并替代 controller 默认的线性模式。 当构建 widget 树时，你会把 Animation 指定给一个 widget 的动画属性，比如 FadeTransition 的 opacity，并告诉控制器开始动画。 下面这个例子展示了在点击 FloatingActionButton 之后，如何使用 FadeTransition 来让 widget 淡出到 logo 图标： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Fade Demo', theme: ThemeData( primarySwatch: Colors.blue, ), home: MyFadeTest(title: 'Fade Demo'), ); }}class MyFadeTest extends StatefulWidget { MyFadeTest({Key key, this.title}) : super(key: key); final String title; @override _MyFadeTest createState() =&gt; _MyFadeTest();}class _MyFadeTest extends State&lt;MyFadeTest&gt; with TickerProviderStateMixin { AnimationController controller; CurvedAnimation curve; @override void initState() { controller = AnimationController(duration: const Duration(milliseconds: 2000), vsync: this); curve = CurvedAnimation(parent: controller, curve: Curves.easeIn); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(widget.title), ), body: Center( child: Container( child: FadeTransition( opacity: curve, child: FlutterLogo( size: 100.0, ) ) ) ), floatingActionButton: FloatingActionButton( tooltip: 'Fade', child: Icon(Icons.brush), onPressed: () { controller.forward(); }, ), ); } @override dispose() { controller.dispose(); super.dispose(); }} 更多信息，请参阅 Animation &amp; Motion widgets， Animations tutorial 以及 Animations overview。 我该怎么绘图？在 iOS 上，你通过 CoreGraphics 来在屏幕上绘制线条和形状。Flutter 有一套基于 Canvas 类的不同的 API，还有 CustomPaint 和 CustomPainter 这两个类来帮助你绘图。后者实现你在 canvas 上的绘图算法。 想要学习如何实现一个笔迹画笔，请参考 Collin 在 StackOverflow 上的回答。 123456789101112131415161718192021222324252627282930313233343536373839404142class SignaturePainter extends CustomPainter { SignaturePainter(this.points); final List&lt;Offset&gt; points; void paint(Canvas canvas, Size size) { var paint = Paint() ..color = Colors.black ..strokeCap = StrokeCap.round ..strokeWidth = 5.0; for (int i = 0; i &lt; points.length - 1; i++) { if (points[i] != null &amp;&amp; points[i + 1] != null) canvas.drawLine(points[i], points[i + 1], paint); } } bool shouldRepaint(SignaturePainter other) =&gt; other.points != points;}class Signature extends StatefulWidget { SignatureState createState() =&gt; SignatureState();}class SignatureState extends State&lt;Signature&gt; { List&lt;Offset&gt; _points = &lt;Offset&gt;[]; Widget build(BuildContext context) { return GestureDetector( onPanUpdate: (DragUpdateDetails details) { setState(() { RenderBox referenceBox = context.findRenderObject(); Offset localPosition = referenceBox.globalToLocal(details.globalPosition); _points = List.from(_points)..add(localPosition); }); }, onPanEnd: (DragEndDetails details) =&gt; _points.add(null), child: CustomPaint(painter: SignaturePainter(_points), size: Size.infinite), ); }} Widget 的透明度在哪里？在 iOS 中，什么东西都会有一个 .opacity 或是 .alpha 的属性。在 Flutter 中，你需要给 widget 包裹一个 Opacity widget 来做到这一点。 我怎么创建自定义的 widgets？在 iOS 中，你编写 UIView 的子类，或使用已经存在的 view 来重载并实现方法，以达到特定的功能。在 Flutter 中，你会组合（composing）多个小的 widgets 来构建一个自定义的 widget（而不是扩展它）。 举个例子，如果你要构建一个 CustomButton ，并在构造器中传入它的 label？那就组合 RaisedButton 和 label，而不是扩展 RaisedButton。 12345678910class CustomButton extends StatelessWidget { final String label; CustomButton(this.label); @override Widget build(BuildContext context) { return RaisedButton(onPressed: () {}, child: Text(label)); }} 然后就像你使用其他任何 Flutter 的 widget 一样，使用你的 CustomButton： 123456@overrideWidget build(BuildContext context) { return Center( child: CustomButton(&quot;Hello&quot;), );} 导航我怎么在不同页面之间跳转？在 iOS 中，你可以使用管理了 view controller 栈的 UINavigationController 来在不同的 view controller 之间跳转。 Flutter 也有类似的实现，使用了 Navigator 和 Routes。一个路由是 App 中“屏幕”或“页面”的抽象，而一个 Navigator 是管理多个路由的 widget 。你可以粗略地把一个路由对应到一个 UIViewController。Navigator 的工作原理和 iOS 中 UINavigationController 非常相似，当你想跳转到新页面或者从新页面返回时，它可以 push() 和 pop() 路由。 在页面之间跳转，你有一对选择： 具体指定一个由路由名构成的 Map。（MaterialApp） 直接跳转到一个路由。（WidgetApp） 下面是构建一个 Map 的例子： 12345678910void main() { runApp(MaterialApp( home: MyAppHome(), // becomes the route named '/' routes: &lt;String, WidgetBuilder&gt; { '/a': (BuildContext context) =&gt; MyPage(title: 'page A'), '/b': (BuildContext context) =&gt; MyPage(title: 'page B'), '/c': (BuildContext context) =&gt; MyPage(title: 'page C'), }, ));} 通过把路由的名字 push 给一个 Navigator 来跳转： 1Navigator.of(context).pushNamed('/b'); Navigator 类不仅用来处理 Flutter 中的路由，还被用来获取你刚 push 到栈中的路由返回的结果。通过 await push() 返回的 Future 来达到这点。 举个例子，要跳转到“位置”路由来让用户选择一个地点，你可能要这么做： 1Map coordinates = await Navigator.of(context).pushNamed('/location'); 之后，在 location 路由中，一旦用户选择了地点，携带结果一起 pop() 出栈： 1Navigator.of(context).pop({&quot;lat&quot;:43.821757,&quot;long&quot;:-79.226392}); 我怎么跳转到其他 App？在 iOS 中，要跳转到其他 App，你需要一个特定的 URL Scheme。对系统级别的 App 来说，这个 scheme 取决于 App。为了在 Flutter 中实现这个功能，你可以创建一个原生平台的整合层，或者使用现有的 plugin，例如 url_launcher。 线程和异步我怎么编写异步的代码？Dart 是单线程执行模型，但是它支持 Isolate（一种让 Dart 代码运行在其他线程的方式）、事件循环和异步编程。除非你自己创建一个 Isolate ，否则你的 Dart 代码永远运行在 UI 线程，并由 event loop 驱动。Flutter 的 event loop 和 iOS 中的 main loop 相似——Looper 是附加在主线程上的。 Dart 的单线程模型并不意味着你写的代码一定是阻塞操作，从而卡住 UI。相反，使用 Dart 语言提供的异步工具，例如 async / await ，来实现异步操作。 举个例子，你可以使用 async / await 来让 Dart 帮你做一些繁重的工作，编写网络请求代码而不会挂起 UI： 1234567loadData() async { String dataURL = &quot;https://jsonplaceholder.typicode.com/posts&quot;; http.Response response = await http.get(dataURL); setState(() { widgets = json.decode(response.body); });} 一旦 await 到网络请求完成，通过调用 setState() 来更新 UI，这会触发 widget 子树的重建，并更新相关数据。 下面的例子展示了异步加载数据，并用 ListView 展示出来： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import 'dart:convert';import 'package:flutter/material.dart';import 'package:http/http.dart' as http;void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { List widgets = []; @override void initState() { super.initState(); loadData(); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: ListView.builder( itemCount: widgets.length, itemBuilder: (BuildContext context, int position) { return getRow(position); })); } Widget getRow(int i) { return Padding( padding: EdgeInsets.all(10.0), child: Text(&quot;Row ${widgets[i][&quot;title&quot;]}&quot;) ); } loadData() async { String dataURL = &quot;https://jsonplaceholder.typicode.com/posts&quot;; http.Response response = await http.get(dataURL); setState(() { widgets = json.decode(response.body); }); }} 更多关于在后台工作的信息，以及 Flutter 和 iOS 的区别，请参考下一章节。 你是怎么把工作放到后台线程的？由于 Flutter 是单线程并且跑着一个 event loop 的（就像 Node.js 那样），你不必为线程管理或是开启后台线程而操心。如果你正在做 I/O 操作，如访问磁盘或网络请求，安全地使用 async / await 就完事了。如果，在另外的情况下，你需要做让 CPU 保持繁忙的计算密集型任务，你需要使用 Isolate 来避免阻塞 event loop。 对于 I/O 操作，把方法声明为 async 方法，并且 await 方法里需要长期运行的任务： 1234567loadData() async { String dataURL = &quot;https://jsonplaceholder.typicode.com/posts&quot;; http.Response response = await http.get(dataURL); setState(() { widgets = json.decode(response.body); });} 这就是对诸如网络请求或数据库访问等 I/O 操作的典型做法。 然而，有时候你需要处理大量的数据，这会导致你的 UI 挂起。在 Flutter 中，使用 Isolate 来发挥多核心 CPU 的优势来处理那些长期运行或是计算密集型的任务。 Isolates 是分离的运行线程，并且不和主线程的内存堆共享内存。这意味着你不能访问主线程中的变量，或者使用 setState() 来更新 UI。正如它们的名字一样，Isolates 不能共享内存。 下面的例子展示了一个简单的 isolate，是如何把数据返回给主线程来更新 UI 的： 1234567891011121314151617181920212223242526272829303132333435363738loadData() async { ReceivePort receivePort = ReceivePort(); await Isolate.spawn(dataLoader, receivePort.sendPort); // The 'echo' isolate sends its SendPort as the first message SendPort sendPort = await receivePort.first; List msg = await sendReceive(sendPort, &quot;https://jsonplaceholder.typicode.com/posts&quot;); setState(() { widgets = msg; });}// The entry point for the isolatestatic dataLoader(SendPort sendPort) async { // Open the ReceivePort for incoming messages. ReceivePort port = ReceivePort(); // Notify any other isolates what port this isolate listens to. sendPort.send(port.sendPort); await for (var msg in port) { String data = msg[0]; SendPort replyTo = msg[1]; String dataURL = data; http.Response response = await http.get(dataURL); // Lots of JSON to parse replyTo.send(json.decode(response.body)); }}Future sendReceive(SendPort port, msg) { ReceivePort response = ReceivePort(); port.send([msg, response.sendPort]); return response.first;} 这里，dataLoader() 是一个运行于自己独立执行线程上的 Isolate。在 isolate 里，你可以执行 CPU 密集型任务（例如解析一个庞大的 json），或是计算密集型的数学操作，如加密或信号处理等。 你可以运行下面的完整例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118import 'dart:convert';import 'package:flutter/material.dart';import 'package:http/http.dart' as http;import 'dart:async';import 'dart:isolate';void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { List widgets = []; @override void initState() { super.initState(); loadData(); } showLoadingDialog() { if (widgets.length == 0) { return true; } return false; } getBody() { if (showLoadingDialog()) { return getProgressDialog(); } else { return getListView(); } } getProgressDialog() { return Center(child: CircularProgressIndicator()); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: getBody()); } ListView getListView() =&gt; ListView.builder( itemCount: widgets.length, itemBuilder: (BuildContext context, int position) { return getRow(position); }); Widget getRow(int i) { return Padding(padding: EdgeInsets.all(10.0), child: Text(&quot;Row ${widgets[i][&quot;title&quot;]}&quot;)); } loadData() async { ReceivePort receivePort = ReceivePort(); await Isolate.spawn(dataLoader, receivePort.sendPort); // The 'echo' isolate sends its SendPort as the first message SendPort sendPort = await receivePort.first; List msg = await sendReceive(sendPort, &quot;https://jsonplaceholder.typicode.com/posts&quot;); setState(() { widgets = msg; }); }// the entry point for the isolate static dataLoader(SendPort sendPort) async { // Open the ReceivePort for incoming messages. ReceivePort port = ReceivePort(); // Notify any other isolates what port this isolate listens to. sendPort.send(port.sendPort); await for (var msg in port) { String data = msg[0]; SendPort replyTo = msg[1]; String dataURL = data; http.Response response = await http.get(dataURL); // Lots of JSON to parse replyTo.send(json.decode(response.body)); } } Future sendReceive(SendPort port, msg) { ReceivePort response = ReceivePort(); port.send([msg, response.sendPort]); return response.first; }} 我怎么发起网络请求？在 Flutter 中，使用流行的 http package 做网络请求非常简单。它把你可能需要自己做的网络请求操作抽象了出来，让发起请求变得简单。 要使用 http 包，在 pubspec.yaml 中把它添加为依赖： 123dependencies: ... http: ^0.11.3+16 发起网络请求，在 http.get() 这个 async 方法中使用 await ： 12345678910111213import 'dart:convert';import 'package:flutter/material.dart';import 'package:http/http.dart' as http;[...] loadData() async { String dataURL = &quot;https://jsonplaceholder.typicode.com/posts&quot;; http.Response response = await http.get(dataURL); setState(() { widgets = json.decode(response.body); }); }} 我怎么展示一个长时间运行的任务的进度？在 iOS 中，在后台运行耗时任务时你会使用 UIProgressView。 在 Flutter 中，使用一个 ProgressIndicator widget。通过一个布尔 flag 来控制是否展示进度。在任务开始时，告诉 Flutter 更新状态，并在结束后隐去。 在下面的例子中，build 函数被拆分成三个函数。如果 showLoadingDialog() 是 true （当 widgets.length == 0 时），则渲染 ProgressIndicator。否则，当数据从网络请求中返回时，渲染 ListView 。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import 'dart:convert';import 'package:flutter/material.dart';import 'package:http/http.dart' as http;void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { List widgets = []; @override void initState() { super.initState(); loadData(); } showLoadingDialog() { return widgets.length == 0; } getBody() { if (showLoadingDialog()) { return getProgressDialog(); } else { return getListView(); } } getProgressDialog() { return Center(child: CircularProgressIndicator()); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: getBody()); } ListView getListView() =&gt; ListView.builder( itemCount: widgets.length, itemBuilder: (BuildContext context, int position) { return getRow(position); }); Widget getRow(int i) { return Padding(padding: EdgeInsets.all(10.0), child: Text(&quot;Row ${widgets[i][&quot;title&quot;]}&quot;)); } loadData() async { String dataURL = &quot;https://jsonplaceholder.typicode.com/posts&quot;; http.Response response = await http.get(dataURL); setState(() { widgets = json.decode(response.body); }); }} 工程结构、本地化、依赖和资源我怎么在 Flutter 中引入 image assets？多分辨率怎么办？iOS 把 images 和 assets 作为不同的东西，而 Flutter 中只有 assets。被放到 iOS 中 Images.xcasset 文件夹下的资源在 Flutter 中被放到了 assets 文件夹中。assets 可以是任意类型的文件，而不仅仅是图片。例如，你可以把 json 文件放置到 my-assets 文件夹中。 1my-assets/data.json 在 pubspec.yaml 文件中声明 assets： 12assets: - my-assets/data.json 然后在代码中使用 AssetBundle 来访问它： 123456import 'dart:async' show Future;import 'package:flutter/services.dart' show rootBundle;Future&lt;String&gt; loadAsset() async { return await rootBundle.loadString('my-assets/data.json');} 对于图片，Flutter 像 iOS 一样，遵循了一个简单的基于像素密度的格式。Image assets 可能是 1.0x 2.0x 3.0x 或是其他的任何倍数。这些所谓的 devicePixelRatio 传达了物理像素到单个逻辑像素的比率。 Assets 可以被放置到任何属性文件夹中——Flutter 并没有预先定义的文件结构。在 pubspec.yaml 文件中声明 assets （和位置），然后 Flutter 会把他们识别出来。 举个例子，要把一个叫 my_icon.png 的图片放到 Flutter 工程中，你可能想要把存储它的文件夹叫做 images。把基础图片（1.0x）放置到 images 文件夹中，并把其他变体放置在子文件夹中，并接上合适的比例系数： 123images/my_icon.png // Base: 1.0x imageimages/2.0x/my_icon.png // 2.0x imageimages/3.0x/my_icon.png // 3.0x image 接着，在 pubspec.yaml 文件夹中声明这些图片： 12assets: - images/my_icon.jpeg 你可以用 AssetImage 来访问这些图片： 1return AssetImage(&quot;images/a_dot_burr.jpeg&quot;); 或者在 Image widget 中直接使用： 1234@overrideWidget build(BuildContext context) { return Image.asset(&quot;images/my_image.png&quot;);} 更多细节，参见 Adding Assets and Images in Flutter。 我在哪里放置字符串？我怎么做本地化？不像 iOS 拥有一个 Localizable.strings 文件，Flutter 目前并没有一个用于处理字符串的系统。目前，最佳实践是把你的文本拷贝到静态区，并在这里访问。例如： 123class Strings { static String welcomeMessage = &quot;Welcome To Flutter&quot;;} 并且这样访问你的字符串： 1Text(Strings.welcomeMessage) 默认情况下，Flutter 只支持美式英语字符串。如果你要支持其他语言，请引入 flutter_localizations 包。你可能也要引入 intl 包来支持其他的 i10n 机制，比如日期/时间格式化。 12345dependencies: # ... flutter_localizations: sdk: flutter intl: &quot;^0.15.6&quot; 要使用 flutter_localizations 包，在 app widget 中指 localizationsDelegates 和 supportedLocales。 123456789101112131415import 'package:flutter_localizations/flutter_localizations.dart';MaterialApp( localizationsDelegates: [ // Add app-specific localization delegate[s] here GlobalMaterialLocalizations.delegate, GlobalWidgetsLocalizations.delegate, ], supportedLocales: [ const Locale('en', 'US'), // English const Locale('he', 'IL'), // Hebrew // ... other locales the app supports ], // ...) 这些代理包括了实际的本地化值，并且 supportedLocales 定义了 App 支持哪些地区。上面的例子使用了一个 MaterialApp ，所以它既有 GlobalWidgetsLocalizations 用于基础 widgets，也有 MaterialWidgetsLocalizations 用于 Material wigets 的本地化。如果你使用 WidgetsApp ，则无需包括后者。注意，这两个代理虽然包括了“默认”值，但如果你想让你的 App 本地化，你仍需要提供一或多个代理作为你的 App 本地化副本。 当初始化时，WidgetsApp 或 MaterialApp 会使用你指定的代理为你创建一个 Localizations widget。Localizations widget 可以随时从当前上下文中访问设备的地点，或者使用 Window.locale。 要访问本地化文件，使用 Localizations.of() 方法来访问提供代理的特定本地化类。如需翻译，使用 intl_translation 包来取出翻译副本到 arb 文件中。把它们引入 App 中，并用 intl 来使用它们。 更多 Flutter 中国际化和本地化的细节，请访问 internationalization guide ，那里有不使用 intl 包的示例代码。 注意，在 Flutter 1.0 beta 2 之前，在 Flutter 中定义的 assets 不能在原生一侧被访问。原生定义的资源在 Flutter 中也不可用，因为它们在独立的文件夹中。 Cocoapods 相当于什么？我该如何添加依赖？在 iOS 中，你把依赖添加到 Podfile 中。Flutter 使用 Dart 构建系统和 Pub 包管理器来处理依赖。这些工具将本机 Android 和 iOS 包装应用程序的构建委派给相应的构建系统。 如果你的 Flutter 工程中的 iOS 文件夹中拥有 Podfile，请仅在你为每个平台集成时使用它。总体来说，使用 pubspec.yaml 来在 Flutter 中声明外部依赖。一个可以找到优秀 Flutter 包的地方是 Pub。 ViewControllersViewController 相当于 Flutter 中的什么？在 iOS 中，一个 ViewController 代表了用户界面的一部分，最常用于一个屏幕，或是其中一部分。它们被组合在一起用于构建复杂的用户界面，并帮助你拆分 App 的 UI。在 Flutter 中，这一任务回落到了 widgets 中。就像在界面导航部分提到的一样，一个屏幕也是被 widgets 来表示的，因为“万物皆 widget！”。使用 Navigator 在 Route 之间跳转，或者渲染相同数据的不同状态。 我该怎么监听 iOS 中的生命周期事件？在 iOS 中，你可以重写 ViewController 中的方法来补货它的视图的生命周期，或者在 AppDelegate 中注册生命周期的回调函数。在 Flutter 中没有这两个概念，但你可以通过 hook WidgetsBinding 观察者来监听生命周期事件，并监听 didChangeAppLifecycleState() 的变化事件。 可观察的生命周期事件有： inactive - 应用处于不活跃的状态，并且不会接受用户的输入。这个事件仅工作在 iOS 平台，在 Android 上没有等价的事件。 paused - 应用暂时对用户不可见，虽然不接受用户输入，但是是在后台运行的。 resumed - 应用可见，也响应用户的输入。 suspending - 应用暂时被挂起，在 iOS 上没有这一事件。 更多关于这些状态的细节和含义，请参见 AppLifecycleStatus documentation 。 布局UITableView 和 UICollectionView 相当于 Flutter 中的什么？在 iOS 中，你可能用 UITableView 或 UICollectionView 来展示一个列表。在 Flutter 中，你可以用 ListView 来达到相似的实现。在 iOS 中，你通过代理方法来确定行数，每一个 index path 的单元格，以及单元格的尺寸。 由于 Flutter 中 widget 的不可变特性，你需要向 ListView 传递一个 widget 列表，Flutter 会确保滚动是快速且流畅的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import 'package:flutter/material.dart';void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: ListView(children: _getListData()), ); } _getListData() { List&lt;Widget&gt; widgets = []; for (int i = 0; i &lt; 100; i++) { widgets.add(Padding(padding: EdgeInsets.all(10.0), child: Text(&quot;Row $i&quot;))); } return widgets; }} 我怎么知道列表的哪个元素被点击了？iOS 中，你通过 tableView:didSelectRowAtIndexPath: 代理方法来实现。在 Flutter 中，使用传递进来的 widget 的 touch handle： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import 'package:flutter/material.dart';void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: ListView(children: _getListData()), ); } _getListData() { List&lt;Widget&gt; widgets = []; for (int i = 0; i &lt; 100; i++) { widgets.add(GestureDetector( child: Padding( padding: EdgeInsets.all(10.0), child: Text(&quot;Row $i&quot;), ), onTap: () { print('row tapped'); }, )); } return widgets; }} 我怎么动态地更新 ListView？在 iOS 中，你改变列表的数据，并通过 reloadData() 方法来通知 table 或是 collection view。 在 Flutter 中，如果你想通过 setState() 方法来更新 widget 列表，你会很快发现你的数据展示并没有变化。这是因为当 setState() 被调用时，Flutter 渲染引擎会去检查 widget 树来查看是否有什么地方被改变了。当它得到你的 ListView 时，它会使用一个 == 判断，并且发现两个 ListView 是相同的。没有什么东西是变了的，因此更新不是必须的。 一个更新 ListView 的简单方法是，在 setState() 中创建一个新的 list，并把旧 list 的数据拷贝给新的 list。虽然这样很简单，但当数据集很大时，并不推荐这样做： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import 'package:flutter/material.dart';void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { List widgets = []; @override void initState() { super.initState(); for (int i = 0; i &lt; 100; i++) { widgets.add(getRow(i)); } } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: ListView(children: widgets), ); } Widget getRow(int i) { return GestureDetector( child: Padding( padding: EdgeInsets.all(10.0), child: Text(&quot;Row $i&quot;), ), onTap: () { setState(() { widgets = List.from(widgets); widgets.add(getRow(widgets.length + 1)); print('row $i'); }); }, ); }} 一个推荐的、高效的且有效的做法是，使用 ListView.Builder 来构建列表。这个方法在你想要构建动态列表，或是列表拥有大量数据时会非常好用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import 'package:flutter/material.dart';void main() { runApp(SampleApp());}class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { List widgets = []; @override void initState() { super.initState(); for (int i = 0; i &lt; 100; i++) { widgets.add(getRow(i)); } } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: ListView.builder( itemCount: widgets.length, itemBuilder: (BuildContext context, int position) { return getRow(position); }, ), ); } Widget getRow(int i) { return GestureDetector( child: Padding( padding: EdgeInsets.all(10.0), child: Text(&quot;Row $i&quot;), ), onTap: () { setState(() { widgets.add(getRow(widgets.length + 1)); print('row $i'); }); }, ); }} 与创建一个 “ListView” 不同，创建一个 ListView.builder 接受两个主要参数：列表的初始长度，和一个 ItemBuilder 方法。 ItemBuilder 方法和 cellForItemAt 代理方法非常类似，它接受一个位置，并且返回在这个位置上你希望渲染的 cell。 最后，也是最重要的，注意 onTap() 函数里并没有重新创建一个 list，而是 .add 了一个 widget。 ScrollView 相当于 Flutter 里的什么？在 iOS 中，你给 view 包裹上 ScrollView 来允许用户在需要时滚动你的内容。 在 Flutter 中，最简单的方法是使用 ListView widget。它表现得既和 iOS 中的 ScrollView 一致，也能和 TableView 一致，因为你可以给它的 widget 做垂直排布： 1234567891011@overrideWidget build(BuildContext context) { return ListView( children: &lt;Widget&gt;[ Text('Row One'), Text('Row Two'), Text('Row Three'), Text('Row Four'), ], );} 更多关于在 Flutter 总如何排布 widget 的文档，请参阅 layout tutorial。 手势检测及触摸事件处理我怎么给 Flutter 的 widget 添加一个点击监听者？在 iOS 中，你给一个 view 添加 GestureRecognizer 来处理点击事件。在 Flutter 中，有两种方法来添加点击监听者： 如果 widget 本身支持事件监测，直接传递给它一个函数，并在这个函数里实现响应方法。例如，RaisedButton widget 拥有一个 RaisedButton 参数： 123456789@overrideWidget build(BuildContext context) { return RaisedButton( onPressed: () { print(&quot;click&quot;); }, child: Text(&quot;Button&quot;), );} 如果 widget 本身不支持事件监测，则在外面包裹一个 GestureDetector，并给它的 onTap 属性传递一个函数： 1234567891011121314151617class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( body: Center( child: GestureDetector( child: FlutterLogo( size: 200.0, ), onTap: () { print(&quot;tap&quot;); }, ), ), ); }} 我怎么处理 widget 上的其他手势？使用 GestureDetector 你可以监听更广阔范围内的手势，比如： Tapping onTapDown — 在特定位置轻触手势接触了屏幕。 onTapUp — 在特定位置产生了一个轻触手势，并停止接触屏幕。 onTap — 产生了一个轻触手势。 onTapCancel — 触发了 onTapDown 但没能触发 tap。 Double tapping onDoubleTap — 用户在同一个位置快速点击了两下屏幕。 Long pressing onLongPress — 用户在同一个位置长时间接触屏幕。 Vertical dragging onVerticalDragStart — 接触了屏幕，并且可能会垂直移动。 onVerticalDragUpdate — 接触了屏幕，并继续在垂直方向移动。 onVerticalDragEnd — 之前接触了屏幕并垂直移动，并在停止接触屏幕前以某个垂直的速度移动。 Horizontal dragging onHorizontalDragStart onHorizontalDragUpdate onHorizontalDragEnd 下面这个例子展示了一个 GestureDetector 是如何在双击时旋转 Flutter 的 logo 的： 1234567891011121314151617181920212223242526272829303132AnimationController controller;CurvedAnimation curve;@overridevoid initState() { controller = AnimationController(duration: const Duration(milliseconds: 2000), vsync: this); curve = CurvedAnimation(parent: controller, curve: Curves.easeIn);}class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return Scaffold( body: Center( child: GestureDetector( child: RotationTransition( turns: curve, child: FlutterLogo( size: 200.0, )), onDoubleTap: () { if (controller.isCompleted) { controller.reverse(); } else { controller.forward(); } }, ), ), ); }} 主题和文字我怎么给 App 设置主题？Flutter 实现了一套漂亮的 MD 组件，并且开箱可用。它接管了一大堆你需要的样式和主题。 为了充分发挥你的 App 中 MD 组件的优势，声明一个顶级 widget，MaterialApp，用作你的 App 入口。MaterialApp 是一个便利组件，包含了许多 App 通常需要的 MD 风格组件。它通过一个 WidgetsApp 添加了 MD 功能来实现。 但是 Flutter 足够地灵活和富有表现力来实现任何其他的设计语言。在 iOS 上，你可以用 Cupertino library 来制作遵守 Human Interface Guidelines 的界面。查看这些 widget 的集合，请参阅 Cupertino widgets gallery。 你也可以在你的 App 中使用 WidgetApp，它提供了许多相似的功能，但不如 MaterialApp 那样强大。 对任何子组件定义颜色和样式，可以给 MaterialApp widget 传递一个 ThemeData 对象。举个例子，在下面的代码中，primary swatch 被设置为蓝色，并且文字的选中颜色是红色： 12345678910111213class SampleApp extends StatelessWidget { @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, textSelectionColor: Colors.red ), home: SampleAppPage(), ); }} 我怎么给 Text widget 设置自定义字体？在 iOS 中，你在项目中引入任意的 ttf 文件，并在 info.plist 中设置引用。在 Flutter 中，在文件夹中放置字体文件，并在 pubspec.yaml 中引用它，就像添加图片那样。 12345fonts: - family: MyCustomFont fonts: - asset: fonts/MyCustomFont.ttf - style: italic 然后在你的 Text widget 中指定字体： 1234567891011121314@overrideWidget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: Center( child: Text( 'This is a custom font text', style: TextStyle(fontFamily: 'MyCustomFont'), ), ), );} 我怎么给我的 Text widget 设置样式？除了字体以外，你也可以给 Text widget 的样式元素设置自定义值。Text widget 接受一个 TextStyle 对象，你可以指定许多参数，比如： color decoration decorationColor decorationStyle fontFamily fontSize fontStyle fontWeight hashCode height inherit letterSpacing textBaseline wordSpacing 表单输入Flutter 中表单怎么工作？我怎么拿到用户的输入？我们已经提到 Flutter 使用不可变的 widget，并且状态是分离的，你可能会好奇在这种情境下怎么处理用户的输入。在 iOS 中，你经常在需要提交数据时查询组件当前的状态或动作，但这在 Flutter 中是怎么工作的呢？ 在表单处理的实践中，就像在 Flutter 中任何其他的地方一样，要通过特定的 widgets。如果你有一个 TextField 或是 TextFormField，你可以通过 TextEditingController 来获得用户输入： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class _MyFormState extends State&lt;MyForm&gt; { // Create a text controller and use it to retrieve the current value. // of the TextField! final myController = TextEditingController(); @override void dispose() { // Clean up the controller when disposing of the Widget. myController.dispose(); super.dispose(); } @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text('Retrieve Text Input'), ), body: Padding( padding: const EdgeInsets.all(16.0), child: TextField( controller: myController, ), ), floatingActionButton: FloatingActionButton( // When the user presses the button, show an alert dialog with the // text the user has typed into our text field. onPressed: () { return showDialog( context: context, builder: (context) { return AlertDialog( // Retrieve the text the user has typed in using our // TextEditingController content: Text(myController.text), ); }, ); }, tooltip: 'Show me the value!', child: Icon(Icons.text_fields), ), ); }} 你可以在这里获得更多信息，或是完整的代码列表： Retrieve the value of a text field，来自 Flutter Cookbook 。 Text field 中的 placeholder 相当于什么？在 Flutter 中，你可以轻易地通过向 Text widget 的装饰构造器参数重传递 InputDecoration 来展示“小提示”，或是占位符文字： 12345body: Center( child: TextField( decoration: InputDecoration(hintText: &quot;This is a hint&quot;), ),) 我怎么展示验证错误信息？就像展示“小提示”一样，向 Text widget 的装饰器构造器参数中传递一个 InputDecoration。 然而，你并不想在一开始就显示错误信息。相反，当用户输入了验证信息，更新状态，并传入一个新的 InputDecoration 对象： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class SampleApp extends StatelessWidget { // This widget is the root of your application. @override Widget build(BuildContext context) { return MaterialApp( title: 'Sample App', theme: ThemeData( primarySwatch: Colors.blue, ), home: SampleAppPage(), ); }}class SampleAppPage extends StatefulWidget { SampleAppPage({Key key}) : super(key: key); @override _SampleAppPageState createState() =&gt; _SampleAppPageState();}class _SampleAppPageState extends State&lt;SampleAppPage&gt; { String _errorText; @override Widget build(BuildContext context) { return Scaffold( appBar: AppBar( title: Text(&quot;Sample App&quot;), ), body: Center( child: TextField( onSubmitted: (String text) { setState(() { if (!isEmail(text)) { _errorText = 'Error: This is not an email'; } else { _errorText = null; } }); }, decoration: InputDecoration(hintText: &quot;This is a hint&quot;, errorText: _getErrorText()), ), ), ); } _getErrorText() { return _errorText; } bool isEmail(String em) { String emailRegexp = r'^(([^&lt;&gt;()[\\]\\\\.,;:\\s@\\&quot;]+(\\.[^&lt;&gt;()[\\]\\\\.,;:\\s@\\&quot;]+)*)|(\\&quot;.+\\&quot;))@((\\[[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\])|(([a-zA-Z\\-0-9]+\\.)+[a-zA-Z]{2,}))$'; RegExp regExp = RegExp(p); return regExp.hasMatch(em); }} 和硬件、第三方服务以及平台交互我怎么和平台，以及平台的原生代码交互？Flutter 的代码并不直接在平台之下运行，相反，Dart 代码构建的 Flutter 应用在设备上以原生的方式运行，却“侧步躲开了”平台提供的 SDK。这意味着，例如，你在 Dart 中发起一个网络请求，它就直接在 Dart 的上下文中运行。你并不会用上平常在 iOS 或 Android 上使用的原生 API。你的 Flutter 程序仍然被原生平台的 ViewController 管理作一个 view，但是你并不会直接访问 ViewController 自身，或是原生框架。 但这并不意味着 Flutter 不能和原生 API，或任何你编写的原生代码交互。Flutter 提供了 platform channels ，来和管理你的 Flutter view 的 ViewController 通信和交互数据。平台管道本质上是一个异步通信机制，桥接了 Dart 代码和宿主 ViewController，以及它运行于的 iOS 框架。你可以用平台管道来执行一个原生的函数，或者是从设备的传感器中获取数据。 除了直接使用平台管道之外，你还可以使用一系列预先制作好的 plugins。例如，你可以直接使用插件来访问相机胶卷或是设备的摄像头，而不必编写你自己的集成层代码。你可以在 Pub 上找到插件，这是一个 Dart 和 Flutter 的开源包仓库。其中一些包可能会支持集成 iOS 或 Android，或两者均可。 如果你在 Pub 上找不到符合你需求的插件，你可以自己编写 ，并且发布在 Pub 上。 我怎么访问 GPS 传感器？使用 location 社区插件。 我怎么访问摄像头？image_picker 在访问摄像头时非常常用。 我怎么登录 Facebook？登录 Facebook 可以使用 flutter_facebook_login 社区插件。 我怎么使用 Firebase 特性？大多数 Firebase 特性被 first party plugins 包含了。这些第一方插件由 Flutter 团队维护： firebase_admob for Firebase AdMob firebase_analytics for Firebase Analytics firebase_auth for Firebase Auth firebase_core for Firebase’s Core package firebase_database for Firebase RTDB firebase_storage for Firebase Cloud Storage firebase_messaging for Firebase Messaging (FCM) cloud_firestore for Firebase Cloud Firestore 你也可以在 Pub 上找到 Firebase 的第三方插件。 我怎创建自己的原生集成层？如果有一些 Flutter 和社区插件遗漏的平台相关的特性，可以根据 developing packages and plugins 页面构建自己的插件。 Flutter 的插件结构，简要来说，就像 Android 中的 Event bus。你发送一个消息，并让接受者处理并反馈结果给你。在这种情况下，接受者就是在 Android 或 iOS 上的原生代码。 数据库和本地存储我怎么在 Flutter 中访问 UserDefaults？在 iOS 中，你可以使用属性列表来存储键值对的集合，即我们熟悉的 UserDefaults。 在 Flutter 中，可以使用 Shared Preferences plugin 来达到相似的功能。它包裹了 UserDefaluts 以及 Android 上等价的 SharedPreferences 的功能。 CoreData 相当于 Flutter 中的什么？在 iOS 中，你通过 CoreData 来存储结构化的数据。这是一个 SQL 数据库的上层封装，让查询和关联模型变得更加简单。 在 Flutter 中，使用 SQFlite 插件来实现这个功能。 通知我怎么推送通知？在 iOS 中，你需要向 developer portal 中注册来允许推送通知。 在 Flutter 中，使用 firebase_messaging 插件来实现这一功能。 更多使用 Firebase Cloud Messaging API 的信息，请参阅 firebase_messaging 插件文档。 此文档由 Luyuan Wang 原创翻译。2018 - 07 - 11","link":"/2018/07/11/Flutter-for-iOS-dev-%E7%BF%BB%E8%AF%91/"},{"title":"一个小坑-以空格分割字符串","text":"Java 以空格分割字符串刷到一道弱智级别的算法题，5 分钟写完信心满满的提交上去，却提示有两个 case 错误。 仔细检查了几百遍自己的代码，感觉什么问题都没有。搞了很久一直过不了，后来把以空格分割字符串的写法从： 1String[] list = str.split(&quot; &quot;); //以空格进行分割 改成了： 1String[] list = str.split(&quot;\\\\s+&quot;); //正则表达式，以任意长空白符进行分割 竟然一下就过了……而题目明明说的输入格式是以空格进行分割啊！之前的写法理论上应该没问题啊！这不科学！ 这个问题困扰了我将近一个小时，虽然是个小问题，且到现在也不清楚为什么会这样……但还是记录一下吧，以后再也不敢直接用空格分割了……","link":"/2018/02/15/Java%E4%BB%A5%E7%A9%BA%E6%A0%BC%E5%88%86%E5%89%B2%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"title":"C语言extern关键字","text":"C语言extern关键字从刚上大学开始学习 C 语言的时候，就被老师告诫不要大量使用 extern ，自然也就没把这个关键字放在心上。结果到现在还不是很熟悉 extern 的用法，说来有点惭愧…… 一个例子先来看两个程序： 12345678910111213#include &lt;stdio.h&gt;extern int x;int x = 10;void foo() { printf(&quot;%d&quot;, x); }int main() { int x; //⚠️ x++; foo();} 12345678910111213#include &lt;stdio.h&gt;extern int x;int x = 10;void foo() { printf(&quot;%d&quot;, x);}int main() { extern int x; //⚠️ x++; foo();} 这两段程序唯一的区别就是 main 函数的第一行，有没有 extern 关键字。请问，这两个程序的输出分别是多少呢？ 答案是，第一个程序输出 10，第二个程序输出 11。 extern 关键字把一个 symbol 声明成外部的。它告诉编译器：这个符号（比如 x）你没有见过，但是不要紧，它在别的地方定义了。你只管放心地编译，链接器会找到它的。也就是说， 1extern int x; 只是一个 declaration，而不是 definition。而 1int x; 既 declare 了 x，又 define 了 x。而在链接的时候，所有标记了 extern 的同名变量，都会被链接到同一个变量上。在上面的两端代码中，如果没有 extern 修饰 x，那么就是在 main 函数中定义了一个新的局部变量 x，并对它加一。跳转到 foo 中，只有全局变量 x 才是可见的，而刚刚的局部变量对全局变量没有影响，故而打印出 10 。第二段程序，因为添加了 extern ，所以在 main 函数中的 int x 不是 definition ，而是 declaration ，被链接器链接到全局变量 x 上。所以执行加一操作，会改变全局变量的值，所以打印出 11 。在第二个程序中，所有出现的 x 都指向同一个变量。 第二个例子我们有三个文件： 123// test.hextern int x;int x = 10; 123456// test1.c#include &quot;test.h&quot;int main() { x = 5; return 0;} 123// test2.c#include &quot;test.h&quot;void foo() { x = 6; } 请问，如果执行 gcc test1.c test2.c 编译这个程序，会发生什么？ 答案是，linker 会报错： 1ld: 1 duplicate symbol for architecture x86_64 #include 引用的文件，会被 C 预处理器 （C PreProcessor, CPP）复制过来。也就是说，在这个程序中，x 被定义了两遍，且被声明成了外部的。刚刚说过，所有外部的同名变量都会被链接器链接到一起，指向同一个变量。那么这里，链接器就会发现有两个 x 的定义，那么该指向哪个呢？只好报错说有 duplicate symbol 。 那么，如果我们把 test.h 文件修改成这样呢？ 123// test.h// extern int x;int x = 10; 我们不声明 x 为外部变量。这样，当头文件被复制到 c 文件时，我们只是分别定义了两次全局变量，应该相安无事了吧？事实上，链接器还是会报同样的错误。因为，全局变量默认就是外部的，写不写 extern 都一样。类似的，函数默认也都是外部的，不用显示地写出 extern 。 那么，怎么才能让全局变量不是外部的呢？答案是 static 关键字。显示地把变量定义为静态的，变量的生命周期就会变成整个程序的生命周期（即使在函数里面定义也是如此），而可见性就只局限在了同一个文件中。所以，如果把 test.h 文件改成这样，就可以通过编译，生成可执行文件了： 12// test.hstatic int x = 10; 现在，虽然 x 被定义了两次，但是井水不犯河水。","link":"/2019/02/07/C%E8%AF%AD%E8%A8%80extern%E5%85%B3%E9%94%AE%E5%AD%97/"},{"title":"Linux下使用gperftools","text":"Linux 下使用 gperftools常用的性能分析工具有很多，比如 gprof，perf 等等。然而，它们似乎对 GCC 更友好。如果想要对 LLVM 编译出来的程序做分析，推荐 Google 的性能分析工具，Google gperftools。 凭借官方只言片语的解释，安装使用 gperftools 还是有点困难的： https://gperftools.github.io/gperftools/cpuprofile.html https://github.com/gperftools/gperftools 安装sudo apt-get install libunwind-dev sudo apt-get install google-perftools libgoogle-perftools-dev 推荐安装一款可视化软件，方便查看性能分析结果： sudo apt-get install kcachegrind 使用编写测试程序的时候，注意需要让程序有一定的运行时间。由于 gperftools 是通过采样来做分析的，如果程序太短很快就退出了，就不会有输出结果。 之后，在用 Clang 编译的时候，链接上 gperftools 的库： clang test.c -lprofiler -o test 这样，性能分析的代码就已经注入到程序里了。运行时，要指定输出文件路径： env CPUPROFILE=./test.prof ./test 这样，输出文件会存放在当前目录下的 test.prof 文件中。 可以通过 pprof 工具来查看： google-pprof -text test test.prof 如果要使用刚刚所说的可视化工具，要先把输出文件转换成该工具支持的类型： google-pprof --callgrind /usr/bin/python ./test.prof &gt; ./test.txt 然后再用 kcachegrind 工具打开： kcachegrind test.txt 截图如下： 当然，Google gproftools 是非常强大的工具，还有更多的功能值得探索。","link":"/2019/03/23/Linux%E4%B8%8B%E4%BD%BF%E7%94%A8gperftools/"},{"title":"LLVM循环优化","text":"LLVM 循环优化LLVM 是一个广为使用的编译器套件，也是苹果官方的编译器。LLVM 前端可以把高级代码转换成 LLVM 自身的中间代码（IR），而后端再把 IR 翻译为目标平台的机器码。而 LLVM 提供的优化器 opt 可以优化 IR 代码，并生成优化过的 IR 代码。在之前的博客中，我已经探索过使用 clang 来优化一个简单的程序。在那个简单的循环程序中，较为影响性能的就是 Loop Unrolling 优化。我也做出了一些性能测试。 但是，单纯的用 clang -O3 来分析 Loop Unrolling 的性能影响是不科学的。在一个较为复杂的程序中，会有很多处可以优化的地方。而如果想要对比某一种优化策略带来的效果，则最好只做这一种优化（控制变量）。比如，用下面的命令来做 Loop Unrolling 优化，则带来的副作用就少得多： 12opt -mem2reg -simplifycfg -loops -lcssa -loop-simplify -loop-rotate -loop-unroll -unroll-count=4 -unroll-allow-partial input.ll -S -o output.ll 编译 LLVM指定 LLVM opt 要运行的 pass 来控制优化种类没有想象中的那么直观，经常会得不到想要的结果。如果在输入命令的时候带上 -debug 或者 -debug-only=&lt;pass name&gt; 标签，就可以获得一些 debug 的信息，会非常有帮助。然而，直接下载安装的 LLVM 是默认关闭这个选项的。这就需要我们自己编译 LLVM，并在编译时指定打开 assertion -DLLVM_ENABLE_ASSERTIONS=On。 下载最新版本的 LLVM： git clone https://github.com/llvm/llvm-project.git clone 后，cd 进入 llvm-project 文件夹。 LLVM 不支持直接在工程文件夹下编译，需要我们自己新建一个构建文件夹： mkdir build cd build 然后开始生成编译所需的文件： cmake -G &lt;generator&gt; [options] ../llvm 多数开发者都会选择用 Ninja 来编译。所以，要先安装 Ninja。如果在 macOS 下，可以用 brew 来安装： brew install ninja 一个例子： 1cmake -G 'Ninja' -DLLVM_ENABLE_PROJECTS='clang;&lt;other build targets&gt;' -DCMAKE_INSTALL_PREFIX=&lt;your install path&gt; -DLLVM_ENABLE_ASSERTIONS=On 稍等一段时间后，就会生成所需要的文件。然后就可以用 Ninja 来编译了： ninja 编译花费的时间比较久，可能需要几个小时。编译完成之后，就可以用 Ninja 来安装了，安装地址就是之前指定的地址。 ninja install Ref: http://llvm.org/docs/GettingStarted.html#getting-started-quickly-a-summary Loop Interchange下面的代码可用来测试 Loop Interchange： 123456789101112#include &lt;stdio.h&gt;int main() { int i=0; int j=0; int a[333][222]; for (i=0; i &lt;222; i++) { for (j=0; j &lt;333; j++) { a[j][i] = a[j][i] + 970815; } } return 0;} 由于二维数组在内存中仍是线性排列，因此先在行内循环效率更优。这是因为行内元素的距离更近，符合空间局部性原理，缓存命中率会更高。在上面的程序中，先做了列内循环，所以可能会被 Loop Interchange 优化循环顺序。 生成 IR 代码，为下一步优化做准备： 1clang -O3 -mllvm -disable-llvm-optzns interchange.c -emit-llvm -S -o interchange.ll 这里用 O3 是因为，如果是 O0 的话，LLVM 就会阻止后面的优化器进行优化（可参见 LLVM 源码）。所以后面又先暂时禁止了 opt 直接自动优化。 之后开始使用 opt 进行优化。虽然 LLVM 的 pass 依赖会自动管理，但有些必要的准备工作还是不可避免的： 123opt -mem2reg interchange.ll -S -o interchange.llopt -loop-rotate interchange.ll -S -o interchange.llopt -loop-interchange interchange.ll -S -o opt.ll 这样就生成了 interchange.ll 和 opt.ll 两个 IR 代码文件。用 llc 来将他们转换成汇编代码： 12llc interchange.ll -o un.sllc opt.ll -o opt.s 在未优化的汇编代码中，可以看到循环和 C 语言中的一样，内层为 333 次，而外层为 222 次。 而在 Loop Interchange 之后，我们可以发现两个循环的顺序被颠倒了。 将汇编代码编译为可执行文件。为了让 gem5 模拟器运行，需要静态链接： 12clang opt.s -o interchange --staticclang un.s -o interchange_no --static 经过 gem5 模拟，优化前执行了 1837199000 个 tick，优化后是 1767821000 个 tick。可以发现优化后程序运行的时间变短了。之前提到过，interchange 可以提高 cache 的命中率。优化前的数据： 优化后： 我们可以看到 data cache 的 miss rate 确实下降了一点，好像不是很明显，但是，miss 次数确实是大幅下降了的。 Loop Unswitch下面的代码可以用来测试 Loop Unswitch： 12345678910111213int main() { int i=0, a[1024]; int w = 0; for (i = 0; i &lt; 1024; i++) { if (w == 999) { a[i] = 555; } else { a[i] = 666; } } return 0;} Loop Unswitch 可以将循环内的条件判断语句移到循环外部，从而在不影响运行结果的前提下节约不必要的判断语句。 123clang -O3 -mllvm -disable-llvm-optzns unswitch.c -emit-llvm -S -o unswitch.llopt -mem2reg unswitch.ll -S -o unswitch.llopt -loop-unswitch unswitch.ll -S -o opt.ll 未优化时的 IR 代码如下： 可以看到判断语句和 C 语言中的一致，在循环内部。而优化后： 原来的循环被拆成了两个独立的循环（判断语句在循环外）。我有时展示 IR 代码，有时展示汇编代码的原因是，有时 IR 代码更加易读，有时汇编代码更易读。但由于汇编代码时从 IR 代码翻译来的，所以本质上是一致的。 经 gem5 模拟，未优化时用了 101847000 个 tick，而优化后使用了 93526000 个 tick。程序耗时减少了。 Loop Reduce下面的代码可以用来测试 Loop Reduce： 123456789int main() { int a[1024]; int i=0; int c = 97; for (i=0; i&lt;1024; i++) { a[i] = i * c; } return 0;} 在 CPU 指令中，有的指令更加耗时。比较耗时的指令一般有 load, store, 以及乘除法等等。Loop Reduce 可以把一些较为耗时的代码转化为更快的指令。比如，这里的乘法就可以优化为累加。 12clang -O3 -mllvm -disable-llvm-optzns reduce.c -emit-llvm -S -o reduce.llopt -mem2reg -loop-reduce reduce.ll -S -o opt.ll 未优化时： 可以看大 IR 代码中使用了 mul 指令。这是比较耗时的。 而优化后： 可以看到 LLVM 把乘法转换成了加法。而加法操作就要快多了。 经过 gem5 模拟，未优化时消耗了 115056000 个 tick，而优化后只用了 98250000 个 tick。还是加快了许多的。 总结LLVM 还有很多循环优化选项，亦有 polly 循环优化器可以执行更多的优化操作。然而，直接选择优化级别进行优化较为简单，而想要具体指定优化 pass 就较为困难了。一开始我以为是有相关的依赖，但是经过发送邮件询问 LLVM 社区，有人回答 pass 依赖是自动被管理的。想要知道具体的步骤还是较为困难的，我目前也没有找到什么特别好的方法。所以虽然对一些其他的优化很感兴趣，但也没有机会尝试了。有点遗憾。","link":"/2019/04/27/LLVM%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96/"},{"title":"LoopUnrolling优化效果对比","text":"Loop Unrolling 优化效果对比循环是计算机程序中非常重要的结构。如果对循环加以优化，就可以大幅提高程序的运行速度。本文通过一段简单的小程序，对比了 Loop Unrolling 前后的性能差异。 什么是 Loop Unrolling简单来说，循环展开就是把循环中的内容复制多次，然后减少循环次数。这是一种牺牲程序占用空间换取执行时间的优化方法。Loop Unrolling 有利于指令级并行，也有利于 pipeline 调度。 指令级并行（multiple issue）是在同一时刻执行多条指令。这建立在 CPU 的结构”冗余”上。例如，如果我们有两个 ALU，我们就可以同时执行两个 ALU 运算操作。 Loop Unrolling 可以由编译器自动优化。 例子为了测试 Loop Unrolling，我编写了如下的代码： 12345678910111213#include &lt;stdio.h&gt;#include &lt;time.h&gt;int main(){ int array[1000000]; printf(&quot;tick: %ld\\n&quot;, clock()); for (int j=0; j&lt;100000; j++) { for (int i = 1; i &lt; 1000000; i++) { array[i] += 970815; } } return 0;} 可以想像，如果存在 Loop Unrolling，中间的加法运算就会被复制多次，而循环次数也对应减少。 使用 LLVM 进行编译，选择 O0 优化，即最低优化级别： clang -O0 -S -emit-llvm unrolling.c 部分汇编代码如下： 这里的代码不是真正的汇编代码，而是 LLVM 的中间语言（IR）。clang 作为 LLVM 的前端，负责解析 C 代码，之后 LLVM 会生成 IR 代码并作优化，最后由 IR 再翻译成平台相关的汇编代码。 这里 970815 （我的生日）是一个 magic number，通过这个数字我们可以迅速定位到循环的位置。可以看到，并没有什么稀奇之处，这个加法运算只出现了一次。 如果使用 O3，即最高级别优化： clang -O0 -S -emit-llvm unrolling.c 可以看到 IR 代码如下： 这里可以很明显的看到，相加运算被复制了很多很多次，即编译器做了 Loop Unrolling 优化。当然，真实的代码可能会和 IR 有所出入，因为在 IR 中，寄存器的数量是无限制的，而真正的 CPU 的寄存器数量很少，所以会有所变动。不过可以确定的是，在 LLVM O3 级别的优化下，确实产生了 Loop Unrolling 现象。 使用 gperftools 测试性能Linux 下有很多性能分析工具，这里我选择了可以配合 clang 使用的 Google gperftools。注意，gperftools 每隔 10ms 做一次采样，因此我设置的循环次数较大，这样才能有足够的时间来统计采样次数。而采样次数也就反映了程序的运行时间。 这张图中，纵坐标是 gperftools 的采样次数（与程序耗时成正比），前三组数据使用 O0 优化，而后三组数据使用 O3 优化。在 clang 中，即使是 O0 级别也是会做出一些基本的优化的。如果想要完全不优化，则需要自己更改 clang 的源代码。（逃 不过根据前面的 IR 代码可以知道，O0 是没有 Loop Unrolling 的。 通过这组数据可以看出，在有 Loop Unrolling 的情况下，性能的提升是显著的。虽然 O3 级别优化肯定也会对其他地方进行优化，但是在如此简单的情景下，可以假定对影响程序时间起主要作用的就是对循环作出的优化。 使用 gem5 模拟器分析在刚才的分析中，我是使用了 VMWare 的 Linux 虚拟机来做的测试。然而，这样的测试变量较多，如系统的负载在不同时刻不一致等。使用 CPU 模拟器，可以得到非常精确的结果。 Gem5 有两种运行模式，SE 和 FS。SE 是 system emulation 的缩写，即模拟了 system call，而并没有真实的操作系统。这是一种较低层次的虚拟化技术。SE 模式下可以运行一些简单的静态编译程序（Linux 格式）。所以，在编译完成后，我将可执行文件从 Linux 虚拟机拷贝回宿主 macOS 上，并交给 gem5 执行。为了静态链接，需要在编译时添加 --static 参数。 clang -O3 unrolling.c -o unrolling_3 --static 未优化时，消耗的 CPU tick 数为：43233500。优化后为：40620500。可以看到优化后性能有所提高。提升没有之前显著的原因是，我将循环次数减少了数万至数十万倍。这是因为 gem5 效率更低，在之前的循环数量下会消耗过长的时间进行仿真。 使用 gem5 仿真的命令是： build/X86/gem5.opt configs/turtorial/two-level.py 这里，使用 opt 模式 X86 架构的模拟器，而后一半是自行编写的 CPU 配置脚本。通过自定义配置脚本，可以指定 CPU 参数，cache 系统等。当然，gem5 本身也提供了一些现成的配置供我们使用。 运行完毕后，gem5 会在 m5out 文件夹下生成 stats.txt 文件展示统计信息。通过统计信息可以看到 cache 命中率等信息。 下面是优化后的缓存 miss rate： 下面是未优化的： 可以看到缓存 miss 比率在优化后反而升高了。这不能解释我们观察到的性能提升现象。（为什么 cache 反而命中率低了？我目前没有想到合理的解释） 使用现有的配置文件，gem5 可以可视化的展示 CPU pipeline。不过要知道，静态链接后程序会变得非常臃肿。而且，真实的汇编代码可读性很低，所以需要找到办法在完整的 pipeline 中找到我们感兴趣的循环部分。 为了定位循环的位置，首先阅读一下真实的汇编代码： 通过 magic number 970815 可以看到对应的 addl 指令位置。而这个立即数的 16 进制值为 imm = 0xED03F。 通过 objdump 工具可以反汇编出可执行文件的结构： objdump -d unrolling_3 &gt; obj.txt 输出的结果默认是打在控制台上的，但由于静态链接后程序体积非常大，我把输出结果重定向在 obj.txt 文件中，方便查看。 搜索 magic number 0xed03f 可以快速定位到位置。可以看到 address 是 0x400b5d 。由于这里是 SE 模式模拟，可以理解为程序在裸的 CPU 上运行，所以可以假象运行时的 PC 值就是这个地址。 使用 gem5 提供的 CPU 配置和可视化工具，可以检查 pipeline。 1build/X86/gem5.opt --debug-flags=O3PipeView --debug-start=1 --debug-file=trace.out configs/example/se.py --cpu-type=DerivO3CPU --caches -c /Users/wangluyuan/Desktop/COProject/test/unrolling_0 这里需要注意的是，官网教程中，向 se.py 传入的参数是 --cpu-type=detailed 。然而实际上 se.py 并不支持这个参数，可能是教程太过于陈旧了。需要传入的参数实际是 DerivO3CPU。 之后把输出结果格式进行转换： ./util/o3-pipeview.py -c 250 -o pipeview.out --color m5out/trace.out 最后打开： less -r pipeview.out 这里的颜色是通过逃逸字符实现的，所以一般的文本编辑器打开是看不到颜色，而只能看到逃逸字符本身。所以最好使用 less 打开。 通过之前的 address 可以在完整的 pipeline 中找到加法对应的位置。当然，如果不想查看完整的 pipeline （太长了），可以在运行时指定参数 --debug-start： 1build/X86/gem5.opt --debug-flags=O3PipeView --debug-start=33800000 --debug-file=trace.out configs/example/se.py --cpu-type=DerivO3CPU --caches -c /Users/wangluyuan/Desktop/COProject/test/unrolling_3 优化前： 优化后： 优化后，ADD 指令连续出现了多次。这里，不同的字母代表流水线的不同 stage： 1f = fetch, d = decode, n = rename, p = dispatch, i = issue, c = complete, r = retire, s = store-complete X86 的流水线比 MIPS 的五段（fetch, decode, exe, mem, wb）流水线复杂很多。但直观上来看，优化后的流水线似乎更满、更完整。或许是这个原因导致的运行速度更快。","link":"/2019/03/26/LoopUnrolling%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/"},{"title":"Obj-C内存管理","text":"Obj-C 内存管理手动引用计数（Manual Reference Counting, MRC)对一个对象发送 retain 消息，该对象引用计数加一；反之，对它发送 release 消息，对象的引用计数会减一。但是，实际上释放内存的消息并不是 release，而是 dealloc 方法。当对象的引用计数达到 0 时，OC 会自动调用 dealloc 方法去释放内存，而不需要手动调用。 测试 MRC首先需要关闭 Xcode 的自动引用计数功能，否则编译器会报错。 在 Building Settings 中搜索 reference counting，将 Objective-C Automatic Reference Counting 设置为 NO。 执行下面的代码： 12345678910111213#import &lt;Foundation/NSObject.h&gt;#import &lt;stdio.h&gt;int main() { id obj = [[NSObject alloc] init]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); //打印当前对象的引用计数 [obj retain]; [obj retain]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); [obj release]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); return 0;} 控制台输出： 123132 释放对象为了彻底销毁对象，也需要给对象所持有的变量发送 release 消息。 由于真正释放内存的是 dealloc 方法，因此需要重写该方法，向类中所有变量发送 release 消息，放弃它们的所有权（ownership）。 12345- (void)dealloc { /* 发送 release 消息 和其他的善后工作 */ [super dealloc];} 自动释放 (Autorelease)许多对象使用一次后就不再使用了。Cocoa 提供了自动释放机制，可以把要发送 release 消息的对象都记录下来，再统一发送。 123456789101112131415#import &lt;Foundation/Foundation.h&gt;#import &lt;stdio.h&gt;int main() { id pool = [[NSAutoreleasePool alloc] init]; //池内 id obj = [[NSObject alloc] init]; [obj retain]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); [obj autorelease]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); [pool release]; printf(&quot;%d\\n&quot;, (int)[obj retainCount]); return 0;} 控制台打印： 123221 也可以用新的方式： 123@autoreleasepool {//池内} 使用新方式更加高效、性能更好，且可以在池内使用 break return goto 等语句，因为只要运行到块外就会出发自动释放池释放内存，而传统方式中，如果使用跳转语句越过 [pool release]; 将会导致内存无法释放。 一般在大量使用临时变量的循环开始前创建自己的自动释放池，并在循环结束后释放。 Cocoa 会在程序开始处理事件前，隐式的创造一个自动释放池以支持 runloop 的资源释放。因此在做 GUI 编程时，不需要手动创造自动释放池也可以使用临时对象。 在支持垃圾回收的环境中，[pool release] 不做任何操作(no-op)，而应该使用 drain 去触发 GC （抽干池子）。在 iOS 中，drain 和 release 等价，因为 iOS 不支持 GC。 便利构造函数在内部调用别的构造函数的构造函数，成为便利构造函数。 OC 中的一些便利构造函数可以创建临时变量，并自动加入到自动释放池中，而无需关心如何销毁它们。这些便利构造函数不以 init 开头，而是以类型名开头，如 + (id) stringWithUTF8String: (const char*) bytes 。 自动引用计数 (ARC)手动引用计数需要程序员管理所有生成对象的所有权，在适当的地方插入 retain , release , autorelease 代码。自动引用计数会在编译时推断应在何处插入这些代码，并自动插入，不需要程序员自己管理。 使用 ARC 并不意味着完全不需要管理内存了。ARC 只能管理 OC 对象，不能管理 malloc 申请的内存，需要程序员自己用 free 函数释放。 使用 ARC，与引用计数相关的方法将被禁止使用，NSAutoreleasePool 也无法使用，但是仍可以使用 @autoreleasepool{} 。 不能随意定义 alloc/init/new/copy/mutableCopy 开头的，且以所有权操作无关的方法。 什么时候需要用 @autoreleasepool多数情况我们不需要显示地使用 @autoreleasepool，因为 runloop 会自动创建自动释放池。 但是在以下情况下需要使用： 不基于 UI Framework 的程序，如控制台程序。因为没有 runloop 为我们创建自动释放池了。 循环中大量创建临时变量，可能在 runloop 没结束时就已经耗尽内存。 12345678910int main() { for(int i = 0; i &lt;10000000; i++) { @autoreleasepool { NSNumber *num = [NSNumber numberWithInt:i]; NSString *str = [NSString stringWithFormat:@&quot;%d &quot;, i]; [NSString stringWithFormat:@&quot;%@%@&quot;, num, str]; //为什么这行是必要的？ } } return 0;} 如果不使用 autoreleasepool，内存将会激增。使用之后，则一直维持在一个很低的水平。注意，如果是在循环中实例化了类，就不会出现类似的问题。在作用域之外，系统会自动帮我们释放对象。 遗留的问题 为什么一定要使用 num 和 str ？如果把该行注释掉，就观察不到实验现象了。 弱引用为避免交叉引用导致内存泄漏，我们需要弱引用。弱引用指向对象，却不改变它的引用计数。弱引用会在它指向的对象被释放掉后自动变成 nil 从而避免出现野指针，这被称为自动 nil 化。 使用 ARC 时应该尽量让对象之间的关系成树状结构，避免循环引用。如果一定要互相引用，一方面可以使用弱引用，另一方面也可以手动给一个引用赋值为 nil 从而打破循环。","link":"/2018/02/28/Obj-C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"title":"Obj-C内存管理细节和多线程","text":"Obj-C 内存管理细节和多线程引用计数的实现iOS 中内存管理的部分是由 NSObject 类实现的。Foundation 框架并没有开源，但是 Cocoa 的互换框架 GNUstep 是开放源码的。互换框架是指，虽然实现的机制可能不一样，但对使用者来说，他们的行为应该是一致的。 首先来看 GNUstep 中是怎么做的： 在 alloc 时，会给对象分配一个 NSZone 作为内存空间。把对象的内存空间置为全 0，并在其头部加上引用计数字段，保存它的引用计数值。retain 方法将使这个值加一，而 release 方法将使它减一。而在 release 方法中，每次都会去判断此时的引用计数是不是 0。如果到了 0，则调用 dealloc 方法把对象的空间释放掉。 其中，NSZone 是为了防止内存碎片化而引入的结构。但是，现代运行时系统的内存管理本身效率已经很高，使用区域（Zone）来管理内存反而会引起内存使用效率低下及源代码复杂化等问题，所以区域已经单纯地被忽略了。 而苹果的实现与它不太一样。苹果使用了一个哈希表（引用计数表）来管理引用计数。表的 key 为内存块地址的哈希值。这样带来的好处有： 对象的内存块不用再考虑预留头部记录引用计数。 引用计数表中存有对象的内存块地址，可以通过记录追溯到内存块。 在利用工具检测内存泄露时，引用计数表的记录也有助于检测各对象的持有者是否还存在。 ARC 模式下的 AutoRelease在 ARC 下，[obj autorelease]; 不允许被调用，但是可以显示地给对象添加修饰符： 123@autoreleasepool { id __autoreleasing obj = [[NSObject alloc] init];} 但是这种情况就与显示地声明 __strong 一样罕见（对象默认就是强引用）。因为编译器会判断方法名是否以 alloc / new / copy / mutableCopy 开头，如果不是，则自动地将返回值的对象注册到 autoreleasepool 中。这也是为什么 OC 中自己定义的函数一般不要以这些单词开头的原因。 所有标记了 weak 修饰符的对象也都会被注册到自动释放池中。这是因为它只持有对象的弱引用，而在访问引用对象的过程中，该对象有可能被废弃。如果添加到自动释放池中，在 @autoreleasepool 结束前，都能确保该对象存在。 C 语言的结构体C 语言的结构体（struct / union）中的成员变量不能时 OC 的对象，否则会引起编译错误。这是因为 C 语言并没有方法来管理结构体成员的生命周期。 如果一定要用，可以把对象强制转化成 void *，或者附加 __unsafe_unretained 修饰符。正如该修饰符的名称，该变量不在编译器所管理的对象之中，因此不安全，一切都需要程序员手动管理。 __weak 修饰符附有 __weak 修饰符的变量所引用的对象一旦被废弃，则该变量会被自动赋值为 nil，这是怎么实现的呢？ 原来，系统会调用一个 objc_storeWeak 的方法，把变量存储进一个 weak 表中。weak 表与引用计数表很像，也是一个哈希表，同样以赋值对象的地址作为 key。当对象被废弃时，会从 weak 表中查找以废弃的对象地址作为 key 的记录，把包含在记录中的所有赋有 weak 关键字的对象的地址找到，并给这些变量赋值为 nil。之后，从 weak 表和引用计数表中删除对应的记录。 从上面的过程中可以看到，如果大量的 weak 对象被废弃，将会消耗更多的 CPU 资源。因此建议只有在必需的情况下使用 weak 来修饰变量。 什么是线程一个 CPU 一次只能执行一个命令，虽然有时命令列的地址会发生迁移，但它永远不可能在某处分开而产生并列执行两条指令的情况。这条无分叉的路径就被称为线程。 但是，当这样的无分叉路经不只一条时，就被称为“多线程了”。 OS X 和 iOS 的 XNU 内核每隔一段时间会切换执行路经。例如将 CPU 的寄存器等信息保存到各个路径专用的内存块中，再复原目标路径内存块中的信息，来切换不同的路径。这被称为“上下文切换”。反复切换时，看上去就是一个 CPU 能并列地执行多个线程一样。当然，如果计算机本身就有多核 CPU，那么就可以真正的使用多个 CPU 核心并行地执行多线程程序。 两种 Dispatch Queue 种类 说明 Serial Dispatch Queue 等待现在执行中处理结束 Concurrent Dispatch Queue 不等待现在执行中处理结束 例如，当 queue 为 serial 类型时，会 1 2 3 4 5 这样等待一个任务执行完后再执行下一个任务。而如果为 concurrent 类型时，就会并行执行多个任务。不过，具体开启几个线程由操作系统根据处理数、CPU 核心数、当前 CPU 负载等状态来决定。 这里，如果创建了多个 queue，这多个 queue 则是并行执行的。虽然在 1 个 Serial Queue 中只能同时执行 1 个处理，但是如果有多个 queue，每个 queue 之间就同时执行了。你可以添加任意多个 queue，从而突破限制，发起任意多个线程。当然，开启的线程数量越多，消耗的内存也就越多。大量的上下文切换也会大幅降低系统的响应性能。 为了避免多个线程竞争数据，可以使用 Serial Dispatch Queue。 生成的 queue 需要自己释放，而不能通过 ARC 自动释放。不过一般不需要我们自己创建 queue，因为系统给我们提供了两个队列：Global Dispatch Queue 和 Main Dispatch Queue。显然，Global 时 Concurrent 的，而 Main 是 Serial 的。 dispatch_barrier_async多个线程读取文件时是安全的，但是当写入时就会出现问题。使用 dispatch_barrier_async 函数，可以等待追加到 concurrent queue 上的并行处理都执行完之后，再来执行特定的处理。在这个函数执行完后，queue 又恢复成一般的动作。 利用这个函数可以高效的实现文件访问。 syncdispatch_sync 函数在指定的处理执行结束前不会返回。因此下面的情况会造成死锁： 12dispatch_queue_t queue = dispatch_get_main_queue();dispatch_sync(queue, ^{NSLog(@&quot;World&quot;);}); 该段代码在主线程执行 block，并等待它结束。而主线程正在执行这段代码，又在等待它返回，就造成了死锁。 所以在用此函数时要特别小心构成死锁。 挂起和恢复可以用以下两个函数： 12dispatch_suspend(queue);dispatch_resume(queue); 信号量通过 Dispatch Semaphore 可以进行排它控制，或用来限制最多执行的线程数。 dispatch-semaphore_create(信号量) 用来创建信号量，如果信号量小于 0 会返回 NULL。 dispatch_semaphore_wait(信号量, 等待时间) 用来等待计数值大于或等于 1。计数值等于 0 时等待。DISPATCH_TIME_FOREVER 表示永久等待。 dispatch_semaphore_signal(信号量) 用于提高信号量。 我们一般在执行一段任务时，先用 wait 来等待（如果该函数返回 0，代表计数值大于等于 1，同时会把计数值降低 1）。在任务结束时，用 signal 来把信号量加一。 dispatch_once该函数保证了引用程序执行中只执行一次特定的处理。我们可以利用这个函数来生成单例对象，实现单例模式。","link":"/2018/04/01/Obj-C%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E7%BB%86%E8%8A%82%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"Obj-C键值编程","text":"Objective-C 键值编程Objective-C 键值编程包括键值编码 KVC 和键值观察 KVO 两部分。 键值编码对象内部的属性由于被封装起来，无法直接访问，而要用到属性的 getter 和 setter 方法。KVC 提供了一种用于访问属性的键值对机制，其中 key 是属性的名称，而 value 是属性的值。这种机制与访问字典条目的机制相同。如： 12[object valueForKey: @&quot;var1&quot;];[object setValue: @&quot;value&quot; forKey: @&quot;var1&quot;]; 通过 KVC，可以用能在运行时改变的字符串来访问属性，从而动态而灵活地访问和操作对象的状态。 也可以通过键路径来指明需要便利的对象属性序列，下面两行代码的功能是相同的： 12person.name.firstName = @&quot;Bob&quot;;[person setValue: @&quot;Bob&quot; forKeyPath: @&quot;name.firstName&quot;]; 还可以通过 dictionaryWithValuesForKeys 方法设置或获取多个属性的值。 NSObject 遵守 NSKeyValueCoding 协议，因此它的所有子类都为键值编码提供了内置支持。 你可以通过在类中重写 NSKeyValueCoding 的一些方法来控制类的行为。比如通过重写 accessInstanceVariablesDirectly 可以让类控制如果没有找到属性的访问方法，能不能直接让键值编码访问属性的支持变量。 键值搜索模式KVC 如何来去获取和设置属性的值呢？ KVC 首先会搜索目标类名称符合 set\\ 的访问方法。例如，如果调用了 setValue:forKey: 方法，为 key 提供了参数 name，那么 KVC 就会搜索目标类中 setName: 的访问方法。 如果没找到访问方法，且接收对象的类方法 accessInstanceVariablesDirectly 返回 YES（默认返回 YES，可以设置为 NO），KVC 就会搜索接收对象的类，寻找名称匹配 _key / _isKey / key / isKey 格式的实例变量。 如果找到了，就会设置值。 如果没找到，接收对象的 setValue:forUndefinedKey: 就会被调用。通过重写这些方法可以处理无法找到属性的情况。 由此可见，写代码时应该遵循 Cocoa 的命名规范，这样才能让 KVC 正常工作。 集合操作符KVC 也可以对集合类型的元素进行操作。格式为 集合键路径.@操作符.属性键路径 。 123NSNumber *totalPrice = [orderItems valueForKeyPath: @&quot;@sum.price&quot;]; //计算总和NSNumber *totalItems = [orderItems valueForKeyPath: @&quot;@count&quot;]; //确定集合含有的对象数量NSArray *itemTypes = [orderItems valueForKeyPath: @&quot;@distinctUnionOfObjects.description&quot;]; //获取每个集合元素的描述 键值观察KVO 是一种通知机制，它使对象能够在其他对象的属性发生更改时获得通知。 通过 addObserver:forKeyPath:options:context: 方法，在观察对象和被观察对象之间建立联系。当被观察属性的值发生改变时，被观察对象就会调用观察对象中的 observeValueForKeyPath:ofObject:change:context: 方法。在该方法中，观察者类会实现用于处理被观察属性发生更改的逻辑。 NSObject 遵守 NSKeyValueObserving 协议，因此它的所有子类都对键值观察提供了内置的支持。 键值观察和通知键值观察和通知都提供了对象间的传递信息机制，功能有些类似。下面对两者进行比较。 NSNotification 能够封装通用信息，可以为更广泛的系统事件提供支持。而 KVO 只能支持对象属性更改通知功能。 通知使用交互的广播模型，信息会通过集中式通知中心分发，可以向多个对象发送消息。通知支持同步传递通知，也支持通过 NSNotificationQueue 来异步传递通知。KVO 使用点对点的交互模型，被观察对象会直接向已注册的观察着发送通知，且程序会一直处于阻塞状态，直到相应的处理执行完为止。通知的非阻塞交互模式可以提高应用程序的响应性。 通知双方是分隔开的，而 KVO 会通过 addObserver 方法为观察对象建立一个强引用。因此在释放被观察对象前，应该先通过 removeObserver 删除观察对象。 KVO 的实现键值观察是通过 Objective-C 的 Runtime 实现的。当你为对象注册观察者时，KVO 的基础设施会动态创建一个被观察对象的子类。然后，它将被观察对象的 isa 指针指向这个新建的子类，这样向原所属类发送的消息实际上就会被发送给这个子类。正常来说，isa 指针会指向对象的所属类，而该类拥有一个列出指针与该类中方法关系的分派表。这个新建的子类会拦截向被观察者发送的消息，向观察者发送通知等。以动态方式置换 isa 指针指向的类被称为 isa-swizzling。","link":"/2018/04/07/Obj-C%E9%94%AE%E5%80%BC%E7%BC%96%E7%A8%8B/"},{"title":"Obj-C运行时系统","text":"Objective-C 运行时系统Objective-C 会在运行时执行许多其他语言在编译或链接时执行的常规操作，如确定类型和方法解析。这些处理会带来额外的开销，Objective-C 通过缓存来节约这些开销。 选择器在 Objective-C 的对象消息传递中，通过被称为 选择器 的字符串来指明调用对象的哪个方法。选择器是一种分为多个段的文本字符串，与方法的声明对应，例如： 1分段1:分段2:分段3 如果创建了一个叫做 calculator 的变量，想调用它的方法，就要在接受器对象（calculator）后跟带输入参数的选择器： 1[calculator sumAddend1:25 addend2:10]; 选择器类型（SEL）是用于在编译源代码时替换选择器值的唯一标识符，Objective-C 运行时系统会保证每个选择器标识符的唯一性。可以用关键字 @selector 来创建 SEL 类型的变量。 1SEL myMethod = @selector(myMethod); 也可以用 Foundation 框架中的 NSSelectorFromString 在运行时创建选择器： 1SEL myMethod = NSSelectorFromString(@&quot;myMethod&quot;); 方法签名方法签名定义了输入参数的数据类型和返回值。编译器会把 [接收器 消息] 形式的对象消息转换为生命中带有方法签名的 C 函数调用语句。因此，为了生成对象消息传递代码，编译器需要获得选择器值和方法签名。从对象消息表达式中提取选择器很容易，但怎么提取方法签名呢？由于接受器和接受器的方法是在程序运行时确定的，因此编译时没有办法知道怎样的数据类型能和要调用的方法对应起来。所以编译器只能根据已知的方法声明进行猜测。如果找不到方法签名，或者方法签名与运行时实际的执行方法不匹配，就会导致从编译器警告到运行时错误的各种问题产生。 动态类型运行时系统通过动态类型功能，可以在运行时决定对象的类型。Objective-C 既支持静态类型，又支持动态类型。使用静态类型时，能在编译期检查类型，而使用动态类型时，就只能在运行时检查类型了。Objective-C 通过 id 类型来支持动态类型。id 类型的变量可以存储任何数据类型的对象。 Objective-C 还为运行时的对象内省（如检查对象属于哪个类）提供了 API。通过内省我们可以在运行时检查对象类型，从而确定对象是否能够执行特定的操作。 动态绑定动态绑定是指在运行时将消息和方法对应起来的过程。在运行时发送消息前，消息和接收消息的对象不会对应。由于许多接受器可能会实现相同的方法，所以调用方法的方式会动态变化，因而这也实现了 OOP 的多态。 动态方法决议使用动态方法决议能够以动态的方式实现方法。可以通过重写 NSObject 的 resolveInstanceMethod 和 resolveClassMethod 方法来动态实现实例方法和类方法。 可以通过 class_addMethod() API 来将函数添加到类中，需要先 #import &lt;objc/runtime.h&gt; 。 动态加载通过动态加载功能，可以在需要时加载可执行代码和源代码，而不必在程序启动时就加载所有的组件。这种 lazy loading 方式可以提高程序的性能和可拓展性。可以通过 NSBundle 来动态加载。 内省通过系统提供的 API 可以动态查询与方法有关的信息，并测试对象的继承性、行为和一致性信息。 运行时系统的组成结构Objective-C 的运行时系统由以下两部分组成：编译器和运行时系统库。 编译器当编译器解析到使用了上述动态特性的 Objective-C 源代码时，会使用适当的运行时系统库函数来生成可执行代码。 当编译器解析对象消息时，会生成调用运行时系统库函数 objc_msgSend() 中的代码，该函数以接受器、选择器和消息传递的参数一起作为参数。每条消息都是动态处理的，因此接受器类型和方法的实际实现都是在运行时决定的。 当编译器解析含有类定义和对象的代码时，会生成相应的运行时数据结构。所有运行时类型都以 isa 指针开头。 运行时系统库运行时系统库也提供了 C 语言的公共 API 供我们使用，这些 API 在 runtime.h 中声明。比如，可以动态的创建一个类。 1Class dynamicClass = objc_allocateClassPair([NSObject class], &quot;DynamicClass&quot;, 0); 当向对象发送消息时，运行时系统会通过自定义代码中的类方法缓存或虚函数表来查找类的方法。虚函数表也叫分派表，是一种动态绑定支持机制。最近调用过的方法的指针会被缓存起来，以优化性能。 运行时系统库定义的方法数据类型 objc_method 定义如下: 123456struct objc_method { SEL method_name; char * method_types; IMP method_imp;}typedef objc_method Method; 其中，IMP 类型的变量用来提供方法的地址。 方法查询逻辑如下： 类方法是如何寻找的呢？运行时系统是通过元类（metaclass）来实现的。每个类都拥有一个独一无二的元类（可认为元类是类的类），元类向普通的类一样，也通过父类指针指向父类的元类。基类的元类会让它的父类指针指向基类本身。","link":"/2018/04/02/Obj-C%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B3%BB%E7%BB%9F/"},{"title":"Raspberry Pi 3B+ 安装 Ubuntu MATE","text":"Raspberry Pi 3B+ 安装 Ubuntu MATE在实验室当 Undergraduate Researcher，需要多个树莓派和主机之间互相通信，果断考虑使用 ROS。采购时，本着电子产品买新不买旧的原则，选择了树莓派 3B+ 型号。Ubuntu 下安装 ROS 较为方便，于是打算安装 Ubuntu MATE 作为操作系统。没想到，Ubuntu Mate 竟然还没有官方支持最新的 Pi 3B+。好在最后经过一番折腾，最终还是安装成功了。 第一步 烧录 Ubuntu MATE先前往 Ubuntu MATE 官网 https://ubuntu-mate.org/download/ 下载镜像。 下载完毕后，安装 ddrescue 工具并拷贝镜像到 SD 卡： 123sudo apt-get install gddrescue xz-utilsunxz ubuntu-mate-16.04.2-desktop-armhf-raspberry-pi.img.xzsudo ddrescue -D --force ubuntu-mate-16.04.2-desktop-armhf-raspberry-pi.img /dev/sdx 注意，这里的 sdx 需要被替换成你的 SD 卡文件。使用 lsblk 命令可以看到所有块设备的信息，以及他们的依赖关系。一般根据 SD 卡的容量就可以看出那个文件是 SD 卡了。当然用 Linux 自带的设备管理程序也可以看到。比如，在我实际操作过程中，我的 SD 卡在 /dev/sdb 下。 经过漫长的等待，就可以看到镜像已经烧录成功了。SD 卡被分成了两个区，BOOT 和 ROOT。 第二步 更改 boot loader由于 Raspberry Pi 3B+ 把处理器换成了 Cortex-A53 (ARMv8)，如果这个时候直接把 SD 卡插入树莓派，是 boot 不起来的。表现为树莓派红灯闪烁，绿灯不亮，接上显示器只有彩虹屏。 解决方法是，下载最新的树莓派固件：https://github.com/raspberrypi/firmware 把 SD 卡中 Boot 区所有文件替换成该固件 boot 文件夹的内容。把 Root 区 lib/modules 下所有文件替换成该固件 modules 文件夹的内容。GUI 界面下拖拽文件可能无效，因为是只读权限。可以命令行下在 sudo 权限下复制文件。 插入 SD 卡，树莓派已经可以运行 Ubuntu MATE 了。但是还没结束…… 第三步 Wifi 怎么办Ubuntu 下，似乎直接在 boot 分区里增加 wpa_config 文件配置 Wifi 无效。所以还是要给树莓派接上鼠标、键盘、显示器来操作。但是，内置的 Wifi 不工作，怀疑是这个版本的 Ubuntu MATE 的 Wifi 驱动不支持新的树莓派。现在我的临时解决方案是给树莓派接上了一个 USB 的无线网卡。 第四步 扩展存储空间Ubuntu MATE 的默认文件系统空间很小，远远没有占满整个 SD 卡。我们需要 resize file system。 1sudo fdisk /dev/mmcblk0 出现 fdisk 的界面后，依次输入 d 2 n p 2 ，然后按两次空的回车，然后输入 w 。然后 reboot。 重启完成后， 1sudo resize2fs /dev/mmcblk0p2 现在，文件系统已经是整个 SD 卡的大小了。 第五步 设置自动登录如果不设置自动登录，每次树莓派上电后会卡在输入密码的页面，连接不上 Wifi。在 /usr/share/lightdm/lightdm.conf.d/60-lightdm-gtk-greeter.conf 文件里增加一行： 1autologin-user=yourUserName 就可以自动登录了。 现在打开 SSH 服务，就可以愉快的玩耍树莓派了。如果需要配置静态 IP 地址，去路由器的 LAN 设置中，给树莓派的 MAC 地址分配一个固定 IP 就可以了。毕竟使用 DHCP 不能保证树莓派的 IP 永远不变，这在实验室里会造成麻烦。 总结可以看到给 3B+ 安装 Ubuntu MATE 还是比较麻烦的。如果没有安装 ROS 的需求，还是建议安装 Raspbian。或者如果没有特别高的性能要求，购买老款的树莓派也会省事不少。关于内置 Wifi 不可用的问题，我还在继续寻找解决方案。 更新现在已经解决无法使用内置 WiFi 的问题。将 Raspbian 下面的 /lib/firmware/brcm 文件夹替换过来。","link":"/2019/02/09/RaspberryPi3B-%E5%AE%89%E8%A3%85UbuntuMATE/"},{"title":"SQLite.Swift 简单使用","text":"SQLite.Swift + Codable 简单使用SQLite.Swift 在新版本中支持了 Swift4 的新特性 Codable。SQLite 体积小，是一个轻量级的数据库，而 SQLite.Swift 则是用 Swift 对其进行了封装，而在多数情况下不必撰写 SQL 语句。得益于 Codale，使用 SQLite.Swift 进行数据持久化将更加简单。 下面，我用 SQLite.Swift 构建了一个简单的笔记本应用，来熟悉它的基本使用方式。 定义数据模型每一条笔记是一个 NoteItem 类型的结构体。由于我打算让它的主键自增，所以要重写 encode 方法。否则，可能就要用 uuid 来作为主键了，有点杀鸡用牛刀的感觉。 12345678910111213141516171819struct NoteItem: Codable { var id = 0 var title = &quot;&quot; var content = &quot;&quot; var timeStamp = 0 init(title: String, content: String, timeStamp: Int) { self.title = title self.content = content self.timeStamp = timeStamp } func encode(to encoder: Encoder) throws { var container = encoder.container(keyedBy: CodingKeys.self) try container.encode(title, forKey: .title) try container.encode(content, forKey: .content) try container.encode(timeStamp, forKey: .timeStamp) }} 因为要用自增主键，就不能自己设定 id，否则 SQLite 会报错。因此要重写 encode 方法，不对对 id 进行编码。而 decode 方法不覆盖，即使用默认方法，把所有属性全部赋值。 连接数据库构建一个数据库管理类，叫 DataBaseHandler。首先要连接数据库才能进行使用。 12345678910111213class DataBaseHandler { var db: Connection! func connect() { do { db = try Connection(getFilePath()) } catch { print(&quot;连接数据库失败&quot;) } } func getFilePath() -&gt; String { return NSHomeDirectory() + &quot;/Documents/db.sqlite3&quot; }} 新建 Table12345678910111213141516171819let id = Expression&lt;Int64&gt;(&quot;id&quot;)let title = Expression&lt;String&gt;(&quot;title&quot;)let content = Expression&lt;String&gt;(&quot;content&quot;)let timeStamp = Expression&lt;Int64&gt;(&quot;timeStamp&quot;) let noteList = Table(&quot;NoteList&quot;)func createTable() { do { try db.run(noteList.create(ifNotExists: true) { t in t.column(id, primaryKey: .autoincrement) t.column(title) t.column(content) t.column(timeStamp) }) } catch { print(&quot;建表失败&quot;) }} 这里指定只有在 Table 不存在的时候才创建。按照数据模型添加列，并把 id 指定为自增主键以获得更好的查找性能。 删除行作为一个笔记本应用，当然要支持滑动删除。 12345678func deleteItem(id: Int) { let item = noteList.filter(Int64(id) == self.id) do { try db.run(item.delete()) } catch { print(&quot;删除失败&quot;) }} 这里先通过 id 查找出元素，再调用 db.run(item.delete()) 就可以了，等价于 SQL 语句 DELETE FROM &quot;NoteList&quot; WHERE (&quot;id&quot; = \\(id)) 。 插入行12345678910func insert(_ item: NoteItem) -&gt; Int { do { try db.run(noteList.insert(item)) return Int(db.lastInsertRowid) } catch { print(error) print(&quot;插入失败&quot;) } return 0} 由于 id 是数据库自己生成的，为了让外界能拿到 id 号来进行其他的操作，必须把新插入的 id 号返回。可以用 db.lastInsertRowid 拿到最新插入的 id，但其实 run() 函数也是有返回值的，返回值就是 rowid，也可以直接返回。 更新行笔记本应用一个常见的操作是编辑已有的笔记，因此需要把已有的行更新。也可以删除旧行再插入新行，但更新的效率更高。 12345678func update(_ item: NoteItem) { let oldItem = noteList.filter(Int64(item.id) == self.id) do { try db.run(oldItem.update(item)) } catch { print(&quot;更新失败&quot;) }} 获取所有行在笔记本应用打开时，应该展示所有已有的笔记，因此需要将数据库所有的元素都取出。 12345678910func getAllItems() -&gt; [NoteItem] { do { return try db.prepare(noteList).map({ row in return try row.decode() }) } catch { print(&quot;查找失败&quot;) } return []} 数据持久化的部分到这里就完成了，剩下的操作就只有构建界面了。需要注意的是，应该尽量减少操作文件，毕竟读硬盘的速度比内存操作慢得多，因此各个界面中应该通过其他方式传值，而不是都根据数据库的内容来更新界面。","link":"/2017/12/31/SQLite%E4%BD%BF%E7%94%A8/"},{"title":"RunLoop 原理","text":"RunLoop - 原理RunLoop 是许多 iOS 开发者都会“假装”理解的概念。相关的概念常看常新，每次都有一番新的收获 （每次都不能彻底理解系列）～ 一句话概括 RunLoop 是干啥的就是一种 Event Loop。通过它来避免程序退出，同时高效地管理和相应各种事件。 这个循环在哪里随着 Swift 的诞生，Apple 开源了一个跨平台的 Foundation 框架：https://github.com/apple/swift-corelibs-foundation 。我们可以在源码中找到这个循环： 1234567void CFRunLoopRun(void) { /* DOES CALLOUT */ int32_t result; do { result = CFRunLoopRunSpecific(CFRunLoopGetCurrent(), kCFRunLoopDefaultMode, 1.0e10, false); CHECK_FOR_FORK(); } while (kCFRunLoopRunStopped != result &amp;&amp; kCFRunLoopRunFinished != result);} 可以看到就是一个简单的 do-while 循环，传入了当前的 RunLoop 作为参数。但这个循环并不是真正的 RunLoop 循环。 跑个题：啥是 check_for_fork当我们 fork 出来一个进程的时候，必须要紧接着调用一个 exec 家族的函数，从而让这个进程变成一个“全新的”进程。否则，包括 CoreFoundation, CoreData 甚至 Cocoa 等基础的框架都会出现异常。这里苹果检测了进程是否是 fork 出来的，如果是，就会调用 1__THE_PROCESS_HAS_FORKED_AND_YOU_CANNOT_USE_THIS_COREFOUNDATION_FUNCTIONALITY___YOU_MUST_EXEC__ 这个断言让程序崩溃。 回归正题。 RunLoop 的获取我们看到在循环中，调用了 CFRunLoopGetCurrent() 函数来获取当前的 RunLoop，并作为参数传入。那么这个函数里都做了什么呢？ 我们都知道苹果不允许我们自己手动创建 RunLoop，除了主线程的 RunLoop 会自动被创建之外，其他线程的 RunLoop 都是在第一次获取的时候被创建出来的。来看一下这个获取当前 RunLoop 对象的函数实现： 123456CFRunLoopRef CFRunLoopGetCurrent(void) { CHECK_FOR_FORK(); CFRunLoopRef rl = (CFRunLoopRef)_CFGetTSD(__CFTSDKeyRunLoop); if (rl) return rl; return _CFRunLoopGet0(pthread_self());} 这个函数的返回值是 CFRunLoopRef ，也就是 RunLoop 结构体的指针类型。之后，先尝试调用 _CFGetTSD 函数获取，如果拿不到，再调用 _CFRunLoopGet0 函数。 跑个题：啥是 TSDTSD 全称 Thread-Specific Data，线程特有数据，有时也叫 Thread-Local Storage, TLS。其中的数据对线程内部透明，而对其他线程屏蔽。使用的时候，可以理解成一个 KV 存储，并可以设定一个 destructor 析构函数指针，会在线程销毁时调用。 每一个进程都持有一个 keys 的数组，数组中，每一个元素包含一个用于指示 key 状态的 flag，和 destructor 函数指针。每一个线程的 TCB 也都含有一个指针数组，其中每个元素和 keys 数组一一对应。TCB 中这个数组的每一个元素指向该线程的 TSD。 所以我们看到，其实 RunLoop 是存储在线程的 TSD 中的。这也就是为什么我们说每个 RunLoop 是和线程一一对应的。而在线程退出的时候，对应的 RunLoop 也会被销毁掉。 继续看一下 _CFRunLoopGet0 函数里都做了什么。这里只保留了一些关键的代码。 123456789101112131415161718192021222324252627282930313233// should only be called by Foundation// t==0 is a synonym for &quot;main thread&quot; that always worksCF_EXPORT CFRunLoopRef _CFRunLoopGet0(_CFThreadRef t) { //... __CFLock(&amp;loopsLock); if (!__CFRunLoops) { //__CFRunLoops 是一个全局的字典 如果为空 CFMutableDictionaryRef dict = CFDictionaryCreateMutable(kCFAllocatorSystemDefault, 0, NULL, &amp;kCFTypeDictionaryValueCallBacks); //就创造一个字典 CFRunLoopRef mainLoop = __CFRunLoopCreate(pthread_main_thread_np()); //然后创建主线程的 RunLoop CFDictionarySetValue(dict, pthreadPointer(pthread_main_thread_np()), mainLoop); //之后放到这个字典里 if (!OSAtomicCompareAndSwapPtrBarrier(NULL, dict, (void * volatile *)&amp;__CFRunLoops)) { CFRelease(dict); } //最后把这个字典设置为全局的 __CFRunLoops 并通过锁来保证线程安全 CFRelease(mainLoop); } CFRunLoopRef newLoop = NULL; //尝试从全局的字典里获取 RunLoop CFRunLoopRef loop = (CFRunLoopRef)CFDictionaryGetValue(__CFRunLoops, pthreadPointer(t)); if (!loop) { newLoop = __CFRunLoopCreate(t); //没有的话就创建一个 CFDictionarySetValue(__CFRunLoops, pthreadPointer(t), newLoop); //然后放到字典里 loop = newLoop; } __CFUnlock(&amp;loopsLock); // don't release run loops inside the loopsLock, because CFRunLoopDeallocate may end up taking it if (newLoop) { CFRelease(newLoop); } // 最后设置 TSD if (pthread_equal(t, pthread_self())) { _CFSetTSD(__CFTSDKeyRunLoop, (void *)loop, NULL); //... } return loop;} 困惑既然 RunLoop 已经被存储到线程的 TSD 里了，为什么还需要用一个字典再来记录一遍线程和 RunLoop 的对应关系呢？ RunLoop 的创建我们看到如果取不到 RunLoop 的时候，会调用 __CFRunLoopCreate 来创建一个。这个函数的实现比较简单，只是创建了一个 RunLoop 的实例，并赋初值。 循环内部逻辑现在，描述 RunLoop 的对象已经被创建出来了。每次循环中，它都会被传入到 CFRunLoopRunSpecific 函数里。现在来看一下这个函数中每次都会执行哪些逻辑。这个函数比较长，简化之后核心逻辑是这样的： 12345678910111213141516171819202122SInt32 CFRunLoopRunSpecific(CFRunLoopRef rl, CFStringRef modeName, CFTimeInterval seconds, Boolean returnAfterSourceHandled) { /* DOES CALLOUT */ CHECK_FOR_FORK(); if (modeName == NULL || modeName == kCFRunLoopCommonModes || CFEqual(modeName, kCFRunLoopCommonModes)) { //参数不合法，直接返回并退出 RunLoop //... return kCFRunLoopRunFinished; } if (__CFRunLoopIsDeallocating(rl)) return kCFRunLoopRunFinished; __CFRunLoopLock(rl); //根据 modeName 找 mode CFRunLoopModeRef currentMode = __CFRunLoopFindMode(rl, modeName, false); if (NULL == currentMode || __CFRunLoopModeIsEmpty(rl, currentMode, rl-&gt;_currentMode)) { //如果找不到，或 mode 里没有 source/timer/observer 直接返回 return did ? kCFRunLoopRunHandledSource : kCFRunLoopRunFinished; } //... if (currentMode-&gt;_observerMask &amp; kCFRunLoopEntry ) __CFRunLoopDoObservers(rl, currentMode, kCFRunLoopEntry); //通知 observers 进入 loop result = __CFRunLoopRun(rl, currentMode, seconds, returnAfterSourceHandled, previousMode); //处理事件 if (currentMode-&gt;_observerMask &amp; kCFRunLoopExit ) __CFRunLoopDoObservers(rl, currentMode, kCFRunLoopExit); //通知 observers 离开 loop //... return result;} 核心就是根据 modeName 拿到 mode，然后传给 __CFRunLoopRun 函数处理。期间通知观察者循环的进入和退出。 再来看看 __CFRunLoopRun 里面都 run 了哪些逻辑。这里删除了不少代码，只留下核心部分。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static int32_t __CFRunLoopRun(CFRunLoopRef rl, CFRunLoopModeRef rlm, CFTimeInterval seconds, Boolean stopAfterHandle, CFRunLoopModeRef previousMode) { int32_t retVal = 0; do { //真正的 RunLoop 循环 if (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeTimers) { __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeTimers); //通知观察者，即将触发 Timers 回调 } if (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeSources) { __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeSources); //通知观察者，即将触发 Sources 回调 } __CFRunLoopDoBlocks(rl, rlm); //执行被加入 RunLoop 的 blocks Boolean sourceHandledThisLoop = __CFRunLoopDoSources0(rl, rlm, stopAfterHandle); //触发 Sources0 回调 if (sourceHandledThisLoop) { __CFRunLoopDoBlocks(rl, rlm); //执行被加入 RunLoop 的 blocks } #if TARGET_OS_MAC msg = (mach_msg_header_t *)msg_buffer; if (__CFRunLoopServiceMachPort(dispatchPort, &amp;msg, sizeof(msg_buffer), &amp;livePort, 0, &amp;voucherState, NULL, rl, rlm)) { //如果是 macOS，处理 Source1 goto handle_msg; //然后直接跳到 handle_msg } if (!poll &amp;&amp; (rlm-&gt;_observerMask &amp; kCFRunLoopBeforeWaiting)) __CFRunLoopDoObservers(rl, rlm, kCFRunLoopBeforeWaiting); //通知观察者即将休眠 __CFRunLoopSetSleeping(rl); __CFRunLoopServiceMachPort(waitSet, &amp;msg, sizeof(msg_buffer), &amp;livePort, poll ? 0 : TIMEOUT_INFINITY, &amp;voucherState, &amp;voucherCopy, rl, rlm); //休眠，直到被 Timer，基于 port 的事件，超时等事件唤醒 rl-&gt;_sleepTime += (poll ? 0.0 : (CFAbsoluteTimeGetCurrent() - sleepStart)); __CFRunLoopUnsetSleeping(rl); if (!poll &amp;&amp; (rlm-&gt;_observerMask &amp; kCFRunLoopAfterWaiting)) __CFRunLoopDoObservers(rl, rlm, kCFRunLoopAfterWaiting); //通知观察者结束休眠状态 handle_msg:; //开始处理 msg#if USE_DISPATCH_SOURCE_FOR_TIMERS else if (modeQueuePort != MACH_PORT_NULL &amp;&amp; livePort == modeQueuePort) { CFRUNLOOP_WAKEUP_FOR_TIMER(); cf_trace(KDEBUG_EVENT_CFRL_WAKEUP_FOR_TIMER, rl, rlm, livePort, 0); __CFRunLoopDoTimers(rl, rlm, mach_absolute_time()) //处理 timers 事件 }#endif __CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE__(msg); //执行 dispatch 到 main queue 的 block } else { CFRUNLOOP_WAKEUP_FOR_SOURCE(); CFRunLoopSourceRef rls = __CFRunLoopModeFindSourceForMachPort(rl, rlm, livePort); if (rls) {#if TARGET_OS_MAC mach_msg_header_t *reply = NULL; sourceHandledThisLoop = __CFRunLoopDoSource1(rl, rlm, rls, msg, msg-&gt;msgh_size, &amp;reply) || sourceHandledThisLoop; //处理 source1 事件 if (NULL != reply) { (void)mach_msg(reply, MACH_SEND_MSG, reply-&gt;msgh_size, 0, MACH_PORT_NULL, 0, MACH_PORT_NULL); CFAllocatorDeallocate(kCFAllocatorSystemDefault, reply); } } } __CFRunLoopDoBlocks(rl, rlm); //处理被加入 RunLoop 的 block } while (0 == retVal); //如果没超时，mode没空，也没被停止，则继续循环 return retVal;} 根据苹果的文档，一次 RunLoop 中处理步骤如下： 通知观察者进入 RunLoop 通知观察者 ready 的计时器即将触发 通知观察者不是基于 port 的 input sources 即将触发 触发 ready 的非基于 port 的 sources 如果有基于 port 的 sources 已经 ready，直接触发，goto 9 通知观察者即将休眠 让线程休眠，除非被一些事件唤醒 通知观察者线程已经苏醒 开始处理事件： 如果 timer ready 了，处理并继续循环，回到 2 超时等情况退出循环 通知观察者 RunLoop 退出了。 关于 source0 和 source1：source1 是基于 port 的事件，是来自其他进程或系统内核的消息。source0 是其余的应用层事件。但有的时候，source1 事件会转交给 source0 来处理，比如触摸事件。当我们触摸屏幕时，会产生硬件中断；操作系统内核会把相关的消息通过 port 发送给应用程序，即 source1 事件；接着这些触摸事件会被丢到事件队列里，再交给 source0 处理。 不出意外的话，后面还会有一篇 RunLoop 的使用～ Ref: 深入理解 RunLoop iOS底层原理总结 - RunLoop 重拾RunLoop原理 RunLoop 源码阅读 线程特有数据 Run Loops , Apple 关于RunLoop你想知道的事","link":"/2019/12/23/RunLoop%E5%8E%9F%E7%90%86/"},{"title":"Swift Tips","text":"Swift Tips结构相等&amp;引用相等结构相等符 == 被用来判断两个值是否相等。而引用相等 === 用来检查两个引用是否具有同一性，即是否指向同一个对象。 1234567class A { var p = 0}var a = A()var b = aprint(b == a) 上面的代码会报错误信息 Binary operator '==' cannot be applied to two 'A' operands，提示你需要自己实现结构相等运算符。而如果把 == 改为 \\=== 就会 print 出 true。若将 class 改为 struct，则 === 也一样会报错。因为结构体是值类型，就谈不上引用了。 forEach一下两段代码有什么不同？ 123456789101112131415161718192021func foo1() { array.forEach { num in print(num) if num &gt; 2 { return } }}func foo2() { for num in array { print(num) if num &gt; 2 { return } }}let array = [1,2,3,4,5]foo1()foo2() 使用 for each in 循环的函数会在打印出 3 之后停止，而使用 forEach 函数的函数会打印出所有的值。这是因为 forEach 的 return 语句只会将 forEach 的尾随闭包返回，而不会终止 forEach 本身的循环。这一点从刚刚“函数的函数”这个说法中也可以看出来。 mutating 关键字123456struct A { var a = 0 mutating func change() { a += 1 }} 结构体中的方法若想改变自身的属性，则需要在 func 前添加 mutating 关键字，而类中不用。可以这样看待这个问题的：可以理解成 self 是函数的一个隐式参数，添加 mutating 关键字代表 self 是可变的（相当于用 var 来声明这个结构体的感觉），否则 self 就是不可变的（相当于用 let 声明，自然不可以改变结构体内属性的值）。而 class 无论是 var 还是 let 来声明，都可以改变属性的值（var 和 let 对引用类型只限制了引用本身是否可以改变，而不是引用指向的对象），故不存在这个问题。更精确地来说，可以理解为 mutating 相当于对隐式变量 self 添加了关键字 inout。 捕获列表将一个对象的属性设置为弱引用是打破循环引用的重要手段。但是，weak 关键字只能运用于 class 类变量，故不适用于同样是引用类型的函数变量。以下代码通过闭包，间接的构成了循环引用： 1234567891011121314151617181920212223242526class Child { var parent: Parent init(parent: Parent) { self.parent = parent } deinit { print(&quot;child deinit&quot;) }}class Parent { weak var child: Child? var closure: (()-&gt;())? deinit { print(&quot;parent deinit&quot;) }}var p: Parent? = Parent()var c: Child? = Child(parent: p!)p?.child = cp?.closure = { print(c)}p = nilc = nil 为了打破这个循环引用，可以通过闭包的捕获列表，将 c 设置为弱引用： 123p?.closure = { [weak c] in print(c)} 闭包中，self 关键字会被强制写出来，也是为了明确的提示我们可能构成的循环引用。如果构成了循环引用，一般通过将 self 设置为 unowned 无主引用来打破循环。无主引用与弱引用的区别是，在引用的对象释放掉之后，它不会被设置为 nil，因此也不用像弱引用那样，必须是可选值，每次使用时都要解包。 &amp;在传递 inout 关键字时，需要在变量名前添加 &amp;。这里的 &amp; 不像 c/c++ 中的那样表示传递的是引用，而是把值复制，再粘贴回来。 如果函数接受的是一个 UnsafeMutablePointer 的话，我们还是需要在变量名前加上 &amp;。但是，这里的 &amp; 表示的确实是传递引用了，更准确地说，传递的是指针。 @autoclosure 关键字@autoclosure 关键字可以自动为参数创建闭包，让我们的代码更加整洁。 如果不加此关键字，我们必须手动写闭包语法 {}： 1234func foo(_ a: () -&gt; Bool) { a()}foo( {1+1==2} ) 有了 @autoclosure： 1234func foo(_ a: @autoclosure () -&gt; Bool) { a()}foo(1+1==2) deferdefer 块会在即将离开函数作用域之前执行。如果有多个 defer 块，则逆序执行（像一个栈）。 12345678let database = openDatabase()defer { closeDatabase()}let connection = openConnection(to: database)defer { closeConnection(to: database)} 自定义/重载运算符定义一个幂运算符 ** : 123456789101112precedencegroup ExponentiationPrecedence { //自定义优先级 associativity: left //左结合性 higherThan: MultiplicationPrecedence //优先级高于乘法优先级}infix operator **: ExponentiationPrecedence //使用 prefix infix 和 postfix 定义前缀、中缀、后缀func **(lhs: Double, rhs: Double) -&gt; Double { return pow(lhs, rhs)}2**3 // 8.0","link":"/2018/03/18/Swift-Tips/"},{"title":"Swift4新特性","text":"Swift4 新特性参考自：Ray Wenderlich - iOS11 by Tutorials One-sided ranges我们现在可以这样表示一个范围： 123let array = [&quot;通信电子线路&quot;, &quot;电磁场与电磁波&quot;, &quot;数字信号处理&quot;, &quot;通信原理&quot;, &quot;计算机网络&quot;]print(array[...3])\\\\打印出: [&quot;通信电子线路&quot;, &quot;电磁场与电磁波&quot;, &quot;数字信号处理&quot;, &quot;通信原理&quot;] 也可以这样： 12array[..&lt;3]array[2...] 单边范围也可以用来产生一个无限序列： 1234let uppercase = [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;]let asciiCodes = zip(65..., uppercase)print(Array(asciiCodes))\\\\打印出: [(65, &quot;A&quot;), (66, &quot;B&quot;), (67, &quot;C&quot;), (68, &quot;D&quot;)] 这里 zip 是函数式编程中常用的一个函数，就像 map, flatmap 那样。它表示把两个序列“齿合”成一个序列。别忘了 zip 有“拉链”的意思。 在模式匹配中也可以应用： 123456789slet value = 2switch value {case ...2: print(2)case 3...: print(3)default: break} 而且并不仅限于整型！Double 型也是支持的。 StringsString 现在回归了集合类型（就像 Swift1 中的那样）。这意味着集合可以做的事情，String 都可以做。 1234567let str = &quot;How are you Indian Mi fans?&quot;for char in str { print(char)}str.countstr.isEmptyString(str.reversed()) 这里注意，str.reversed() 返回的是一个 ReversedCollection&lt;String&gt; ，所以必须强制转换成 String。 String 虽是集合类型，但是 Int 和 Swift3 中一样不能作为其下标。下标必须是一个 String.Index 。 12let index = str.index(str.startIndex, offsetBy: 4)str[index...] //are you Indian Mi fans? Swift4 还带来了一个新的类型：Substring 为什么不继续使用 String 类型，而要构造一个新的 Substring 类型呢？我们知道，为了保证高效率，Swift 大量使用了 copy-on-write 技术。在你提取出一个子串的时候，并不会真的复制出一个新的字符串出来，而是多了一个指向原有字符串其中一部分的指针。就像这样： 这回使得该字符串的引用计数增加。当你不在使用原有的字符串而转而只用子串时，原有的字符串就无法被自动释放。而如果引入了新的类型 Substring，而大量的 api 要求传入的类型是 String，你就不得不强制将 Substring 转化为 String（Swift 是强类型语言的缘故）。这个被强制转化出来的 String 就与之前的字符串无关了（被 copy 出来），从而避免了内存泄露。 在上面的例子中就已经出现了 Substring： 12let sub = str[index...]type(of: sub) //Substring.Type 由于 String 和 Substring 都遵守 StringProtocol，所以大多数用法都是一致的。重点需要记住的就是内存中的关系。 Range&lt;String.Index&gt; 和 NSRange 之间的转化也变得更方便了： 1234let str = &quot;🙈🙉🙊🐵🐒&quot;str.count //5str.utf16.count //10let nsRange = NSRange(str.startIndex..., in: str) //{0, 10} （NSRange 和 UTF-16 是对应的） Swift4 还带来了多行字符串，就像 Python 中的那样： 1234let str = &quot;&quot;&quot;大鹏一日同风起，抟摇直上九万里。&quot;&quot;&quot; Dictionary enhancements有了新的初始化函数，现在可以使用键值序列来构造字典了： 12let dic = Dictionary(uniqueKeysWithValues: zip(1..., [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;]))//dic: [2: &quot;2&quot;, 3: &quot;3&quot;, 1: &quot;1&quot;] 或者用元组的序列也可以： 1let dic = Dictionary(uniqueKeysWithValues: [(1,&quot;1&quot;), (2,&quot;2&quot;)]) 并且增加了一个 merge 函数，用来合并两个字典。在闭包中定义遇到冲突时的处理方法： 12345678910let defaultStyling: [String: UIColor] = [ &quot;body&quot;: .black, &quot;title&quot;: .blue, &quot;byline&quot;: .green]var userStyling: [String: UIColor] = [ &quot;body&quot;: .purple, &quot;title&quot;: .blue]userStyling.merge(defaultStyling) { (user, _) -&gt; UIColor in user}// [&quot;body&quot;: .purple, &quot;title&quot;: .blue, &quot;byline&quot;: .green] 新的 mapValues 函数可以不改变字典的结构（map 会返回一个数组，而不是字典）： 1234var dic = Dictionary(uniqueKeysWithValues: zip(1..., [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;]))dic = dic.mapValues{ String(Int($0)! + 1)} 字典也可以依据某一个特征来进行分组（Grouping）： 123let names = [&quot;Harry&quot;, &quot;ron&quot;, &quot;Hermione&quot;, &quot;Hannah&quot;, &quot;neville&quot;, &quot;pansy&quot;, &quot;Padma&quot;].map { $0.capitalized } //大写let nameList = Dictionary(grouping: names) { $0.prefix(1) }//[&quot;H&quot;: [&quot;Harry&quot;, &quot;Hermione&quot;, &quot;Hannah&quot;], &quot;R&quot;: [&quot;Ron&quot;], &quot;N&quot;: [&quot;Neville&quot;], &quot;P&quot;: [&quot;Pansy&quot;, &quot;Padma&quot;]] 自定义下标可以返回范型了： 1234567891011121314151617struct Grade { private var data: [String: Any] init(data: [String: Any]) { self.data = data } subscript&lt;T&gt;(key: String) -&gt; T? { return data[key] as? T }}let gradebook = Grade(data: [&quot;name&quot;: &quot;Neil Armstrong&quot;, &quot;exam&quot;: &quot;LEM Landing&quot;, &quot;grade&quot;: 97])let who: String? = gradebook[&quot;name&quot;]let grade: Int? = gradebook[&quot;grade&quot;] 这样就不必写 as 语句把 Any 类型转化了。但是指明类型仍是必不可少的（即:String？不可缺少）。 还有一些其他的小变化 extension 中可以访问到 private 成员变量了。 出于内存安全性的考虑，一个变量不能被当作两个 inout 参数传入同一个函数，这被称为“排他性”（exclusivity）。所以 Swift3 中的 swap 函数在 Swift4 中就非法了： 12swap(&amp;numbers[1], &amp;numbers[3]) // illegal in Swift4//numbers 不能被当作两个 inout 参数传入 swap 函数 ​ 现在可以用： 1numbers.swapAt(1, 3) ​ 更详细的介绍参看这里。 Swift4 中对 NSNumber 的桥接做了安全性检测： 12let n = NSNumber(value: 603)let v = n as? Int8 ​ 在 Swift3 中，会出现一个不正确的值。而现在会是 nil 了。也可以用 is 语句来判断是否可以转换。 可以具体指明一个对象既是某个类型，又遵守某个协议了： 12345protocol MySpecialDelegateProtocol {}class MySpecialView: UIView {}class MyController { var delegate: (UIView &amp; MySpecialDelegateProtocol)?} 还有一些参考资料：https://github.com/apple/swift-evolution https://developer.apple.com/videos/play/wwdc2017/402/","link":"/2017/10/08/Swift4%E6%96%B0%E7%89%B9%E6%80%A7/"},{"title":"Swift集成友盟数据统计","text":"Swift 集成友盟数据统计友盟是比较有名的数据统计服务提供商，但其 SDK 是用 OC 写的，开发文档中暂时也没有给出 Swift 的接入教程。不过其实用 Swift 集成友盟还是非常简单的。 获取 App Key注册友盟账号，在 U-App 中创建新应用，就可以获取到 App Key 了。 安装 SDK虽然目前在 iOS 的文档中没有写明，但友盟已经支持使用 CocoaPods 进行安装了。在 Podfile 里添加： 1pod 'UMengAnalytics' 或 1pod 'UMengAnalytics-NO-IDFA' 上面的是标准 SDK，下面的是无 IDFA 版本的。IDFA 是苹果的广告标识符，用于保护用户隐私的同时让商家可以最终广告效果。友盟使用 IDFA 是为了防止今后苹果可能会禁用 open-UDID 而造成数据异常。不过苹果禁止没有广告而获取 IDFA 的应用上架，因此审核期间可能会有风险。这里我选择了不采集 IDFA 的版本。 构建桥接文件由于友盟的 SDK 是用 OC 编写的，因此在 Swift 项目中需要桥接文件来完成混编。好在 Swift 调用 OC 是非常方便的。 Command + N 呼出新建文件窗口，选择 Header File，命名为 YourAppName-Bridging-Header.h。（如果你已经引用过 OC 的代码，无视这一步） 在其中插入你需要的组件的头文件，如 #import &quot;UMMobClick/MobClick.h&quot;。 在工程的 Build Settings 中，找到 Swift Compiler - General （如果没有，记得勾选上方的 All，或者直接搜索）。在 Objective-C Bridging Header 项填入刚刚桥接文件的路径。也可以双击该项使它处于可编辑状态，把文件直接从文件树中拖过来，就会自动填充路径。 开始使用桥接文件构建完成，就可以按照官方文档用 Swift 调用友盟的 api 了。在 AppDelegate.swift中，找到 application(_:didFinishLaunchingWithOptions:) 函数，开始配置。 1234567func application(_ application: UIApplication, didFinishLaunchingWithOptions launchOptions: [UIApplicationLaunchOptionsKey: Any]?) -&gt; Bool { let UMConfig = UMAnalyticsConfig() UMConfig.appKey = &quot;Your App Key&quot; UMConfig.channelId = &quot;App Store&quot; MobClick.start(withConfigure: UMConfig) return true} 现在，在真机或模拟器中启动程序，如果你在友盟的统计页面中看到相应的信息，就说明已经配置成功了！ 如果不想污染数据，可以使用友盟的集成调试功能。具体的内容可以参考开发文档。","link":"/2017/12/23/Swift%E9%9B%86%E6%88%90%E5%8F%8B%E7%9B%9F%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1/"},{"title":"Python import 崩溃问题","text":"Python import 崩溃问题最近遇到了一个比较诡异的问题，在一个 Python 文件中，我 import 了如下几个库： turtle time numpy 在另一个 Python navigation.py 中，我 import 了另外几个库： numpy skfuzzy from skfuzzy import control matplotlib.pyplot 两个文件分别运行时，都非常正常。但是，我在第一个文件中一旦 import navigation.py 文件（我想使用其中定义的函数），就会收到操作系统抛出的终端异常： 1Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSApplication _setup:]: unrecognized selector sent to instance 0x114c65a40' 可以看到，这个异常是 macOS 给出来的，而并不是 Python 报给我的。 经过测试，我发现如下情况可以让程序执行：不调用 turtle 的绘图语句，或者，同时注释掉 from skfuzzy import control 和 import matplotlib.pyplot 。这就让问题显得十分诡异。 最终的解决方案是，在程序的最开始添加如下代码： 1234from sys import platform as sys_pfif sys_pf == 'darwin': import matplotlib matplotlib.use(&quot;TkAgg&quot;) 这应该是 matplotlib 的一个 bug，在 macOS 环境下，要显示指明使用 TkAgg 作为界面库。崩溃的原因或许是 turtle 和 matplotlib 绘图的机制有所冲突？ 附记使用 skfuzzy （scikit-fuzzy）库的时候，直接调用 view() 方法画 membership function 的曲线图无效（图片不显示），必须要先 import matplotlib.pyplot as plt 然后调用 plt.show() 才可以显示。也是个很奇怪的问题呢…… 本来只是想把 Python 当作一个顺手的工具，没想到越是着急写东西越是遇到大坑，由此可见把底层原理搞明白有多么重要。","link":"/2018/12/12/Python-import-%E5%B4%A9%E6%BA%83%E9%97%AE%E9%A2%98/"},{"title":"Promise是什么","text":"Promise 是什么之前和前端组的同学聊天，发现他们有一个很有意思的东西叫 Promise。既然要是从前端组那里听说的 Promise，那么我们就先谈一些关于前端的东西。 单线程的 JavaScriptJavaScript 是单线程语言，也就是同一时间只能做一件事情。准确来说，是负责解释并执行 JS 代码的线程只有一个。为什么要把 JavaScript 设定为单线程呢？这是因为它的工作环境主要是在浏览器中与用户互动，并操作 DOM。如果它是多线程的，那么就可能会并发地操作 DOM，从而带来非常复杂的同步问题。在新标准中，JavaScript 也被允许开启子线程，但子线程完全受主线程控制，且禁止操作 DOM。因此，JavaScript 仍然是单线程语言。 既然 JS 是单线程的，那么当我们进行耗时操作，比如前端非常常见的网络请求时，不就会发生界面卡死的情况吗？但我们又可以看到，浏览网页时是非常顺滑流畅的，并没有发生这种情况。因为虽然 JS 是单线程的，但浏览器作为一个 App 是支持多线程的。JS 通过一些方法，完全可以做到异步操作。异步和单线程并不是冲突的。 JavaScript 异步原理首先来区分一下同步和异步。同步是指排队执行的任务，即前一个任务执行完成了，后一个任务才能开始执行，也就是我们熟悉的 sync。所有的同步任务都会在主线程执行，并形成一个执行栈。而异步任务有了运行结果后，就会把对应的事件放到任务队列中，比如鼠标点击事件、键盘事件、网络请求事件等等。当执行栈空了之后，系统就会读取任务队列，把相应的任务放入执行栈中执行。这个过程会不断的重复。 这里说的执行异步任务，指的是回调函数。异步任务在创建时必须指定回调函数，这个函数会被挂起，在主线程空闲后被拿来执行。这个重复的过程被称为 Event Loop。 清楚了回调方法后，再来谈具体是怎么实现异步的。前面提到，浏览器是多线程的，在浏览器中，会有这些线程： UI 线程。我们非常熟悉的线程，负责渲染 UI 界面。 JS 引擎线程。JS 代码在这个线程上执行。但是 JS 引擎线程并不仅是一个线程，会有子线程来配合它。JS 会影响页面渲染，因此它和 UI 线程是互斥的，这也是为什么 JS 执行时会阻塞 UI 线程。 HTTP 请求线程。 Event Loop 轮询线程。 …… 向网络请求这类的操作，实际上是通过浏览器的 API 委托给浏览器执行的。执行完毕，回调函数再给 JS 引擎执行。 回调地狱 Callback Hell回调函数大家都很熟悉。每次异步任务，都要指定一个回调函数。那当我们想完成一步操作后，再进行下一步操作，就要在上一步的回调函数中写。如果下一步依赖上一步完成的情况多了，就会出现回调地狱： 1234567891011{ { { { { //很容易编写出三角形的代码 } } } }} 举个例子：先登录，登录之后我们可以拿到用户的信息。根据用户信息去请求用户的头像，拿到头像后再去设置图片……我们在平时编写 iOS 应用时很容易就写成这样： 123456789login { info, error in if let info = info { fetch(avatar: info.userAvatarURL) { image, error in if let image = image { self.imageView = image } } }} 饱受回调地狱折磨的显然不仅是前端，还有我们 iOS 啊！ 初识 PromisePromise 最早由开源社区提出并实现，最终被加入到了 JS ES6 标准中。Promise 代表了异步操作最终完成的或失败的对象。你可以把回调函数绑定在这个由函数返回的对象上，而不是把回调函数当作参数传进函数。 当作参数传进函数的例子： 123456789function successCallback(result) { console.log(&quot;It succeeded with &quot; + result);}function failureCallback(error) { console.log(&quot;It failed with &quot; + error);}doSomething(successCallback, failureCallback); 绑定 Promise 对象的例子： 1doSomething().then(successCallback, failureCallback); Promise 了什么？Promise 到底保证了什么呢？ 当前运行完成前，回调函数永远不会被调用。 .then 添加的回调函数，都会被调用。 多次调用 .then 可以添加多个回调函数，它们会按照插入顺序独立运行。 Promise 对象有三种状态，Pending、Resolved、Rejected。只有异步操作的结果可以决定当前是哪一种状态，其他任何操作都无法改变状态，且状态一旦改变就不会再变。这也是 Promise 名字的来源。 Promise 使用我们可以直接 new 一个 Promise 对象，也可以把 Promise 对象作为返回值。Promise 里的代码会立即执行。 12345678910111213141516171819//1let promise = new Promise((resolve, reject) =&gt; { //使用了箭头函数 if(success) { resolve(value) } else { reject(error) }})//2function doSomething() { return new Promise(function (resolve, reject) { if(success) { resolve(value) } else { reject(error) } })} Promise 接受一个函数作为参数，这个函数又有两个参数 resolve 和 reject。resolve 和 reject 又分别是两个函数。这两个函数有 JavaScript 引擎提供，不需要自己实现。resolve 的作用是把状态从 pending 变为 resolved；reject 的作用是把状态从 pending 变为 rejected，同时把错误作为参数传递出去。 生成 Promise 实例后，可以用 then 方法制定状态变为 Resolved 和 Rejected 时的回调函数： 12345promise.then(function(value) { //success}, function(value) { //failure}); then 方法的第二个参数是可选的，不一定要提供。这两个函数接受 Promise 对象传出的值作为参数。 整体来看就是这样： 12345678function timeout(ms) { return new Promise((resolve, reject) =&gt; { setTimeout(resolve, ms, 'done'); //'done'作为参数传递给resolve函数 });}timeout(100).then((value) =&gt; { console.log(value);}); then 的返回值也是一个 Promise 对象，因此可以链式调用。而 Promise 的错误具有冒泡性质，会一直向后传递直到捕获为止，因此可以在最后用 catch 统一捕获错误。 看一段代码到现在，我们终于能看懂前端组的同学写的部分代码了，一起欣赏一下： 12345678910111213function createRequest(......) { const options = {......}; ...... return new Promise((resolve, reject) =&gt; { request(options, (error, res, body) =&gt; { if (error) { reject(error); } else { resolve({ error, res, body }); } }); });} 首先，这是一个用于发送 HTTP 请求的函数，它传入了一些参数用来构建请求的参数 options。函数的结尾，返回了一个 Promise 对象。构造这个 Promise 对象时，传入了一个函数。这个函数体里，调用 request 函数实际发送请求，request 函数除了接受刚刚构建的 options 以外，还有一个回调函数作为参数。请求成功，resolve；失败，reject。 当然，在实际调用这个函数的时候，他是使用了 await 语法糖结合 try / catch 捕获错误。不过这里就不再讨论 await / async 这些东西了。 回到 iOS讲了这么多 JavaScript 的东西，是时候回到 iOS 了。既然前端有 Promise 这么好的东西，我们当然也可以使用。 感谢开源社区，我们有了 Promise Kit 。 再来看我们已开始举的例子：登录 - 获取头像，用 Promise Kit 可以这样写： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import UIKitimport PromiseKitstruct Info { var url = &quot;&quot;}struct MyError: Error { var description: String}class ViewController: UIViewController { var imageView = UIImageView() override func viewDidLoad() { super.viewDidLoad() firstly { login() }.then { info in self.fetch(imageUrl: info.url) }.done { image in self.imageView.image = image print(&quot;got image&quot;) }.catch { error in print(error) } } func login() -&gt; Promise&lt;Info&gt; { print(&quot;start login&quot;) return Promise { seal in DispatchQueue.global().async { Thread.sleep(forTimeInterval: 2) seal.fulfill(Info(url: &quot;https://www.baidu.com&quot;)) } } } func fetch(imageUrl: String) -&gt; Promise&lt;UIImage&gt; { print(&quot;start fetch image&quot;) return Promise { seal in DispatchQueue.global().async { Thread.sleep(forTimeInterval: 2) seal.reject(MyError(description: &quot;获取图片出错了&quot;)) } } }} 这里我就简单的 sleep 了两秒钟来模拟网络请求。我们可以看到，代码成功地变成了扁平的，避免了层层嵌套。在 Promise Kit 中，执行成功的函数被叫做了 fulfilll。firstly 只是语法糖，直接调用 login().then 是完全一样的，但是使用 firstly 将使得语义更加清晰。","link":"/2018/05/20/Promise%E6%98%AF%E4%BB%80%E4%B9%88/"},{"title":"Swift 多线程初步","text":"Swift 多线程初步多线程简介在 iOS 中，每个进程（应用程序）启动后，都拥有一个主线程（UI 线程）。这个线程是其他所有线程的父线程。其他线程都是独立于 CocoaTouch 框架的，因此只能在主线程更新 UI。在其他线程中虽然也可以更新 UI，但由于 UIKit 不是线程安全的，可能会导致出现问题，因此不推荐。当用户做网络操作、更新数据库等比较耗时的操作时，如果不使用多线程，而直接在主线程进行的话，就会导致整个应用卡住，用户体验很差。多线程就是在多个处理器中（或者单个处理器分时间片）同步地执行一些操作，从而提高效率。 线程和进程一个应用程序可以看作是一个进程。线程是进程的基本执行单元，进程的所有任务都在线程中执行。一个进程一般可分为新建、就绪、运行、阻塞、终止等 5 个状态。 iOS 多线程程序开发在 iOS 中，我们有以下几种方式去开发多线程的程序，分别是： pThread NSThread GCD NSOperation pThreadpThread 是一个 C 语言的跨平台多线程框架，可以运行在 Unix 、Linux 、macOS 等多种操作系统上，Windows 也有相应的移植版本，当然也可以运行在 iOS 上。在 obj-C 中，可以引入 pthread.h 头文件来使用。由于过于底层，不仅需要与 C 语言交互，还要手动管理线程的生命周期等事务，因此在开发中基本不会使用。 NSThreadNSThread 是经过苹果封装的框架，完全面向对象，但线程的生命周期仍然需要手动管理。 1234567891011121314151617181920212223242526272829303132import UIKitimport PlaygroundSupportclass ViewController: UIViewController { override func viewDidLoad() { //点击按钮，创建子线程 view.backgroundColor = UIColor.white let button = UIButton(frame: CGRect(x: 100, y: 100, width: 100, height: 30)) button.backgroundColor = UIColor.red button.addTarget(self, action: #selector(ViewController.onClick), for: .touchUpInside) view.addSubview(button) } func onClick() { NSLog(&quot;Main Thread\\n&quot;) let thread = Thread(target: self, selector: #selector(ViewController.runThread), object: nil) //创建线程 thread.start() //启动线程 } func runThread() { for i in 0..&lt;10 { NSLog(&quot;%d\\n&quot;, i) sleep(1) } } }PlaygroundPage.current.liveView = ViewController() 这个程序会创建一个新的线程。在这个线程中，每隔 1 秒钟输出一个数字。 点击按钮后，控制台输出如下信息： 12345678910112017-06-22 22:53:43.704 test[7391:1122296] Main Thread2017-06-22 22:53:43.715 test[7391:1122434] 02017-06-22 22:53:44.727 test[7391:1122434] 12017-06-22 22:53:45.732 test[7391:1122434] 22017-06-22 22:53:46.737 test[7391:1122434] 32017-06-22 22:53:47.743 test[7391:1122434] 42017-06-22 22:53:48.747 test[7391:1122434] 52017-06-22 22:53:49.752 test[7391:1122434] 62017-06-22 22:53:50.756 test[7391:1122434] 72017-06-22 22:53:51.762 test[7391:1122434] 82017-06-22 22:53:52.764 test[7391:1122434] 9 可以看到在主线程中，线程号是 1122296 ，而输出数字的线程号是 1122434 。可见确实新建了一个子线程。 也可以使用其他的方法创建新的线程： 1Thread.detachNewThreadSelector(#selector(ViewController.runThread), toTarget: self, with: nil) 或者： 1self.performSelector(inBackground: #selector(ViewController.runThread), with: nil) 但是这两种方法无法获得线程对象。⚠️注意第二个方法中是 self 的方法，而不是 Thread 的静态方法。 GCDGCD 全称 Grand Central Dispatch，是苹果为并发代码在多核心处理器上执行提供支持的一套 API，底层用 C 语言编写。GCD 管理着一个线程池（队列），根据系统资源自动对多线程进行管理，而不用程序员直接和线程打交道。 GCD 有三种队列形式： 名称 简介 Serial 串行队列，队列和队列之间是并行执行的，但是队列里面的各个子线程是顺序执行的。事实上，队列里面是一个线程，而不是多个线程。唯一的一个线程保证了严格的串行执行。 Concurrent 并发队列可以同步地执行多个任务，会由系统根据负载来选择并发执行的任务。 Main Dispatch Queue 提交到此线程的任务会被放到主线程执行，可以在此进行更新 UI 的操作。 基本用法 async 是异步；sync 是同步。 123456789101112131415161718192021222324252627282930313233343536import UIKitimport PlaygroundSupportclass ViewController: UIViewController { override func viewDidLoad() { //点击按钮，创建子线程 view.backgroundColor = UIColor.white let button = UIButton(frame: CGRect(x: 100, y: 100, width: 100, height: 30)) button.backgroundColor = UIColor.red button.addTarget(self, action: #selector(ViewController.onClick), for: .touchUpInside) view.addSubview(button) } func onClick() { NSLog(&quot;Main Thread\\n&quot;) DispatchQueue.global().async { self.runThread() //耗时操作 DispatchQueue.main.async { NSLog(&quot;更新 UI&quot;) //回到主线程更新 UI } } } func runThread() { for i in 0..&lt;10 { NSLog(&quot;%d\\n&quot;, i) sleep(1) } } }PlaygroundPage.current.liveView = ViewController() 点击按钮后，控制台输出以下信息： 1234567891011122017-06-23 09:24:47.665 test[790:34424] Main Thread2017-06-23 09:24:47.666 test[790:34456] 02017-06-23 09:24:48.668 test[790:34456] 12017-06-23 09:24:49.671 test[790:34456] 22017-06-23 09:24:50.676 test[790:34456] 32017-06-23 09:24:51.677 test[790:34456] 42017-06-23 09:24:52.682 test[790:34456] 52017-06-23 09:24:53.688 test[790:34456] 62017-06-23 09:24:54.692 test[790:34456] 72017-06-23 09:24:55.697 test[790:34456] 82017-06-23 09:24:56.701 test[790:34456] 92017-06-23 09:24:57.706 test[790:34424] 更新 UI 可以看到更新 UI 时，线程标号与主线程标号一致。说明耗时操作完成之后，确实回到了主线程执行更新 UI 的操作。 DispatchGroup 123456789101112131415let group = DispatchGroup() let download1 = DispatchQueue(label: &quot;d1&quot;)download1.async(group: group) { self.runThread()} let download2 = DispatchQueue(label: &quot;d2&quot;)download2.async(group: group) { self.runThread()} group.notify(queue: DispatchQueue.main, execute: { NSLog(&quot;更新 UI&quot;)}) 在组里的任务都结束之后，会执行 notify。 NSOperationNSOperation 基于 GCD，封装了一些更为实用的功能。除了使用 BlockOperation 之外，还可以自定义子类继承 NSOperation。 基本用法 12345678let queue = OperationQueue()queue.maxConcurrentOperationCount = 2 //设置最大并发数 let operation = BlockOperation(block: { self.runThread()}) queue.addOperation(operation) 添加依赖 123456789101112131415let queue = OperationQueue()queue.maxConcurrentOperationCount = 2 let operationA = BlockOperation(block: { self.runThread()}) let operationB = BlockOperation(block: { self.runThread()}) operationB.addDependency(operationA) //添加依赖关系 queue.addOperation(operationA)queue.addOperation(operationB) 这里 B 依赖 A，所以 B 会等待 A 执行完之后再执行。和串行执行不同，A 和 B 是两个独立的线程。注意添加依赖的时候不要构成循环依赖，否则会导致死锁。 同步锁多个线程访问同一个资源时，可能会因为“争抢”而出现数据错乱。比如经典的售票问题： 123456789101112131415161718192021222324252627282930313233343536import UIKitimport PlaygroundSupportclass ViewController: UIViewController { var ticketAmount = 20 override func viewDidLoad() { view.backgroundColor = UIColor.white let button = UIButton(frame: CGRect(x: 100, y: 100, width: 100, height: 30)) button.backgroundColor = UIColor.red button.addTarget(self, action: #selector(ViewController.onClick), for: .touchUpInside) view.addSubview(button) } func onClick() { NSLog(&quot;Main Thread\\n&quot;) let salerA = Thread(target: self, selector: #selector(ViewController.sale(name:)), object: &quot;A&quot;) let salerB = Thread(target: self, selector: #selector(ViewController.sale(name:)), object: &quot;B&quot;) salerA.start() salerB.start() } func sale(name: String) { while ticketAmount &gt; 0 { ticketAmount -= 1 print(name + &quot;售出一张票，剩余\\(ticketAmount)张&quot;) sleep(1) } } }PlaygroundPage.current.liveView = ViewController() 点击按钮后，控制台输出： 1234567891011121314151617181920A售出一张票，剩余19张B售出一张票，剩余18张B售出一张票，剩余16张A售出一张票，剩余16张A售出一张票，剩余15张B售出一张票，剩余14张A售出一张票，剩余13张B售出一张票，剩余12张B售出一张票，剩余11张A售出一张票，剩余10张A售出一张票，剩余8张B售出一张票，剩余9张A售出一张票，剩余7张B售出一张票，剩余6张A售出一张票，剩余5张B售出一张票，剩余4张A售出一张票，剩余3张B售出一张票，剩余2张B售出一张票，剩余1张A售出一张票，剩余0张 不出意外地出现了数据错乱现象。为了解决这个问题，就需要对访问资源的代码部分加锁： 123456789func sale(name: String) { while ticketAmount &gt; 0 { objc_sync_enter(self) //加锁 ticketAmount -= 1 print(name + &quot;售出一张票，剩余\\(ticketAmount)张&quot;) sleep(1) objc_sync_exit(self) //解锁 }} 再次运行，数据就正常了。","link":"/2017/06/23/Swift-%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"title":"V-REP实现Bubble Rebound算法","text":"V-REP 实现 Bubble Rebound 算法V-REP 是一款较为易用的机器人仿真软件。它拥有 4 个不同的物理引擎，可以较好地进行动力学仿真。 首先，参考官方教程建立 bubbleRob 机器人模型。为了方便实现 Bubble Rebound 算法，还要添加几个额外的接近传感器。 模型建立好了之后，就可以开始着手实现 Bubble Rebound 避障算法了。Bubble Rebound 是一个很简单的避障算法，该论文可以在 IEEE Xplore 上找到。简单来说，首先对距离传感器进行编号。以上图为例，最左边的传感器为 3 号，向右依次为 2，1，-1，-2，-3 。论文的插图给出了一侧四个传感器的例子： 之后，根据文章中给出的公式可以计算出机器人应该旋转的角度。大体思路是，如果左边有障碍物，那么正数部分就会因为距离较小而较小，从而计算得到一个负数的角度。在机器人 z 轴向上的情况下，旋转一个负数的角度即转向没有障碍物的右侧。 但是在 V-REP 中使用内建的 Lua 脚本控制机器人旋转某个角度的实现中，有一点需要注意。旋转某个角度的思路大概如下：在一个循环中，给机器人的两个轮子施加不同的速度，不断对比当前的转角与目标转角，直至达到目标。需要注意的是，如果新建的是非多线程脚本，那么这个循环就会阻塞住仿真线程。仿真过程被阻塞住，也就无法让机器人旋转；机器人不旋转，我们的循环就无法退出，从而造成机器人不转、仿真不进行的尴尬局面。 为了解决这个问题，就要使用多线程脚本。同时，也可以调用 sim.switchThread() 提前切换线程来得到更好的性能。进一步地说，Lua 本身并不是使用的多线程来进行的并行操作，而是使用了协程（coroutine）。多个协程在同一个线程中，可在子程序内部中断，去执行其他子程序，再返回，而不是函数调用（函数调用也可以算作协程的一种特殊状态）。因为是在同一个线程中，且由程序自身控制切换（线程、进程的切换由调度器来进行，程序员干预较少），因此效率非常高，没有线程转换的开销；不需要担心资源抢占，无需锁机制。多个子程序协作完成任务（而非抢占），故称为协程（co-routine）。 完整代码可参见我的 GitHub。","link":"/2018/11/10/V-REP%E5%AE%9E%E7%8E%B0Bubble-Rebound%E7%AE%97%E6%B3%95/"},{"title":"Calculate Absolute Trajectory Error with ROS","text":"Calculate Absolute Trajectory Error with ROSAbsolute Trajectory Error (ATE) 是衡量 SLAM 算法的一个重要指标。它描述了 SLAM 估计出来的机器人路径和 ground truth 之间的差异大小。显然 SLAM 算法的表现越好，那么估计出来的路径误差就会越小。 ATE 是一个评估全局性能的指标，它需要让机器人走较长的一段距离。另一个衡量局部准确性的指标是 Relative Pose Error (RPE)。 ATE 定义Ground truth 路径和机器人估计的路径很可能不在同一个坐标系下。比如，我们可以用 total station (全站仪) 来精确的获取机器人的位置从而用作 GT，坐标系的原点默认会在全站仪所处的位置。而机器人往往用最开始的几帧定义世界坐标系的原点。即使修改全站仪的设置，使得原点的位置在机器人的初始位置，由于全站仪不能测量旋转姿态，同样无法保证两个坐标系重合。所以我们需要通过 Horn’s method 寻找一个变换矩阵，将两个轨迹对齐。给定 3 对以上的匹配点，Horn’s method 可以找到最优的变换矩阵来最小化误差，而且这是一个闭式解 (closed form solution)。 时刻 i 的 ATE error matrix 定义为：$$E_i := Q_i^{-1}SP_i$$其中，Q 表示 GT，P 表示估计的轨迹，S 表示找到的刚体变换矩阵。注意这里的 E 是误差矩阵，其中包括旋转误差和平移误差。 全部轨迹的 ATE 可以用 root mean square error 表示：$$ATE_{rmse} = \\left( \\frac{1}{n} \\sum_{i=1}^n || trans(E_i) || ^2 \\right)^{\\frac{1}{2}}$$其中 trans 表示 matrix E 中的 translation 部分，即我们不考虑 rotation。 实际使用TUM 的 researcher 开源了一组实用的 benchmarking toolbox。然而其实现使用的是 Python 2，不过只需要稍做改动就可以迁移到 Python 3，还算比较容易。但是我们需要先将轨迹点转换到它需要的格式。 首先，假设机器人的位姿是通过 ROS TF 广播的，我们可以先录制一个只包含 /tf topic 的 ROS bag： 1rosbag record /tf 解析 ROS bag 比较费劲，但我们可以直接把它导出成 CSV 的格式，这样就很容易解析了： 1rostopic echo -b &lt;your_bag_name&gt;.bag -p /tf &gt; tf.txt 文件内容大概这样： 123%time,field.transforms0.header.seq,field.transforms0.header.stamp,field.transforms0.header.frame_id,field.transforms0.child_frame_id,field.transforms0.transform.translation.x,field.transforms0.transform.translation.y,field.transforms0.transform.translation.z,field.transforms0.transform.rotation.x,field.transforms0.transform.rotation.y,field.transforms0.transform.rotation.z,field.transforms0.transform.rotation.w1645564988578113729,0,1645397999136861801,world,body,-0.0237263019323,-0.183226266184,0.0574725730104,-0.0199035477786,-0.017429874818,0.0730891285439,0.9969744367531645564988578145616,0,1645397999136861801,body,camera,-0.011094,0.00522558,-0.0394383,-0.500806957696,-0.499043786406,0.495054661047,0.505043139691 之后可以用一个 Python 脚本把 world - body 的位姿关系转换成所需的格式： 12345678910111213141516import csvfrom os import readdef process_tf_file(file_path='tf.txt'): with open('tf_ate.csv', 'w') as output_file: writer = csv.writer(output_file) with open(file_path) as input_file: reader = csv.reader(input_file) next(reader) # skip header for row in reader: header_frame = row[3] child_frame = row[4] if header_frame != 'world' or child_frame != 'body': continue ts = float(row[0]) / 1e10 x, y, z = float(row[5]), float(row[6]), float(row[7]) writer.writerow([ts, x, y, z]) 转换之后的文件就只包括时间戳和 x，y，z 位置了： 1234164556498.8578114,-0.0237263019323,-0.183226266184,0.0574725730104164556498.86749378,-0.0317886917667,-0.189064281648,0.0602023804558164556498.8774454,-0.040280908714,-0.19915625333,0.0610245969542164556498.88754055,-0.0510204634397,-0.206446264428,0.0607193932249 对 GT 进行类似操作后，就可以使用 TUM 的工具来计算 ATE 了： 1evaluate_ate.py ./pos_ate.csv ./tf_ate.csv --plot result.png 最终结果如下（对绘图代码有改动）：","link":"/2022/02/23/ate-ros/"},{"title":"Bundle Adjustment using Ceres-Solver","text":"Bundle Adjustment using Ceres-SolverBundle Adjustment (BA) has a broad application in Structure From Motion (SFM) problems, which further optimize the location of points to achieve 3D reconstruction. In recent years, traditional filter-based SLAM algorithms have been taken place by optimization-based SLAM, in which BA is the core part. BA can simultaneously optimize camera poses as well as the locations of 3D points by minimizing the reprojection error. Ceres-Solver is an optimization library that can be used to solve least-squares problems. There is an example program of solving BA on its official documents: http://ceres-solver.org/nnls_tutorial.html#bundle-adjustment BAL DatasetThe example program uses Bundle Adjustment in the Large (BAL) dataset. This dataset uses a pinhole camera model, which has 9 parameters. There are 3 parameters for rotation R, 3 parameters for translation T, 1 parameter for focal length f, and two radial distortion parameters k1 and k2. The data format in each file is described as follows: The first line includes 3 numbers, which are &lt;num_cameras&gt;, &lt;num_points&gt;, and &lt;num_observations&gt;. There are 4 numbers in each line of the following num_observations lines, representing &lt;camera_id&gt;, &lt;point_id&gt;, \\, and \\, respectively. The next 9 * &lt;num_cameras&gt; lines represents the camera parameters. Every 9 lines represent 1 camera. The order is the same with &lt;camera_id&gt;. The last 3 * &lt;num_points&gt; lines are the point locations. Every 3 lines represent 1 point. The order is the same with &lt;point_id&gt;. The following Python script can be used to visualize the points in a BAL data file. Here I took the first file in the LadyBug dataset as an example. 12345678910111213141516171819202122232425262728import numpy as npfrom matplotlib import pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Ddef read_bal_file(): num_cam = 49 num_points = 7776 num_observations = 31843 points = [] with open('./ba_data.txt') as file: lines = file.readlines() for idx in range(1 + num_observations + 9 * num_cam, len(lines), 3): points.append([float(lines[idx].rstrip()), float(lines[idx + 1].rstrip()), float(lines[idx + 2].rstrip())]) points = np.array(points) return points def plot_3d(points): x_list = points[:, 0] y_list = points[:, 1] z_list = points[:, 2] fig = plt.figure() ax = Axes3D(fig) ax.scatter(x_list, y_list, z_list) plt.show()points = read_bal_file()plot_3d(points) CompilationThe following CMakeLists.txt file can be used to build the program. 123456789101112131415161718192021222324# cmake version to be usedcmake_minimum_required( VERSION 3.0 )# project nameproject(ba)# targetadd_executable( ba bundle_adjustment.cc )# external libsfind_package(Ceres REQUIRED)find_package(OpenCV REQUIRED)target_include_directories(ba PRIVATE ${CERES_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS})target_link_libraries(ba PRIVATE ${CERES_LIBRARIES} ${OpenCV_LIBRARIES}) Reprojection ErrorIf we know the 3D coordinates of a point plus the intrinsic and extrinsic parameters of the camera, we can calculate the projection location of that point in the pixel frame. Ideally, the line from the optical center of the camera and the 3D point should overlap with this projection point. However, the measurement and the calculation are not perfect, there is an error in the projection. By optimizing camera parameters and the location of the 3D point, we can minimize the reprojection error, which is the idea of BA. The cost function of BA is shown in the following formula:$$\\frac{1}{2} \\sum_i \\sum_j | z_{ij} - h(T_i, p_j) |^2$$Where z is the measurement (point in the image plane) of point p at pose T. h is the measurement function, which converts the 3D coordinate of the given point into the 2D image frame. In the example program, we first convert the point from the world frame into the camera frame, using the extrinsic parameters (R and T). Then, undistortion is applied. Finally, we calculate the difference between the prediction with the observation and use it as the residual. 12345678910111213141516171819202122232425262728293031323334353637383940414243struct SnavelyReprojectionError { SnavelyReprojectionError(double observed_x, double observed_y) : observed_x(observed_x), observed_y(observed_y) {} template &lt;typename T&gt; bool operator()(const T *const camera, const T *const point, T *residuals) const { // camera[0,1,2] are the angle-axis rotation. T p[3]; ceres::AngleAxisRotatePoint(camera, point, p); // camera[3,4,5] are the translation. p[0] += camera[3]; p[1] += camera[4]; p[2] += camera[5]; // Compute the center of distortion. The sign change comes from // the camera model that Noah Snavely's Bundler assumes, whereby // the camera coordinate system has a negative z axis. T xp = -p[0] / p[2]; T yp = -p[1] / p[2]; // Apply second and fourth order radial distortion. const T &amp;l1 = camera[7]; const T &amp;l2 = camera[8]; T r2 = xp * xp + yp * yp; T distortion = 1.0 + r2 * (l1 + l2 * r2); // Compute final projected point position. const T &amp;focal = camera[6]; T predicted_x = focal * distortion * xp; T predicted_y = focal * distortion * yp; // The error is the difference between the predicted and observed position. residuals[0] = predicted_x - observed_x; residuals[1] = predicted_y - observed_y; return true; } // Factory to hide the construction of the CostFunction object from // the client code. static ceres::CostFunction *Create(const double observed_x, const double observed_y) { return (new ceres::AutoDiffCostFunction&lt;SnavelyReprojectionError, 2, 9, 3&gt;( new SnavelyReprojectionError(observed_x, observed_y))); } double observed_x; double observed_y;}; In the main function, the corresponding camera parameters and the 3D coordinates of each measurement are retrieved. All residual blocks are added into ceres::Problem and jointly optimized. 123456789101112ceres::Problem problem;for (int i = 0; i &lt; bal_problem.num_observations(); ++i) { // Each Residual block takes a point and a camera as input and outputs a 2 // dimensional residual. Internally, the cost function stores the observed // image location and compares the reprojection against the observation. ceres::CostFunction *cost_function = SnavelyReprojectionError::Create( observations[2 * i + 0], observations[2 * i + 1]); problem.AddResidualBlock(cost_function, NULL /* squared loss */, bal_problem.mutable_camera_for_observation(i), bal_problem.mutable_point_for_observation(i));} Note that we can speed up the procedure of solving BA problems by utilizing its sparsity. However, it’s not demonstrated in this simple example.","link":"/2021/11/28/ba-ceres/"},{"title":"用概率论分析娘娘们的怀孕概率","text":"用概率论分析娘娘们的怀孕概率 AI 科普文章系列 —— 贝叶斯定律（Bayes’s Theorem） B 站视频：https://www.bilibili.com/video/BV1Cz4y1b7nN/?spm_id_from=333.337.search-card.all.click 故事皇上坐拥后宫佳丽三千人，人人都想怀上龙裔争宠上位。但是在娘娘们使用各种麝香、药物明争暗斗的过程中，真正能怀孕的概率是较小的。我们不妨假设皇上对嫔妃们雨露均沾，且娘娘们的受孕体质一致，这样每个人的怀孕概率都是一致的，为 1%。太医院赫赫有名的温太医擅长通过号脉的方式来检查娘娘们是否真的怀孕。作为一名老中医，如果某位娘娘真的有孕在身，那么他号出是喜脉的概率为 100%（温大人真的很厉害！）。然而人有失手、马有失蹄，温太医的诊断也有 5% 的假阳率，即有 5% 的概率把没有怀孕的娘娘也错误的判断成喜脉。 今天，甄嬛觉得身体不适，遂请温太医来号脉。如果温太医说：“娘娘这是喜脉啊！”，请问甄嬛怀孕的概率有多高呢？请大家估计一下量级： 90% 左右 50% 左右 10% 左右 背景知识我们快速复习一下概率论中的基本知识。 记 P(A) 为事件 A 发生的概率。例如 P(抛硬币正面朝上) = 50%。在我们的例子中，P(娘娘怀孕) = 1%。 记 P(A | B) 为在事件 B 发生的条件下，事件 A 发生的概率。例如 P(学生很菜｜考试成绩为 C) &gt; P(学生很菜)。在甄嬛传的例子中，P(号出喜脉｜怀孕) = 100%。P(号出喜脉｜没有怀孕) = 5%。 最后，P(A) = P(A | B)P(B) + P(A | not B)P(not B)。这被称为全概率公式。这是因为 B 和非 B 分割了整个样本空间。当然，我们也可以把样本空间分割成更多个互不重叠的小块。 贝叶斯定律在温太医号出喜脉的条件下，娘娘真的怀孕的概率可以记为 P(怀孕｜号出喜脉)。我们可以用贝叶斯定律来求这个概率。贝叶斯定律为：$$P(A | B) = \\frac{P(B|A)P(A)}{P(B)}$$其中，P(A) 和 P(B) 被称为先验概率（prior probability）。可以理解为在没有任何其他信息的时候，我们就已经知道的一些知识。比如在什么都不知道的情况下，某位娘娘的怀孕概率为 1%。 P(A|B) 被称为后验概率（posterior probability）。在给定温太医号出喜脉这个信息后，我们就可以更新娘娘怀孕的概率了。显然这个概率会变得更大一些。 P(B|A) 被称为似然性（likelihood）。它用来描述在证据确凿的情况下，对观测结果的估计。如果给娘娘照了 B 超，发现真的怀孕了，像温太医这样的高手能 100% 地号出喜脉。而一些庸医却只能 50% 地号出喜脉（瞎猜）。我们就可以说温太医号脉具有更高的似然性。 计算我们暂时不谈论贝叶斯定律是如何推导出来的，而是用甄嬛传这个例子来直观地理解一下它的应用。 记温太医号出喜脉这个事件为 +（阳性）。怀孕事件记为 H。没有怀孕则记为 $\\bar{H}$。小横杠代表这个事件的逆。 现在我们有 $P(H) = 1\\%$，$P(+|H) = 100\\%$，以及$P(+|\\bar{H})=5\\%$。求 $P(H|+)$。 根据贝叶斯定律，我们有：$$P(H|+) = \\frac{P(+|H)P(H)}{P(+)}$$现在唯一未知的部分是 P(+) ，即温太医随便号出喜脉的概率为多大。直观上我们要考虑两种情况，一个是娘娘真的怀孕了，另外一个是娘娘没有怀孕但是被误诊了。那么根据全概率公式：$$P(+) = P(+|H)P(H) + P(+|\\bar{H})P(\\bar{H})$$带入上式，可得：$$P(H|+) = \\frac{P(+|H)P(H)}{P(+|H)P(H) + P(+|\\bar{H})P(\\bar{H})} \\= \\frac{100\\%\\times1\\%}{100\\%\\times1\\% + 5\\% \\times 99\\%} \\= \\frac{1}{1 + 4.95} \\approx 16.7\\%$$我们发现，即使在温太医这样高超的检测技术下号出喜脉，娘娘真的怀孕的概率也只有不到 20%。这是否符合你之前的估计呢？ 程序验证养成动手实践的习惯非常有助于大家学习计算机相关的技术。我们可以编写一个简单的小程序来验证贝叶斯定律是否可靠。注意，这个程序是为了尽量符合直觉，而没有对运行效率做优化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import random'''妃子属性：是否怀孕'''class Lady: def __init__(self, is_pregnant=False): self.is_pregnant = is_pregnant'''太医属性：号脉的真阳性概率（默认 100%）、假阳性概率（默认 5%）'''class Doctor: def __init__(self, true_positive=1.0, false_positive=0.05): self.true_positive = true_positive self.false_positive = false_positive ''' 对某位妃子号脉。返回是否为喜脉。 ''' def check(self, lady): if lady.is_pregnant: return random.choices( [True, False], weights=[self.true_positive, 1 - self.true_positive] )[0] else: return random.choices( [True, False], weights=[self.false_positive, 1 - self.false_positive] )[0]def run(): ladies = [] for _ in range(100000): # 后宫佳丽十万人 is_pregnant = False if random.random() &lt; 0.01: # 1% 的怀孕概率（皇上雨露均沾） is_pregnant = True ladies.append(Lady(is_pregnant=is_pregnant)) doc = Doctor() # 温太医 num_positive = 0 # 验为喜脉的妃子人数 num_true_pregnant = 0 # 有喜脉的妃子中，真正怀孕的人数 for lady in ladies: result = doc.check(lady) # 挨个号脉 if result: # 恭喜小主，是喜脉 num_positive += 1 if lady.is_pregnant: # 真的怀孕了 num_true_pregnant += 1 print('P(Pregnant | Test Positive) = %f%%' % (num_true_pregnant / num_positive * 100))if __name__ == '__main__': run() 这个程序随机生成十万个娘娘，请温太医来一一号脉。最终程序输出的概率为 16.6% 左右，非常接近我们的理论值。建议大家修改一些参数，亲自运行一下程序并观察实验结果。 结语贝叶斯定律可以帮我们计算后验概率，它告诉我们不仅要在意检测手段的准确率，还要考虑事件本身发生的概率。我们会在接下来学习机器人的状态估计、AI 决策算法中，频繁地见到贝叶斯的身影。","link":"/2023/05/16/bayes-theorem/"},{"title":"WiFi监听UDP包","text":"Wi-Fi 监听 UDP 包最近遇到一个需求，一个被远程控制的小车需要在多个网络中无缝漫游。如果按照我们熟悉的方式，搭建一个 Wi-Fi 网络，小车上的树莓派就可能在网络切换时掉线 1 至 2 秒钟。鉴于小车是被实时远程控制的，我们需要网络切换时间极短，而不同 Wi-Fi 之间的切换速度就不符合要求。 我认为，与其想办法加快在不同网络之间切换的速度，不如干脆不接入任何一个网络了——让树莓派嗅探空气中的所有数据包，并解析出自己需要的包来获取控制信息。不接入网络，自然就不存在基站切换的耗时问题。这相当于在以广播的形式通信。 我也考虑了使用其他的通信方式，比如蓝牙、Zigbee 等，最终还是更加倾向于 Wi-Fi。 网络架构多台树莓派充当 AP，通过 UDP 协议广播数据。小车车载树莓派监听所有数据包，并筛选自己需要的数据。这需要车载树莓派进入 monitor mode。普通的 managed mode 下，网卡会过滤掉目的地址不是自身的包。由于我们不希望小车接入网络，所以在这种模式下就收不到包了。monitor mode 不同于 promiscuous mode（混杂模式），它不需要和 AP 建立连接（太好了）。 硬件不是所有的无线网卡都支持 monitor mode。Raspberry Pi 3 B+ 板载网卡就默认不支持，因此需要额外购买合适的网卡。但社区也提供了支持 monitor mode 的布丁 nexmon 。 进入 monitor mode1234$ sudo ifconfig &lt;your interface&gt; down$ sudo iwconfig &lt;your interface&gt; mode monitor$ sudo ifconfig &lt;your interface&gt; up$ sudo iwconfig &lt;your interface&gt; channel &lt;your channel number&gt; 这里，需要指定网卡工作的频率。虽然 Wi-Fi 信道有重叠，但最好还是要和路由器的工作频率匹配。比如，我就设置路由器（或者其他作为 AP 的树莓派）的工作信道设置成了 channel 5 。当然，如果许多热点在同时工作，则最好工作在不同的频段防止干扰，再不断切换车载 Wi-Fi 频道。虽然 Wi-Fi 有载波监听、冲突避免等机制，但仍会大幅降低传输效率。 Wi-Fi 最好不要设置密码——否则数据包会被加密，如何解包又是一个问题。 如果使用 Wireshark 抓包，则要在 Wireshark 里面也勾选上 monitor mode。 捕捉 UDP 数据包和 Wireshark 一样，我们要使用 libpcap 来抓包。libpcap 有一个 python 的封装 pcapy ，这样编写 python 代码就更方便了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#!/usr/bin/env pythonimport sysimport pcapyimport socketfrom struct import *def parse_packet(packet): wifi_length = 0x32 //【1】 if len(packet) &lt; wifi_length: return None wifi_protocol = packet[0x30 : wifi_length] wifi_protocol = unpack('!h' , wifi_protocol) //【2】 wifi_protocol = wifi_protocol[0] # ip protocol if wifi_protocol == 0x0800: ip_header = packet[wifi_length : 20+wifi_length] iph = unpack('!BBHHHBBH4s4s', ip_header) version_ihl = iph[0] version = version_ihl &gt;&gt; 4 ihl = version_ihl &amp; 0xF iph_length = ihl * 4 protocol = iph[6] s_addr = socket.inet_ntoa(iph[8]) d_addr = socket.inet_ntoa(iph[9]) #udp if protocol == 17: u = iph_length + wifi_length udph_length = 8 udp_header = packet[u : u+8] udph = unpack('!HHHH' , udp_header) source_port = udph[0] dest_port = udph[1] length = udph[2] checksum = udph[3] h_size = wifi_length + iph_length + udph_length data_size = len(packet) - h_size #get data from the packet data = packet[h_size:] print(&quot;Data: &quot;) + data pcap = pcapy.open_live(&quot;wlx000f00906ff3&quot;, 65536, 1, 0) //【3】while (1): (header, packet) = pcap.next() parse_packet(packet) 【1】802.11 协议比较复杂，事实上，在 IP 层外不止封装了一层。通过 Wireshark 捕捉 UDP 包可以看到格式，这里我直接把 IPv4 协议上层封装全作为一层处理了。 【2】unpack 函数可以把一个字符串（python 里字符数组亦被用来存储原始二进制数据，毕竟一个 char 正好对应一个字节）按照格式解析，并返回一个元组。最前面的感叹号代表网络字节序。网络字节序是大字节序，和我们 x86 上常见的小字节序相反，要特别小心。从大字节序转换成小字节序可以用 ntohs 函数，当然也可以自己反转。 【3】wlx000f00906ff3 是我的网卡 interface 的名字。 测试编写一个 shell 脚本来测试程序是否能抓到 UDP 包： 12345for i in {1..1000}do echo -n &quot;hello world!&quot; | ncat -u 192.168.1.255 8080done 使用 ncat 来向广播地址发送简单的 UDP 包。当然这里不一定是广播地址，毕竟什么包都能抓到…… 我测试时，主机通过以太网连接无线路由器，主机未接入无线局域网，但是程序可以通过无线网卡抓到包。使用另一台树莓派作为 AP 发送 UDP 包，同样可以抓到。 Alternate Choice也可以考虑简历一个虚拟网卡，让小车同时接入两个网络。这样在发生切换时，保证另一个网络仍是畅通的。如果 Wi-Fi 网络不加密，建立连接的速度也会比较快。","link":"/2019/04/22/WiFi%E7%9B%91%E5%90%ACUDP%E5%8C%85/"},{"title":"Try-Catch Segmentation Fault in C","text":"Try-Catch Segmentation Fault in C这篇文章对 C / C++ 老油条来说应该是属于基本操作了，但是对平时不怎么写 C 的我来说还是值得记录一下的。 起因是在写 OS 课的作业时（是的，历经千辛万苦，我终于选到了 OS 课 🎉，希望一切顺利 🙏），发现有时难以判断哪些指针是合法的，哪些是非法的。于是我想：与其费尽心机挨个检查地址范围，不如就让它抛出 SIGSEGV，然后捕获住做异常处理就好了。就像我们在其他的高级语言里非常自然的异常处理那样： 12345try { access_illegal_address() // do something really dangerous} catch e { print(&quot;haha, I didn't crash.&quot;)} 可惜 C 语言中并没有 try-catch 语句。 就算有呢？等等…… 虽然 C 不支持 try-catch，但是 C++ 支持呀。如果我们小小的作弊一下，允许使用 C++ 的话，我们是不是就可以通过 catch 住 Segmentation Fault 来检查指针是否合法了呢？答案是——也不行。因为 C++ 的 try-catch 只能捕获 C++ 语言本身的异常。Segmentation Fault 作为更底层的异常，并不会被捕获，程序还是会 crash。 使用 Signal Handler这个时候问题很多的小明就要问了，那我们不如用 Signal Handler 来捕获 SIGSEGV 好了！这当然是没问题的。如果我们直接在 Stack Overflow 搜索，也会看到许多回答提到使用 Signal Handler。但是，多数答案只提到了如何捕获信号，但是在 handler 里只是简单的 print 一句，就早早的 exit(0) 了。这并不符合我们的要求。 如果不 exit 程序呢？正常的 signal handler 返回后，操作系统会继续执行中断产生时的下一条指令，让程序继续运行。而 SIGSEGV 发生时，访问野指针的指令显然并未完成，因此会重新执行这条指令。除非我们在 signal handler 里修复好了指针地址，让其变得合法，否则重新执行一遍显然又会抛出 SIGSEGV。这样就会无限地调到 signal handler，让程序进入死循环。 破解这个死循环的方法就是，跳出循环 😊。 类 Try-Catch 实现我们可以通过 setjmp 函数家族跳转到 catch 对应的位置。由于是在 signal handler 中，因此应当使用 sigsetjmp 和 siglongjmp 函数对。具体实现如下： 1234567891011121314151617181920212223242526272829#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;setjmp.h&gt;#include &lt;signal.h&gt;#include &lt;stdio.h&gt;sigjmp_buf buf;void segfault_handler(int sig) { siglongjmp(buf, 1);}int main(int argc, char **argv) { struct sigaction sa; memset(&amp;sa, 0, sizeof(struct sigaction)); sigemptyset(&amp;sa.sa_mask); sa.sa_handler = segfault_handler; sa.sa_flags = SA_ONSTACK; sigaction(SIGSEGV, &amp;sa, NULL); if (!sigsetjmp(buf, 1)) { // try int *p = NULL; *p = 6; // of course, this is illegal } else { // catch printf(&quot;caught seg fault!\\n&quot;); } return 0;} 注册 signal handler 的部分比较直观，这里不做赘述。setjmp 函数稍微有点难以理解。这个函数被调用一次后，会返回两次。第一次也就是正常设置 buffer，它会返回 0。因此会进入到所谓的 try block 中。当异常产生时，在 handler 中会调用 longjmp 函数。它与 setjmp 成对使用，表现刚好相反。调用一次时，它并不会返回。相反，它会通过修改一系列 context 寄存器，让 setjmp 函数返回第二次。本次的返回值可以自己定义，这里我们返回 1，于是进入到了所谓的 catch block 中。异常就被捕获了。 TL;DR： setjmp 调用一次，返回两次。 longjmp 调用一次，返回零次。 综上，C 语言函数都会且只返回一次吗？答案是不一定哦。","link":"/2023/01/23/c-try-catch/"},{"title":"Channel Attention (CBAM)","text":"Channel Attention (CBAM)注意力机制通过关注相对重要的特征、抑制不必要的特征来对数据进行加权，从而更有利于神经网络总结出数据的规律。通道注意力就是在通道的维度计算出一个权重，也就是给每个通道的重要性打分。比较常用的网络是 SE-Net。 CBAM（Convolutional Block Attention Module）是 ECCV18 的一份工作，以一种简单的方式分别对通道和空间进行注意力计算。CBAM 非常轻量，且易于集成到现有的网络中。由于我们的项目中主要想应用通道注意力，因此可以简单地将后半部分（空间注意力）舍弃。 原理CBAM 论文中提到，SENet 只使用了 average pooling 来做通道注意力的计算，但这并不是最优的做法。CBAM 的通道注意力同时使用了 average pooling 和 max pooling。具体做法如下： 对输入进来的特征图分别做 max pool 和 average pool，沿空间的维度进行压缩，得到两个 1 维的向量（C x 1 x 1）。之后，把这两个向量输入进一个共享的 MLP 中，对结果进行 element-wise 的加和。最后通过一个 sigmoid 激活函数，输出得到通道注意力的分数。 其中使用的 MLP 只有一个隐含层。如果希望减少参数量，可以让隐含层的维度小一些，从而形成一个类似 bottlenet 的结构。 公式如下：$$Mc(f) = \\sigma(MLP(MaxPool(f)) + MLP(AvgPool(f)))$$ PyTorch 实现原理比较简单，因此代码实现也并不复杂： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class ChannelAttention(nn.Module): def __init__(self, input_channels, reduction_ratio): super().__init__() self.input_channels = input_channels self.reduction_ratio = reduction_ratio self.hidden_dim = int(self.input_channels / self.reduction_ratio) self.mlp = nn.Sequential( nn.Linear(self.input_channels, self.hidden_dim), nn.ReLU(), nn.Linear(self.hidden_dim, self.input_channels) ) def forward(self, x): shape = (x.shape[2], x.shape[3]) avg_pool = F.avg_pool2d(x, shape) max_pool = F.max_pool2d(x, shape) avg_pool = avg_pool.view(avg_pool.shape[0], -1) max_pool = max_pool.view(max_pool.shape[0], -1) avg_pool = self.mlp(avg_pool) max_pool = self.mlp(max_pool) pool_sum = avg_pool + max_pool sig = torch.sigmoid(pool_sum) sig = sig.unsqueeze(2).unsqueeze(3) return sigclass CBAM(nn.Module): ''' CBAM only W/ channel attention ''' def __init__(self, input_channels, reduction_ratio): super().__init__() self.input_channels = input_channels self.reduction_ratio = reduction_ratio self.channel_attention = ChannelAttention(input_channels, reduction_ratio) def forward(self, f): attention_score = self.channel_attention(f) fp = attention_score * f return fp CBAM 模块可以很容易地插入已有的网络中，比如 MobileNet v2: 123456789101112131415161718192021222324252627class MobileNet(torchvision.models.MobileNetV2): def __init__(self, attention_loc='none', input_channel=6, **kwargs): super().__init__(**kwargs) self.attention_loc = attention_loc if self.attention_loc == 'last': self.channel_atten = CBAM(input_channels=self.last_channel, reduction_ratio=1.0) elif self.attention_loc == 'first': self.channel_atten = CBAM(input_channels=input_channel, reduction_ratio=1.0) conv = self.features[0][0] self.features[0][0] = nn.Conv2d(input_channel, conv.out_channels, conv.kernel_size, conv.stride, conv.padding, groups=1, bias=False) nn.init.kaiming_normal_(self.features[0][0].weight, mode='fan_out') def _forward_impl(self, x): if self.attention_loc == 'first': x = self.channel_atten(x, return_score=return_score) x = self.features(x) if self.attention_loc == 'last': x = self.channel_atten(x, return_score=return_score) x = nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1) x = self.classifier(x) return x 一般来说，CBAM 有两种使用方式：一是在每个残差块中间都使用，二是只用在最后的全连接层之前，只对最终的 feature map 做注意力加权。这里我只实现了应用在输入层（first），或最后一层（last）。 验证为了验证代码实现的正确性和有效性，我在 CIFAR-10 数据集上做了一个粗略的对比实验。CIFAR-10 是一个十分类的数据集，包含了 60,000 张 32x32 大小的彩色自然图像，类别有飞机、轮船、猫、狗等。该数据集规模较小，比较适合快速验证。 由于每张图片大小仅有 32x32，而 MobileNet 的默认输入是 224x224，如果直接输入，卷积核的尺寸就会显得过大了。出于简便，图像全部被 resize 到 112x112 再输入。这样可以在不太影响运行速度的情况下，尽量不牺牲分类精度。初始 LR 0.01，Batch Size 32，训练 20 个 epoch。 实验结果如下： Model Top 1 Acc MobileNet Baseline 84.53% MobileNet + Attention (Last) 85.47% 为了验证注意力机制缺失更 focus 在重要的通道上，还做了另一组实验。在正常的 RGB 三通道输入上再叠加三个随机噪声通道，即输入变为 6 通道： 实验结果如下： Model Top 1 Acc RGB Input Baseline 84.53% RGB + Random Noise 83.73% RGB + Random Noise + Attention 84.34% 可见增加了三个噪声通道后，确实对网络造成干扰。使用注意力机制可以把精度补救回来。使用分类精度最高的模型，在测试集上随机选取 64 张图片，统计平均通道注意力数值，数值和可视化结果如下： 10.9846477, 0.96408206, 0.91101015, 0.00664441, 0.0050977, 0.00696521 可见前三个通道的注意力分数确实远高于后三个随机噪声通道，符合直觉。","link":"/2021/05/11/cbam-channel-attention/"},{"title":"Backpropagation and Computational Graphs","text":"Backpropagation and Computational Graphs我在大四的时候上过一门课叫 Computational Intelligence，当时有一次作业就是写一个简单的神经网络。遗憾的是当时并不了解向量化的含义，对反向传播的理解也只局限于每个神经元怎么更新自己的权重。可想而知，当时我写的是一个很不优雅、运行效率很低的程序。现在试着从另一个视角来理解神经网络和反向传播算法。 Neural Networks一般我们理解的神经网络都是如下的结构： 一个个神经元互相连接，非常直观，也很像我们大脑中神经网络的样子。但其实完全可以用纯数学的方式（不掺杂一点生物学概念）来理解神经网络。它其实就是一个线性分类器，经过一个非线性函数后，再输入给下一个线性分类器…… 中间的非线性函数是必不可少的，否则整个神经网络就将塌缩成一个大的线性分类器。 普通的线性分类器可以表示为：$$s = W\\cdot x$$其中 x 是输入，如果是一个 32x32x3 的图像的话，就可以表示为（3072, 1）的列向量。W 作为参数为（10, 3072）的矩阵。这样相乘得到一个十个元素的向量，对应 10 个不同分类的得分。 那么一个两层的神经网络就可以表示成：$$s = W_2max(0,\\space W_1 x)$$其中的 max 就是上述的非线性函数，被称为 ReLU（Rectified Linear Unit）。当然我们还有很多很多其他的非线形函数可以选择，比如 tanh 或者 Sigmoid 函数。这个函数也就是所谓的激活函数（activation function）。这样的神经网络看起来就像下图的样子。 类似地，三层的神经网络可以表示为：$$s = W_3max(0,\\space W_2max(0, \\space W_1 x))$$W1, W2, W3 也就是我们要通过 SGD（Stochastic Gradient Descent）学习的参数。 Cross-Entropy Loss (Softmax)为了优化参数，我们需要定义一个损失函数（Loss Function）。我们仍然可以使用 Softmax 分类器的交叉熵损失函数。交叉熵把输出的 score 看作是概率。$$L_i = -log(\\frac{e^{f_{yi}}}{\\Sigma_je^{f_j}})$$log 里面的部分即为 softmax 函数。这个函数把一个普通的向量中的元素都压缩到 0 至 1 的范围内，并让他们相加得 1，这样就可以用概率来解释了。 上面的公式等价于：$$L_i = -f_{y_i} + log\\Sigma_je^{f_j}$$Softmax 分类器既可以用概率论的视角也可以用信息论的视角来解读。这里我们只关心这个损失函数。 我们可以写出计算 loss 的 numpy 代码： 12345678910111213141516def loss(self, X, y=None, reg=0.0): W1, b1 = self.params['W1'], self.params['b1'] W2, b2 = self.params['W2'], self.params['b2'] N, D = X.shape scores = None loss = None out1 = np.maximum(0, X.dot(W1) + b1) # relu, (N, H) scores = out1.dot(W2) + b2 # (N, C) correct_class_score = scores[np.arange(N), y].reshape(N, 1) exp_sum = np.sum(np.exp(scores), axis=1).reshape(N, 1) loss = np.sum(np.log(exp_sum) - correct_class_score) loss /= N loss += 0.5 * reg * np.sum(W1 * W1)+ 0.5 * reg * np.sum(W2 * W2) 注意最后还要加上正则项（这里用的 L2 正则），它可以让模型的参数尽量简化。 Computational Graph of NN计算图可以用来表示任意的数学表达式。它可以自动微分的特性使得主流的深度学习框架都以计算图为核心。一个两层的神经网络可以画成： Backpropagation我们需要 loss 和 gradient 才能使用 SGD 来学习参数。通过正向传播，很容易计算出 loss，而 gradient 就要通过反向传播来计算。 即我们要求出以下四个导数的值：$$\\frac{\\partial J}{\\partial W_1},\\space \\frac{\\partial J}{\\partial W_2},\\space \\frac{\\partial J}{\\partial b_1},\\space \\frac{\\partial J}{\\partial b_2},\\space$$从后向前计算：$$\\frac{\\partial J}{\\partial L} = 1 \\\\frac{\\partial J}{\\partial o} = \\frac{\\partial J}{\\partial L} \\cdot \\frac{\\partial L}{\\partial o} = \\frac{\\partial L}{\\partial o}$$Recall Softmax 函数：$$L_i = -o_{y_i} + log\\Sigma_je^{o_j}$$可以看到这里有两项 o，因此分开算：$$\\frac{\\partial L_i}{\\partial o_{y_i}} = -1 \\\\frac{\\partial L_i}{\\partial o_{j}} = \\frac{\\partial log\\Sigma_je^{o_j}}{\\partial o_{j}}=\\frac{e^{o_j}}{\\Sigma e^{o_j}}$$继续对 W2 求导可得：$$\\frac{\\partial J}{\\partial W_2} = \\frac{\\partial J}{\\partial o}\\cdot h + \\lambda W_2$$我们可以写出对应的代码： 1234567margin = np.exp(scores) / exp_summargin[np.arange(N), y] += -1margin /= N #(N, C)dW2 = out1.T.dot(margin) #(H ,C)dW2 += reg * W2 grads['W2'] = dW2grads['b2'] = np.sum(margin, axis = 0) 类似地，求解 W1 和 b1 的导数代码为： 123456margin1 = margin.dot(W2.T) #(N, H)margin1[out1 &lt;= 0] = 0 # 正向传播时 ReLu 过滤掉了一部分，这部分实际上对 loss 是没有任何贡献的。因此反向计算时也要把这部分排除dW1 = X.T.dot(margin1) #(D, H)dW1 += reg * W1 grads['W1'] = dW1grads['b1'] = np.sum(margin1, axis = 0) 可以看到，我们在正向计算时缓存了一些中间变量，而反向计算时就可以直接使用了，这有一些动态规划的意思。而且整个计算时全向量化的，没有嵌套循环。Numpy 底层使用 C 编写，本身循环速度会比 python 快很多，再加上许多优化处理，例如优化缓存命中率或利用 CPU 的 SIMD 指令等，因此非常高效。向量化得代码还有助于后续在 GPU 上加速计算。","link":"/2020/08/09/backprop-and-comp-graph/"},{"title":"CS336 Study Note - Assignment1","text":"CS336 Study Note - Assignment 1Stanford CS336 学习笔记 作业 1 主要涵盖以下几个方面： BPE tokenizer 从头搭一个 Transformer LM，包括要手写 Multi-head attention，RoPE 训练相关的 AdamW 优化器，top-p 采样等 总体来说工作量还是比较大的。我的精力主要放在理解原理和保证代码的正确性上，由于学习时间有限，像性能调优以及跑实验对比参数等就略过了。写完这次作业收获很大，这篇文章用来记录下我当时比较 confused 的点，以及一些 insight。 BPEBPE 属于一听原理都懂，但是真的动手写还是有些挑战的。我觉得 BPE 可能是作业 1 里最花时间的一部分了。这个算法整体是这样工作的： 初始化 vocabulary，要把 special token 和 0-255 这种单字节的所有可能值放进去。这样任意的字符串都能编码，即使有 BPE 训练时没见过的表示。比如，用户输入了一个特殊的字符，这个字符在训练集里从未出现过。 把输入的字符串用 unicode encode 成 a list of bytes。注意 unicode 是可变长的编码，一个字符可能占多个字节。 special token 永远不能再分割。为了方便，还会做 pre-tokenize，大概就是用一个正则尽量按单词划分。 以 pre-tokenize 分割的“单词”里，每两个 byte 为一组，统计频率。例如 [32, 12, 5] 就要分别统计 (32, 12) 和 (12, 5) 出现的频率。Pre-tokenize 之后就不考虑跨“单词”的 pair 了。分割单词还有个好处，就是可以统计单词词频，然后用单词内 byte pair 的频率乘单词词频就能统计全文的 byte pair 频率，提高效率。 选择频率最高的 byte pair，如果有相同的，按字典序 break tie。讲这个合并后的 byte pair 作为新的 vocab，并赋予 token id。把全文中所有出现该 pair 的地方用心的 token 替代。例如 [32, 12, 5] 中，假设 (32, 12) 被替换成了 258，那就变成 [258, 5]。 重复这个过程。过程中，vocabulary 会逐渐增多，直到达到 vocab_size 的 limit 后停止。 保存 vocabulary （即 bytes -&gt; token id），以及 merge 的顺序。保存顺序是为了 encode 的时候能按照训练时同样的顺序合并。否则，假如 (32, 12) 和 (12, 5) 都在 vocab 里，[32, 12, 5] 应该先合并哪个呢？答案是，如果训练的时候 (12, 5) 先合并的，encode 的时候也应该先合并 (12, 5)。 Byte Level Pair?顾名思义，我一开始认为所有的 pair 都是在 byte level 操作的。这个命名有点误导性。真正操作应该是在 token (id) level 的。 假设输入的字符串转化成 byte 是 [32, 12, 5]。我们有一个 special token EOS。那么，我们可以这样初始化： Bytes Token ID EOS （special token 是不可分割的整体） 0 0 （单 byte，value 是 0） 1 1 2 … … 那转化成 token，就应该是 [33, 13, 6]，注意这里就是 token ID 了，也就是我们可能会看到 [1000, 5000, 2] 这样的 list。然后所有的 merge 和替换，应该都在 token level 进行。 Bytes -&gt; ID or ID -&gt; Bytes？两个方向的映射都需要，可以存一个，推断出另一个。 字典序（lexicographically greater pair）我当时有个疑问，break tie 时用的字典序是应该从 bytes 之间比较，还是转换成 character 再比较？毕竟字典序听起来像是 character 之间的比较。其实应该是 byte 的，毕竟两个 byte pair 都不一定能组成合法的 unicode character。 我觉得 lexicographically order 只是形容排序方法，即先比第一个，再比第二个（像字典的排序），和字符不字符没关系，两个整型数组也能比。 Yield如果想要返回一个 iterable，可以用 yield 关键字。这个我平时用的比较少，我的思维还停留在 coroutine 的时候 CPU yield :) 123def encode_iterable(self, iterable: Iterable[str]) -&gt; Iterator[int]: for chunk in iterable: yield from self.encode(chunk) 性能优化以下是一些可以用来优化性能的地方（我就没有实现了）。 第一当然是多线程。在统计词频，包括 encode，和替换 merge pair 的时候，都可以分配给多个线程处理再汇总。 在统计频率之后，每次 merge 后并不需要全量再统计一遍新的频率。可以通过 track merge 产生的位置，就可以只更新受影响的词频。其余地方就不用再算一遍了。 维护最大值可以用一个 heap，就像 leetcode 经典的 top-k problems。 Encode 的时候，因为要按照 merges 的顺序合并，而不是简单的 bytes 先后合并，一个朴素的想法是从前往后遍历 merges。但这样很慢。一个更快的实现是，建立一个 merges_rank，即从 merged pair 到它在 merges 数组里位置的映射。rank 越小，优先级越高。之后遍历所有 pair，找到 rank 最小的 pair 合并。使用了这个 trick，本来需要跑几小时的代码几秒钟就完成了。 Transformer LM照着公式写 PyTorch 还是比手写 BPE 容易不少的。这里记录一下一些我已经生疏了的用法。 nn.Parameter以前我一直不知道 nn.Param 有什么用，感觉直接用 Python 的 class property 不就行了吗，为什么要包一层。毕竟，直接使用也会参与梯度计算。其实有两方面作用： 用 nn.Parameter 包裹后，就自动变成了 named param。在 load_state_dict 之类的时候，变量名就是 key。 会出现在 model.parameters() 里，优化器就可以直接更新它。否则即使有 grad，优化器也不会给它更新。 Advanced Indexing当 index 是一个 tensor 的时候，就会触发 advanced indexing。普通的索引只能找连续的切片。 比如在实现 Embedding class 的时候就能用到。Embedding 的 weight 其实是一个 (vocab_size, embedding_dim) 的 tensor。这里 embedding_dim 也就是 d_model。说白了，就是给一个 token id，返回一个 d_model size 的 embedding vector 的字典。当输入是 batch_size 乘 seq_length 个 token id 的时候，我们不需要写循环一个一个的取 embedding，而是用 advanced indexing 就可以批量取出来。 12345678910class Embedding(torch.nn.Module): def __init__(self, num_embeddings, embedding_dim, device=None, dtype=None): super().__init__() weight = torch.zeros((num_embeddings, embedding_dim), device=device, dtype=dtype) torch.nn.init.trunc_normal_(weight, mean=0, std=1, a=-3, b=3) self.weight = torch.nn.Parameter(weight) def forward(self, token_ids: torch.Tensor) -&gt; torch.Tensor: out = self.weight[token_ids] # advanced indexing return out Numerical Stability这个其实还蛮重要的。如果不用上一些 trick 保证 numerical stable，那么可能产生 NaN 或者 INF。我还在实现 temperature scaled softmax 的时候忘记使用 trick，导致 CUDA 崩溃，报错： 1CUDA error: device-side assert triggered 找了半天发现是因为算 softmax 时不稳定导致的。这个还挺难 debug 的。 总结下来，这个作业里有两处要注意，一个时 softmax，一个是 sigmoid，都有一些 trick 来让数值更稳定。 Softmax为什么 softmax 运算要用 exp，而不是直接用线性归一化呢？有以下三个原因： logits 可能有负数，出现负概率就不对了。用 exp 可以把数值都缩放到 0 至正无穷。 exp 的导数简单，梯度平滑，方便训练。 指数能放大差距，让大的数占据主导（所以叫 soft-max）。 RoPE由于 attention 操作是位置无关的，所以需要引入位置编码来引入 token 的位置信息，因为显然“我爱你”和“你爱我”的含义是非常不同的。为什么 self attention 是位置无关的呢？我们看它的公式：$$Attention(Q, K, V) = softmax(\\frac{Q^TK}{\\sqrt{d_k}})V$$注意这里 QKV 都是 (…, seq_len, d_model) 维度的。假设输入是 [x1, x2, x3]，输出是 [y1, y2, y3]，那么如果交换 x1, x3 的位置，得到的 y1’ 和 y3’ 实际上是没变的，只是位置跟着做了同样的改变，即输入变为 [x3, x2, x1] 输出变为 [y3, y2, y1]。换句话说，这是 permutation equivalent 的操作。即 token 之间注意力的相对大小没有改变，这不符合直觉。 举例来说，“我打你很痛”，和“你打我很痛”，前者应该的”你“和”痛“应该注意力很高；后者应该是”我“和”痛“注意力高。如果注意力大小一致的话，模型就感知不到是谁痛这层的信息了。 RoPE 是一种相对位置编码，这篇文章讲解的很好。对位置 i 的高维向量，两两一组做二维旋转变化来赋予位置信息。从公式来看：$$R_k^i =\\begin{bmatrix}cos(\\theta_k^i) &amp; -sin(\\theta_k^i) \\sin(\\theta_k^i) &amp; cos(\\theta_k^i)\\end{bmatrix}$$可以看到，旋转的角度即取决于该向量在 sequence 里的位置 i，又取决于维度 k。这样可以让模型获得多尺度的位置感知能力，从而学会在不同的维度上学习不同的东西。在低维度，旋转变化慢，适合学长距离关系；在高维度，旋转快，适合学短距离关系。 为什么说是相对位置编码呢？因为考虑两个位置的向量，一个旋转了 p 度，另一个旋转了 q 度，他们相对旋转了 p - q 度。对于注意力机制来说，有如下性质（尖括号代表注意力的 dot product 运算）：$$\\langle R_{\\theta_p} q,\\, R_{\\theta_q} k \\rangle = \\langle q,\\, R_{\\theta_{p - q}} k \\rangle$$在 PyTorch 实现的过程中，我遇到了以下几个有意思的点： 可以利用 register_buffer 来把参数添加为模型的一部分，但是不参与优化（不进入 parameters）。虽然不参与优化，但是可以跟随 .to(device) 移动，也可以 load_state 时保存。 repeat_interleave 在构造两两重复的 cos 和 sin 值的时候很实用。 用 x_for_sin[..., 0::2] = -x[..., 1::2] 可以间隔地给 x 加上负号。 Attention在看 attention 的公式的时候，我产生了一个疑问：QK 的点积是在算相似度，这很好理解，但是为什么要除以根号下 d_k？这是因为 QK 是很多个随机变量的乘积的和。虽然期望为 0，但是方差是 d_k。下面解释为什么方差是 d_k： 我们假设 Q 和 K 里每个元素都是 iid 的，期望为 0，方差为 1。内积 s = QK 的方差为：$$Var(s) = E(s^2) - (E(s))^2 = E(s^2)$$因为 E(s) 是 0。展开：$$E(s^2) = E((\\sum q_ik_i)^2)$$展开这个多项式的平方，把 E 换到里面，就有：$$E((\\sum q_ik_i)^2) = \\sum_i E((q_ik_i)^2) + \\sum_{i \\neq j} E(q_ik_iq_jk_j)$$因为 iid 且期望为 0，因此第二项为 0。又因为 q 和 k 独立，因此：$$E((q_ik_i)^2) = E(q_i^2) \\cdot E(k_i^2)$$由于 Var(q) = 1，因此有 Var(q) = E(q^2) - E(q)^2 = 1，所以 E(q^2) = 1。那么：$$E((q_ik_i)^2) = 1 \\Var(s) = \\sum_i E((q_ik_i)^2) = \\sum_{i}^{d_k}1 = d_k$$所以，$$Var(\\frac{Q^TK}{\\sqrt{d_k}}) = (\\frac{1}{\\sqrt{d_k}})^2 \\cdot Var(Q^TK) = \\frac{1}{d_k} \\cdot d_k = 1$$这样，就把整体的方差从 d_k 转化成了 1，避免了数值可能过大的问题，便于优化。 TrainingCross Entropy Loss在 Transformer LM 中，Cross Entropy Loss 的定义如下：$$l(\\theta; D) = \\frac{1}{|D|m} \\sum_{x \\in D} \\sum_{i=1}^{m}-\\mathrm{log} p_{\\theta}(x_{i+1}|x_{1:i})$$其中，D 是训练集，m 是 seq_len，p 代表给定前序的 token，预测下一个 token 的概率，即模型输出的 logits 过 softmax 之后算出的概率。加和求平均值的概念比较好理解，我的疑问是，为什么这就是 cross entropy？ 首先回顾下信息论中 entropy 的定义：$$H(P) = -\\sum_xP(x)\\mathrm{log}P(x)$$熵用来衡量一个分布的不确定度或信息量，即概率小（惊讶程度越高），熵越大。所以要用每种 x 的可能取值的概率做加权。取 -log 作为信息量的衡量，是因为 log 可以把多个随机变量的概率相乘变成相加，便于计算；而负号让大的概率变成小的信息量。 交叉熵用来衡量两个概率分布的差距：$$H(P, Q) = -\\sum_{x}P(x)\\mathrm{log}Q(x)$$其中 P 是真实分布（ground truth），Q 是模型的预测（softmax 概率）。 P 经常是 one-hot 编码，所以只有正确的时候是 1，其他所有 case 都是 0。换句话说，CE loss 只在意正确的分布大小。在我们这里，传入的 targets 是正确的 token id (index)，所以可以用 torch.gather 函数收集正确 index 上的 logits 值。 这里也有一些数值稳定性的优化，包括减去最大值，以及 cancel out log 和 exp，等。 AdamWAdamW 是一个有状态的优化器，它可以自适应学习率，让每个参数都能独立调节步长。同时还有 weight decay，防止参数过大。这其中涉及到估计梯度的一阶矩 (first moment) 和二阶矩 (second moment)。一阶矩是梯度的期望，即梯度的平均方向，即动量。二阶矩是梯度平方的期望，即波动大小。 在估计一二阶矩的时候，采用的是指数加权平均（EMA）的 online estimation。这是对历史梯度的加权平均，即越近的梯度权重越大，越老的梯度权重呈指数衰减。 Next Token Prediction平时总说 LM 就是预测下一个词，这让我之前产生了一个印象，即模型的输入应该是 tokens，如 [x1, x2, x3]，输出应该是下一个 token，即 y = x4。其实这是不对的。模型的输出，是对每一个位置的下一个词的预测。即，模型的输出应该是 [y1, y2, y3]，对应的 ground truth 应该是 [x2, x3, x4]。只不过在 test time，我们只取出最后一个 token 的预测。 那因果性（causality）怎么保证呢？训练时，如果输入输出 pair 是 ([x1, x2, x3], [x2, x3, x4])，模型不是已经提前看到了 x1 的下一个 token 是 x2 了吗？答案是，在 attention 的计算中， 我们传入了 causal mask 来过滤掉未来的 token。 具体来说，在计算 attention 的时候，我们算出来的 attention score 会在违反因果性的地方（mask）被设置成 -inf。这样通过 softmax 之后会变成 0，从而让模型无法在该位置看到后面的信息。再具体一点，每个 token 只能和左侧的 token 算出 attention，和右侧的永远会被重置成 0。 既然 attention 的因果性保证了，那网络的其他部分会不会破坏掉因果性呢？这是不会的。拆解来看，embedding 层，encoding，FFN，RMSNorm，Residual，全部都是在每个位置独立计算的，不会横跨 token；即他们都把 seq_len 维度当作 batch 维度对待。Attention 是唯一一个例外。 Text GenerationDecoding &amp; Top-P Sampling当我们有了一个能 predict next token 的模型，怎么 decode 出文本呢？我的直觉是：这还不简单吗，找到概率最大的 token id，然后查询 vocab 中对应的 bytes 不就好了。这被称为 greedy decoding，是可行的，但是让 model 失去了生成多样性回答的能力。更好的办法是根据概率采样。 Decoding 有两个 trick，第一个是 temperature scaling。其实就是算 softmax 的时候引入一个额外的温度参数。温度高，就把概率的差距改小了，那模型的输出就更随机一些。温度低，就退化成了 one-hot，接近 greedy decoding。 另外就是 top-p 了。原理很简单，就是把概率排序，找到概率最大的几个元素，使他们的概率和不超过 p。之后只在这几个大概率的 token 中采样。","link":"/2025/10/25/cs336-assignment-1/"},{"title":"Spatial Attention (CBAM)","text":"Spatial Attention (CBAM)在之前的博客中介绍了 CBAM 中的通道注意力，为了保持完整性，这次介绍剩余的空间注意力（Spatial Attention）部分。 原理在理解通道注意力后，CBAM 中的空间注意力就非常好理解了，两者异曲同工。其原理图如下： 空间注意力通过获取特征图相邻空间的信息来计算，是为了告诉神经网络“哪里”更重要，从而强化重要的部分并抑制不重要的部分。Feature map 首先被沿着通道的维度被 MaxPool 和 AveragePool 压缩。假设原来的维度是 CxWxH，就会分别被压缩成两个 1xWxH 的张量。这两个张量被拼接在一起，形成 2xWxH 的张量，如图中蓝色、橙色所示。接下来把这个拼接在一起的张量通过 7x7 的卷积，对重点区域编码。最后通过一个 Sigmoid 函数形成注意力得分 Ms。Ms 与原始数据相乘即可。其公式为：$$M_s(F) = \\sigma (f^{7\\times 7}([AvgPool(F); MaxPool(F)]))$$ PyTorch 实现实现起来比较容易： 123456789101112class CBAMSpatialAttention(nn.Module): def __init__(self): super().__init__() self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=3, stride=1, padding=1) def forward(self, x): max_pool = torch.max(x, axis=1, keepdim=True)[0] mean_pool = torch.mean(x, axis=1, keepdim=True) cat = torch.cat([max_pool, mean_pool], dim=1) out = self.conv(cat) out = F.sigmoid(out) return out * x, out Experiment为了快速验证，简单的训练了一个 MNIST 分类器，并只把注意力模块插到了网络最前面一层，即对输入图像应用注意力机制。由于 MNIST 数据集图片尺寸比较小，因此没有严格按照 CBAM 使用 7x7 的卷积核，而是使用了 3x3 的。虽然 MNIST 是灰度图像，只有一个颜色通道，计算 MaxPooling 核 AveragePooling 没有任何意义，但这里还是为了通用性计算了一下。输入图像如下： 每张图片对应的空间注意力得分可视化如下： 其中越绿的地方代表数值越高，越黄的地方代表数值越低。可以看到网络确实在强调数字本身，抑制了边缘分界的地方，而对黑色的背景几乎不感兴趣。猜测这样可以让边缘差异更大，有利于后面的 CNN 捕获特征。 由于 MNIST 随便训练一下准确率就到了 99%，因此没有对比空间注意力带来的分类精度的提升。","link":"/2021/07/04/cbam-spatial/"},{"title":"Custom Plot Tensorboard","text":"Custom Plot TensorboardTensorboard 是一款非常好用的深度学习可视化工具，而且它并不依赖 TensorFlow 本身。这样即使项目使用的是 PyTorch，也仍然可以用 Tensorboard 来记录日志。在撰写论文或报告的时候，我们有时候会想绘制一个 Loss 变化的曲线图。这个时候就不得不去读取 Tensorboard 文件，自己画图了。毕竟总不能直接在网页上截图吧…… Read local tensorflow dataTensorboard 的文档提供了一种将 Tensorboard 数据转化成 pandas DataFrame 的方式。但是必须要将日志文件上传到他的服务器。文档中还特别描写了读取本地日志的功能还没有实现，以后才会添加： Note: 1. This API is still in its experimental stage, as reflected by its API namespace. This means the API may be subject to breaking changes in the future. 2. Currently, this feature supports only logdirs uploaded to TensorBoard.dev, a free hosted service for persisting and sharing your TensorBoard. Support for locally stored TensorBoard logdir will be added in the future. Briefly, you can upload a TensorBoard logdir on you local filesystem to TensorBoard.dev with a single line of command: tensorboard dev upload --logdir &lt;logdir&gt;. See the documentation at tensorboard.dev for more details. 刚看到这个文档觉得有点绝望，经过一番查阅，其实 Tensorboard 是提供了 API 给我们来读本地的日志文件的，只不过不是 DataFrame 的格式而已： 1234from tensorboard.backend.event_processing.event_accumulator import EventAccumulatorevent_base = EventAccumulator('&lt;path/to/your/log/folder&gt;')event_base.Reload()wall_time, step_nums, values = zip(*event_base.Scalars('val/top1_acc')) 拿到散点的原始数据，剩下的工作就变成常规的画图了。 Plot with SeabornSeaborn 是 Matplotlib 的上层封装，用它画图比直接用 Matplotlib 要简单许多。如果画一条折线图，只需要一行代码就可以实现： 12import seaborn as snssns.lineplot(x=x_array, y=y_array) 由于想把多个折线绘制在一个图里方便对比不同算法的效果，就需要封装一个 DataFrame 来传给 Seaborn。 1234567891011121314import pandas as pdfrom matplotlib import pyplot as pltimport seaborn as snsdata = pd.DataFrame({ 'epoch': step_nums, 'baseline': vals_base, 'my_model_1': vals_1, 'my_model_2': vals_2,})plt.figure(figsize=(10, 8))plt.subplot(111)sns.lineplot(x='epoch', y='loss', hue='method', data=pd.melt(data, ['epoch'], var_name='method', value_name='loss')) 这里使用了 pandas.melt 函数，将不同的数值与名称对应起来。具体可以参考：https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html 截图？刚刚提到“总不能直接去网页上截图吧”，毕竟直接截图不清晰、截取多个图片大小难以保证一致，而且难免会截取到不相关的内容。但其实我们利用网页调试工具，就可以直接把页面元素导出截图。以 Safari 浏览器为例： 找到对应的元素，直接右键点击捕捉截屏即可。 效果还不错，所以截图其实也不是不可以…… 😄","link":"/2021/07/16/custom-plot-tensorboard/"},{"title":"Debugging iOS App Crashes with Hopper Disassembler","text":"Debugging iOS App Crashes with Hopper Disassembler当线上的 App 发生 crash 的时候，我们总能收集到 crash 报告。很多时候，只看 crash 报告的崩溃堆栈信息就能帮助我们定位到问题了。但要想获得更多的信息，有时候就不得不去反编译我们的程序。 本文记录了一次通过反编译来帮助定位问题的经过，算是一种探索和尝试吧。 确定代码负责人公司有自己的 crash 监控平台，上面看到了这样的一个堆栈情况（命名已脱敏）： 由于解析失败，其实只能看到系统的堆栈。但是如果配合 dsym 文件正常解析的话，是能看到这样的解析后的日志的： 123456789Thread 0 name: com.apple.main-threadThread 0: Crashed0 XXXXXXXXXXXXX 0x0000000104c66a64 __36-[XXXManager showObject:]_block_invoke.74 (in XXXXXXXXXXXXX) (XXXManager.m:158)1 libdispatch.dylib 0x000000018ae56610 __dispatch_call_block_and_release (in libdispatch.dylib) + 242 libdispatch.dylib 0x000000018ae57184 __dispatch_client_callout (in libdispatch.dylib) + 163 libdispatch.dylib 0x000000018ae3a34c __dispatch_main_queue_callback_4CF$VARIANT$armv81 (in libdispatch.dylib) + 9964 CoreFoundation 0x000000018b1085e4 ___CFRUNLOOP_IS_SERVICING_THE_MAIN_DISPATCH_QUEUE__ (in CoreFoundation) + 125 CoreFoundation 0x000000018b1035d8 ___CFRunLoopRun (in CoreFoundation) + 2004...... 看到解析后崩溃的代码，就可以实锤了。代码的作者（我本人）就不得不出来接锅了。 定位问题根据 crash log 提示的行号找到对应的代码： 可以看到是在调用一个 block 的时候崩溃的。作为一个典型问题，大概率也能猜出来原因，就是虽然在最外层判断了 object.showBlock 是否为空，但是执行到 dispatch_async 的时候，showBlock 可能又被释放了，需要再判断一次。 虽然是一个很简单的 crash，但是为了确定崩溃原因，可以反编译查看汇编代码。 反编译第一步，是要在打包平台上找到本次发布的 ipa 包。 下载对应的 ipa 文件后，解压缩（如果没有解压缩选项可以直接把后缀改成 .zip），进入后右键选择显示包内容，找到可执行文件。 我们使用 Hopper Disassembler 来反汇编。打开 Hopper，直接把可执行文件拖拽进去就可以了。期间 Hopper 解析会比较缓慢，要耐心等待，否则分分钟崩给你看。 可执行文件拖拽进去后，会询问解析哪种文件： 由于我这里崩溃的设备是 64 位的 iPhoneX，所以要选择 AArch64 。如果崩溃的设备是 32 位的，则选择 ARM v7 。再下一步的对话框中保持默认选项就好。 这个时候可以下载下来原始的 crash 日志（解析前）： 1234567Thread 0 Crashed:\\n0 XXXXXXXXXXXXX 0x0000000104c66a64 0x104080000 + 12479076 ((null)) + 0)\\n1 libdispatch.dylib 0x000000018ae56610 0x18adfb000 + 374288 ((null)) + 0)\\n2 libdispatch.dylib 0x000000018ae57184 0x18adfb000 + 377220 ((null)) + 0)\\n3 libdispatch.dylib 0x000000018ae3a34c 0x18adfb000 + 258892 ((null)) + 0)\\n4 CoreFoundation 0x000000018b1085e4 0x18b05f000 + 693732 ((null)) + 0)\\n...... 看崩溃日志的第一行： 10 XXXXXXXXXXXXX 0x0000000104c66a64 0x104080000 + 12479076 ((null)) + 0) 在 menu bar 中选择 Modify -&gt; Change File Base Address ，输入 base 地址 0x104080000。之后选择 Navigate -&gt; Go to Symbol or Address ，输入 0x0000000104c66a64，跳转到发生 crash 的指令。 在 0x0000000104c66a64 这行，LDR x0, [x0, #0x10] 。LDR 是 Load Register 指令，把内存中的值 load 到寄存器中。第一个 x0 是目标寄存器，第二个 x0 是源寄存器，它的值会和立即数 0x10 像加，得到一个地址。该地址在内存中的值会被 load 到 x0 寄存器中。 即在 x0 寄存器 + 0x10 的地址处取值时发生了崩溃。对应我们的 fault address 是 0x10，说明 x0 的值被错误的设置成了 0 （nil）。 往上追溯，最开始 x0 的值是从 x0 + 0x20 处获得的。 由于这段指令在一个子程序（procedure，也就是 OC 代码的 block）中，x0 - x7 寄存器是参数寄存器，而 x0 寄存器就是 block 本身的 isa 地址。 根据 block 的内存布局： 从 isa 开始偏移 0x20 (-0x68 + 0x20 = -0x48) 正好是第一个 capture 到的变量，对应我们的代码中也就是 object 对象。 之后调用了 msgSend 方法，x0 此时作为 Argument Register，被 msgSend 当作参数使用。 而 msgSend 中会查找 IMP 并调用，以下几种情况均可能造成返回值为 0（ARM64 汇编中也使用 x0 寄存器存储返回值） ： x0 本身就是 0，所谓的对 nil 发送消息。 没有找到 IMP，返回 0。 找到了 IMP，调用后结果为 0。 在当前的情况下，由于 block 本身 capture 到了 object，所以 object 不应该为 nil。showBlock 方法本身也存在，也不应该是没有找到 IMP。那么就只能是 showBlock == nil 了。也就是说，确实是调用一个 nil 的 block 导致的 crash。 解决方案虽然只要判断一下 block 是否为空就好了，但是为了避免多线程抢占的问题，如在刚刚判断完 block 是否为空的时候，其他线程释放了 block 的情况，最好这样来写： 12BlockType block = object.showBlock;!block ?: block();","link":"/2020/05/09/debug-crash-hopper-disassembler/"},{"title":"Derivation of VINS-Mono IMU Pre-integration","text":"Derivation of VINS-Mono IMU Pre-integration参考： https://arxiv.org/pdf/1708.03852.pdf https://arxiv.org/pdf/1912.11986.pdf https://github.com/MRwangmaomao/VSLAM/tree/master/VINS/VINS-Mono-code-annotation-master/paper If the pdf preview below is not working, click here to view.","link":"/2022/09/18/derive-vins-imu/"},{"title":"Design Patterns","text":"Design Patterns设计模式可以帮助我们更好地组织代码结构。模式是针对软件设计中常见问题的解决方案工具箱，它们定义了一种让团队更高效沟通的通用语言。每个模式就像一张蓝图，我们可以通过对其进行定制来解决代码中的特定设计问题。 CatalogCreational Patterns 创建型模式提供创建对象的机制，提升已有代码的灵活性和可复用性。 Structural Patterns 结构型模式如何将类和对象组织成更大的结构，同时保持结构的灵活和高效。 Behavioural Patterns 行为模式这类模式负责对象之间的算法和职责委派。 Creational PatternsFactory Method 工厂方法在父类中创建一个方法，在子类中决定实例对象的类型。调用工厂函数的代码无需关心不同子类之间对象的具体实现方式，只知道一组统一的接口定义就好。 举例：一个 UI 框架需要对不同的平台提供不同风格的按钮，比如 Material Design 或 Cupertino Flavor。那么就可以在定义一个 Creator，提供一个 object&lt;Button&gt; createButton() 的方法。然后两个具体的 Creator 继承自该类，并在实现中创建不同的按钮实例。当然所有的按钮实例都要实现统一的 Button 接口，从而对外屏蔽具体的实现细节。 还有一种情况，就是在资源密集型程序中，可以在工厂方法中使用重用池，可以避免污染外界代码。 Abstract Factory 抽象工厂抽象工厂与工厂方法很类似，只不过可以生产一组产品。例如一个 GUI 框架要提供 Button、CheckBox、ProgressBar 等等组件，每个组件又有多种风格，以适应不同的平台。 总的来说，抽象工厂生产抽象产品，背后是具体工厂实现具体产品。 Builder 生成器模式当构建一个对象需要非常多的参数时，可以把冗长的构造函数拆成多个步骤，例如： 1234buildWalls()buildDoors()buildWindows()... 外界（客户端代码）可以直接调用这些步骤，也可以抽象出一个主管类，来管理这些顺序。 首先需要一个 Builder 接口，来定义所有通用步骤： 1234reset()buildStepA()buildStepB()getResult() 然后由具体生成器来实现这个接口，从而生产具体的产品。 主管类的使用： 12345678director = new Director()CarBuilder builder = new CarBuilder()director.constructSportsCar(builder)Car car = builder.getProduct()CarManualBuilder builder = new CarManualBuilder()director.constructSportsCar(builder) 使用构造器，可以避免出现构造方法需要几十个参数，而不得不提供一系列便利构造方法的情况。 Prototype / Clone 原型模式 / 克隆当对象需要能被复制时，可以使用原型模式。否则，外界就只能遍历每个成员变量，而当存在私有变量时，就无能为力了。而且，这种遍历会依赖到该对象所属的类。如果只知道对象实现了某种接口，就无法手动复制了。 原型模式是指把复制的指责交给对象本身。一般来说提供一个 clone 的方法接口就可以了。 Singleton 单例模式单利模式保证每个类只有一个实例对象，同时提供一个全局的访问节点。由于它同时实现了两个功能，因此违反了单一职责原则。 使用单例模式应特别注意多线程的情况，避免在多个线程创建出多个对象。 Structural PatternsAdapter 适配器模式适配器是一个特殊的对象，能够转化对象的接口，使之能和其他对象进行交互。被封装的对象甚至察觉不到适配器的存在。 Bridge 桥接模式桥接模式把一个复杂的类抽离成“抽象”和“实现”两个独立的层次，从而简化代码的复杂度。 假如我们要编写遥控器的代码，遥控器本身有不同的形态，比如触控式的或按键式的，而被遥控的家电有电视、空调等等。如果我们为每一种 case 都写一个类的话，就会有 TvTouchRemote ，TvButtonRemote，AcTouchRemote，AcButtonRemote 等等继承自 Remote 的类。类的数量会根据变化以几何级数的速度增长，而其中又会有很多类似的代码。而如果把所有代码编写在一个类来避免数量的指数爆炸，代码里就又会充斥 if-else ，造成维护的困难。 桥接模式通过拆分层次的方式，把继承改为组合来解决这一问题。抽象部分（Abstraction）是一个高阶的控制层，本身不完成实际工作，而把工作委派给具体的实现（Implementations）——抽象持有实现。客户端代码只关心如何与抽象交互，但是需要对抽象指定一个实现。实现部分提供通用的接口，由具体实现（Concrete Implementation）来完成不同的平台操作。精确抽象（Refined Abstraction）来提供抽象的变体。 回到遥控器的例子，遥控操作可以看作抽象，而针对不同电器编写的特定代码为实现。 1234567891011121314151617181920212223class RemoteControl { var device: Device // 抽象持有实现 func togglePower()}class AdvancedRemoteControl: RemoteControl{ //....}protocol Device { func enable() func disable()}class TV: Device { //....}// client codetv = new TV()remote = new RemoteControl(tv)remote.togglePower() Composite / Object Tree 组合模式 / 对象树只有在应用的核心模型可以用树来表示时，此模式才有意义。 对象树模式的好处在于，客户端代码无需关心元素的具体类型，而是可以通过统一的方式来操作他们。Component 接口描述了树中简单项目和复杂项目的所有共同项目，直接与客户端交互。Leaf 是不包含子项目的节点，完成大部分实际工作。Container 包含 Leaf 或其他 Container，它也不关心子节点的具体类型，同样通过通用的接口通知子节点工作。 例如，一个图形编辑器可能有圆形、方形等基础形状（Leaf），也会有组合形状（Container）。而他们都有一组通用的接口，例如移动、绘制等。 Decorator 装饰器模式装饰器通过将原始对象放入一个包含特定行为的装饰器中，从而为原对象绑定新的行为。我们甚至可以构造多个不同的装饰器，从而组合多种行为。这也是一种组合替代继承的思想。 装饰器应该提供和原对象完全一致的接口，因此从客户端视角来看，两者是完全相同的。装饰器中引用的成员变量应该是遵循同样接口的任意对象，这样就可以像栈一样，多层封装。 用真实世界类比，毛衣可以御寒，而雨衣可以避雨。在寒冷的雨夜，我们就可以同时穿上毛衣和雨衣，从而组合御寒和避雨两个功能。当其中某个功能不再需要时，也可以很容易地脱掉。 例如，在把一个数据写入磁盘时，我们要压缩并加密。这就可以构造一个 EncryptionDecorator 和一个 CompressionDecorator 。由于接口保持一致，在客户端视角来看，增加一个装饰器和直接写入原始数据的代码是可互换的。 Facade 外观模式外观模式对客户端提供了一个简单的接口，从而屏蔽内部的复杂子系统。就像电话购物，通过客服人员对购买者提供了简单的语音接口，屏蔽了内部复杂的仓储、物流、交付、结算等等环节。 客户端代码应该仅通过外观与复杂的子系统交互。 Flyweight 享元模式享元模式可以用来减轻内存压力。一般情况下，我们会把所有的数据都存储在各个对象中，比如在一个游戏中，子弹对象可能有坐标、贴图等属性。但是当子弹数量特别大的时候，程序可能会 OOM。 其实相同类型的子弹贴图是完全相同的，而贴图也恰好是占用内存的大头。这类外界不会改变、只会读取的数据被称为内在状态。相反，每个子弹的坐标都不相同，外界也会不断更改这些属性，这被称为外在状态。享元模式建议把内在状态用“享元”对象存储——假如说我们的游戏有子弹、导弹两种类型粒子，则享元对象只存在两个。外在状态可以用一个数组存储。这个数组的对象包含了每个子弹的外在状态：坐标、速度等等。这些对象共享“享元”对象的数据。 我们还可以构造一个享元工厂，来管理享元对象的缓存池。 Proxy 代理模式代理模式可以让我们提供一个原始对象的替代品，从而完全控制对原对象的访问，并在把请求提交前后做一些额外的处理。代理应该遵循和原始对象一样的服务接口，才能伪装成原始对象。 例如，我们的程序中可能有一个下载类，但是每次请求该下载类，都会重新下载一次视频。我们可以构造一个实现了同样接口的代理，在代理中保存下载记录。如果多次请求同一文件，可以直接返回已有的缓存文件。或者当我们需要给某些操作打日志时，就可以包装一个日志代理，用于保存访问记录。 听起来，装饰器和代理非常相似，但不同之处在于代理会自行管理服务对象的生命周期，而装饰器通常由客户端来组装。 Behavioral PatternsChain of Responsibility (CoR) 责任链模式责任链模式允许我们将请求沿着处理者的链条传递。每个节点都可以处理请求，或是发送给下一个处理者。因此，请求的处理顺序很清晰，且每个环节的职责单一，避免了代码的混乱。它同时也满足开闭原则，可以在不更改现有代码的情况下新增处理者。 在一个订购系统中，责任链可能包括权限验证、数据缓存、安全检查等等。当其中一个环节出现异常后，该处理流程可以天然地中断，从而提升效率。另一个典型的例子是 GUI 系统。视图树上的 View 可以依次判断自己是否可以处理点击事件，如果不能，则沿着视图树向父节点发送该事件。 Command 命令模式命令模式把请求转换成一个包含有与请求相关所有信息的对象。这有助于我们实现请求参数化、延迟请求执行，或实现撤销操作。 假设我们要实现一个文本编辑器，那么可能有多个地方都要触发保存功能：保存按钮、保存菜单栏，以及 command+S 快捷键。一般我们可能会让这些 GUI 元素直接操作业务逻辑层，于是保存相关的逻辑可能分散在工程的各个位置。命令模式建议我们不要让 GUI 直接处理保存操作，而是建立一个新的层：SaveCommand。从此，GUI 模式只触发命令，而不再关心业务逻辑层是否接收到了请求，也无需了解其对请求进行的处理方式。命令对象会自己处理所有的细节。 1234567891011121314class Command { func execute()}class CopyCommand: Command { //....}class PasteCommand: Command { //....}// client codecopyBotton.setCommand(new CopyCommand()) Iterator 迭代器模式一般我们会让集合本身提供多种遍历方法，但是这模糊了其“存储数据”的主要职责。迭代器模式把迭代算法抽离成一个单独的对象，从而让客户端代码与具体的集合解耦。 首先，迭代器应该有一组通用的接口，如 getNext() 等。之后，集合类型需要包括一个获取迭代器的接口，这样可以配置不同的迭代器。最后，为每一种集合类型，构造一个专属的迭代器类。 Mediator 中介者模式中介者模式思想很简单，它可以解决对象和对象之间耦合过于紧密的问题。使用中介者模式，组建之间不再直接通信，而是通过中介者简介通信。 现实生活中，飞机驾驶员通常不会直接沟通起降顺序，而是通过中介者——塔台来间接通信。 Memento 备忘录模式备忘录模式允许在不暴露对象实现细节的情况下，保存和恢复对象之前的状态，因此特别适合“撤销编辑”等场景。 备忘录模式建议把状态的副本存储在“备忘录”这一特殊对象中，除了创建备忘录的对象之外，其他对象都不允许访问和修改该备份的状态。但是其他对象可以访问如创建时间等基础信息。备忘录的创建由实际状态的持有者原发器（Originator）负责。 备忘录可以保存在负责人（Caretaker）中。负责人只知道“何时”、“为何”创建了备忘录，以及何时该恢复副本。需要回滚时，负责人从栈中取出栈顶的备忘录，并传给 Originator 的恢复方法中。 123456789101112131415class Editor { func save() -&gt; Memento func restore(m: Memento) -&gt; BOOL}class Memento { var state: State func getState() -&gt; State}class HistoryCaretaker { var stack: Memento[] func undo() -&gt; BOOL func doSomething()} Observer 观察者模式观察者模式很好理解，由 Publisher 发布消息，只有之前注册过的 Subscriber 才会收到消息。 State 状态模式状态模式和有限状态机密切相关，它可以让一个对象的状态改变时，改变自己的行为。 首先需要定义一个 State 的接口，该接口中声明跟状态有关的方法。具体状态（Concrete State）基于某种状态来实现这些接口。上下文（Context）保存具体状态的引用，并通过状态接口与状态对象交互。上下文或具体状态都能触发状态的转移。 12345678910111213141516171819202122232425262728293031323334353637class AudioPlayer { var state: State func changeState(state: State) { this.state = state } func clickLock() { this.state.clickLock() } func clickPlay() { this.state.clickPlay() } //....}class State { var player: AudioPlayer func clickLock() func clickPlay() //....}class LockedState { func clickLock() { player.changeState(new PlayingState(this.player)) } //....}class ReadyState { //....} Strategy 策略模式策略模式和状态模式有点类似，他是通过预先定义好接口，将一系列算法封装进不同的对象中。由 Context 来维护指向具体策略的引用。客户端代码负责创建一个特定的策略，并传递给 Context。 例如，在一个地图应用中，驾车导航、步行导航就可以作为两种不同的策略。 Template Method 模版方法模式模版方法模式建议在超类中定义算法的框架，让子类在不修改结构的情况下，重写算法的特定步骤。具体方式是在父类中定义一系列方法，并可以提供一些默认实现，由子类去做覆写。此外，还可以在关键步骤之间添加钩子方法，执行一些额外的步骤。 Visitor 访问者模式假如我们现在有 City，Industry 等等一系列的类，现在需要支持一个到处为 XML 文件的方法。最直观的想法是在每一个类中都新增一段导出逻辑。然而这样可能会影响到已有的代码，从而让整个程序都不稳定。 访问者模式建议把新的行为放在“访问者”这个单独的类中，而把需要执行操作的原始对象作为参数传给访问者。由于每个类的实现可能不同，因此要提供一系列的函数。 1234class ExprotXMLVisitor { func exportCity(city: City) func exportIndustry(industry: Industry)} 但是当我们遍历全部对象时，面对一个具体类型未知对象，该如何确定该调用哪个方法呢？ 1234567for(node in graph) { if (node.isKindOf(City.class)) { //... } else (node.isKindOf(Industry.class)) { //... }} 这样的类型检查太过丑陋了。一个解决方法是用 Double Dispatch 的方式来避开判断语句。既然每个对象清楚自己是什么类，为什么要让客户端来检查类型呢？ 12345678910class City { func accept(v: Visitor) { v.exportCity(self) }}// client codefor(node in graph) { node.accept(visitor)} References: [1] https://refactoring.guru/design-patterns/","link":"/2020/08/23/design-patterns/"},{"title":"下载 m3u8 格式视频","text":"生活小妙招：下载 m3u8 格式视频最近想通过看美剧的方式提高下听力水平。在浏览器上播放美剧，频繁的倒带往往会出发缓存重新加载，体验很不好。而且，为了达到联系效果，往往需要将一集视频重复观看多遍。这个时候就比较希望能够把视频文件直接下载下来，一劳永逸。 查看源文件因为之前没有了解过网页是怎样播放视频的，所以很天真的认为会有一个 .mp4 的资源文件，只要去请求下载这个文件就好了。通过开发者工具查看网页播放器的源代码，发现确实有 src 链接： 然而这并不是一个 .mp4 之类的视频文件。这个时候我注意到网络请求中，也确实没有一个大的资源文件在下载，而是一直有很多个小的请求。这才想到应该是某种分片加载视频资源的协议。 下载 m3u8去请求上面的 src 链接，得到了一个 .m3u8 格式的文件，打开后发现里面是一串 js 文件的地址列表： 1234567891011...#EXTINF:3.586,https://meiju2.zzwc120.com/20180928/f7Q8OCzP/1000kb/hls/Ln08abn2358000.js#EXTINF:3.628,https://meiju2.zzwc120.com/20180928/f7Q8OCzP/1000kb/hls/Ln08abn2358001.js#EXTINF:2.085,https://meiju2.zzwc120.com/20180928/f7Q8OCzP/1000kb/hls/Ln08abn2358002.js#EXTINF:3.294,https://meiju2.zzwc120.com/20180928/f7Q8OCzP/1000kb/hls/Ln08abn2358003.js#EXTINF:4.17,... 想来就是视频切片的地址了。通过 ffmpeg 就可以下载完整的视频。命令如下： 1ffmpeg -protocol_whitelist file,http,https,tcp,tls,crypto -i &quot;&lt;path_to_m3u8&gt;.m3u8&quot; &quot;&lt;output_name&gt;.mp4&quot; 这里注意，将 https 添加到白名单是必要的，否则会报错。m3u8 格式的文件路径可以是远端的路径，但在我这个例子中，直接请求会 404，因此就先把 m3u8 文件下载到了本地，填的本地路径。 下载的过程是串行的，略慢。ffmpeg 还没有实现多线程的下载，慢慢等待吧。 不要用来做侵犯版权的事情哦 ⚠️","link":"/2021/01/09/download-m3u8/"},{"title":"用 Python 绘制炫酷的 Icon","text":"用 Python 绘制炫酷的 Icon最近在做一个和 Swift 编码相关的项目，就想给项目做一个 logo 出来，不然光秃秃的不好看。因为是编码相关，因此就想到可以用 0 和 1 填充 Swift 的图标，再加上一个炫酷的渐变色。Swift 的 logo 在官网就可以下载矢量图格式。最终实现的效果如下： 感觉还是挺好看的。 思路用 Pillow 和 OpenCV 库，先随机生成彩色的 0 和 1 排列，之后用 Swift 的 logo 做一下 mask 就可以了。生成彩色 0 1 图又需要先生成一张渐变图，然后用黑白的 0 和 1 图做一次 mask。整体思路比较简单。 PIL 渐变图我这张图是从上到下渐变，给定两个 RGB 颜色值，从上到下做线性插值。这里的实现比较简单粗暴，直接去遍历 1024x1024 的图像的每个像素，速度比较慢（又不是不能用系列）。毕竟是参考的网上其他人的实现，实际上用 np.linspace 会快很多…… 而且同样的值直接复制也不需要依次循环…… 偷懒了。 1234567891011121314151617181920212223from PIL import Image, ImageDraw, ImageFontimport randomimport cv2import numpy as npimg = Image.new(mode='RGB', size=(1024, 1024), color='white')draw = ImageDraw.Draw(img)color1 = (255, 0, 0)color2 = (255, 173, 0)step_r = (color2[0] - color1[0]) / 1024step_g = (color2[1] - color1[1]) / 1024step_b = (color2[2] - color1[2]) / 1024for y in range(0, 1024): # 可以直接用 numpy 向量运算，会快很多 r = round(color1[0] + y * step_r) g = round(color1[1] + y * step_g) b = round(color1[2] + y * step_b) for x in range(0, 1024): draw.point((x, y), fill=(r, g, b)) # 同样的值没必要写循环复制grad = np.asarray(img) # PIL 转 numpygrad = cv2.cvtColor(grad, cv2.COLOR_RGB2BGR) # 转到 OpenCV 默认的 BGR 排列 生成的渐变图如下： 0-1 排列图之后要制作一张 0 和 1 随机排列的黑白图。只要写个循环把随机数排满画布就可以了： 1234567891011img = Image.new(mode='RGB', size=(1024, 1024), color='white')draw = ImageDraw.Draw(img)font = ImageFont.truetype('Consolas.ttf', size=35)for x in range(0, 1024, 25): for y in range(0, 1024, 30): text = random.randint(0, 1) draw.text(xy=(x, y), text=str(text), fill=(0, 0, 0), font=font)numbers = np.asarray(img).copy()numbers = cv2.cvtColor(numbers, cv2.COLOR_RGB2BGR) 效果如下： 渐变 0-1 排列之后就是使用黑白的 0-1 图当作蒙版去给渐变图做遮罩。那我们很容易就写出这样的代码： 1numbers[numbers_gray == 0, :] = grad[numbers_gray == 0, :] 也就是把图片中黑色的地方（为 0）替换成渐变图的颜色。但是如果事情发展的这么顺利我就不写这篇文章了…… 直接这样做，生成的渐变数字会带有黑边： 看起来感觉很脏。显然数字本身并不是纯黑色的，边缘位置是灰色。那如果我们把图片中不是白色的地方都替换掉呢？ 1numbers[numbers_gray != 255, :] = grad[numbers_gray != 255, :] 这次黑边确实看不见了，但是总感觉文字很模糊，不够锐利。尤其是数字 0，边缘非常毛糙。 如果我们仔细观察黑白图片，就会发现文字的边缘的颜色是逐渐变浅的，这是因为绘图库为我们做了抗锯齿（Anti-Aliasing）操作。如果我们简单把所有非 255 的值都替换掉，文字的锯齿效果就很明显，特别是 0 这样带有弧度的字符。 为了继承这种抗锯齿效果，最直接的想法就是按照黑色的深浅来调整颜色。如果某个像素的颜色比较浅，则应该把对应的渐变图的颜色也向白色的方向调整。在 RGB 色彩空间中我们不好这样操作，因此更适合转换到 HSV 空间中，调整饱和度。 12345678910numbers_gray = cv2.cvtColor(numbers, cv2.COLOR_BGR2GRAY)scale = ((255 - numbers_gray[numbers_gray != 255]) / 255) # 根据黑色的程度计算 scalenumbers[numbers_gray != 255, :] = grad[numbers_gray != 255, :] numbers = cv2.cvtColor(numbers, cv2.COLOR_BGR2HSV)numbers[numbers_gray != 255, 1] = numbers[numbers_gray != 255, 1] * scale # 调整 S 通道numbers = cv2.cvtColor(numbers, cv2.COLOR_HSV2BGR)color_number = numbers 最终效果如下，还是比较满意的： Logo Mask最后就是把黑白的 Logo 图当作 mask，制作最终的图片了。 12345swift = cv2.imread('swift.png', cv2.IMREAD_UNCHANGED)mask = swift[..., 0:3] != 255swift[..., 0:3][mask] = color_number[mask]cv2.imwrite('color_swift.png', swift) 理论上我们也应该考虑抗锯齿，但是由于 logo 本身尺寸比较大，效果不明显，所以又偷懒了 : ) 最后再来欣赏一下成果吧：","link":"/2022/07/09/draw-swift-logo/"},{"title":"DTCWT Lowpass Shape","text":"DTCWT Lowpass Shape双树复小波变换 (Dual-Tree Complex Wavelet Transform, DTCWT) 低频系数矩阵的尺寸一致很让人困惑，许多文献都重点讨论了高频部分（6 个方向），而对低频部分的介绍较少。对一个单通道，大小为 (N, N) 的二维图像做一次 2D DTCWT 变换，高频部分应该有 6 个，尺寸均为 (N/2, N/2) 其中每个都是复数。那么低频部分呢？ 不同的尺寸对低频部分的描述至少有三种说法： 2 个低频图像，大小和 6 个高频图像一致为 (N/2, N/2) 4 个低频图像，大小为 (N/2, N/2) 1 个高频图像，大小为高频图像的两倍。如果只做一次 DTCWT，则为 (N, N) 。做两次，则为 (N/2, N/2) 2 个低频图像在论文 SAR Image segmentation based on convolutional-wavelet neural network and markov random field 中，作者使用了 DTCWT 作为 pooling layer。作者表示一次分解应产生 8 个成分，分别为 2 个低频和 6 个高频： 4 个低频图像纽约大学的 Ivan Selesnick 教授开源了 DTCWT 的 MATLAB 实现，且有详细的讲解。其低频部分有 4 组值： 1234567% OUTPUT:% w{j}{i}{d1}{d2} - wavelet coefficients% j = 1..J (scale)% i = 1 (real part); i = 2 (imag part)% d1 = 1,2; d2 = 1,2,3 (orientations)% w{J+1}{m}{n} - lowpass coefficients% d1 = 1,2; d2 = 1,2 但是注释中并没有说明 m，n 的含义。如果类比高频部分，分别代表实部、虚部的话，倒是和 2 个低频图像的说法对应上了，即 2 个复数的低频和 6 个复数高频。但是可能并不能简单地这样理解。 1 个低频图像1 个低频图像，尺寸为高频的 2 倍的说法其实是出现频率最高的，至少有三处来源： Python 的一个 DTCWT 工具包：https://pypi.org/project/dtcwt/ 剑桥大学的一篇博士毕业论文中开源了另一个 DTCWT 的 PyTorch 实现：https://pytorch-wavelets.readthedocs.io/en/latest/dtcwt.html MATLAB 官方的 Wavelet ToolBox：https://www.mathworks.com/help/wavelet/ref/dualtree2.html 因此倾向于这种说法更加可信。 低频图像的来源DTCWT 只有一个低频图像，且尺寸是高频图像的 2 倍 —— 做一次变换，低频图像的大小和原图一致；做两次变换，低频图像才缩小到 1/2，听起来比较反直觉。那么这个低频图像是怎么出来的呢？ 在剑桥博士毕业论文中，作者给出了 DTCWT 的算法说明： 可以惊喜地看到，最终的一个低频图像是由四个低频分量构造出来的，即 yl = interleave(…) 。这样就不和纽约大学的代码矛盾了。遗憾的是作者并没有详细描述 interleave 函数的含义。但是根据字面意思理解，应该是指从 4 个低频分量中各取一个点，拼接成一张大图。这样大图的长、宽就正好是小图的两倍。 翻阅其代码，作者的实现和论文中的描述并不一致。虽然没有做交叉插值的步骤，但是其中有这样一个函数： 12345678910111213141516171819# def q2c(y, dim=-1):def q2c(y, dim=-1): &quot;&quot;&quot; Convert from quads in y to complex numbers in z. &quot;&quot;&quot; # Arrange pixels from the corners of the quads into # 2 subimages of alternate real and imag pixels. # a----b # | | # | | # c----d # Combine (a,b) and (d,c) to form two complex subimages. y = y/np.sqrt(2) a, b = y[:,:, 0::2, 0::2], y[:,:, 0::2, 1::2] c, d = y[:,:, 1::2, 0::2], y[:,:, 1::2, 1::2] # return torch.stack((a-d, b+c), dim=dim), torch.stack((a+d, b-c), dim=dim) return ((a-d, b+c), (a+d, b-c)) 这里的输入和低频的尺寸是一样的，然后四个值分别拆开（再通过加减运算）构成了 2 个复数高频： 这和论文中描述的算法是逆操作，所以应当是等价的。","link":"/2021/05/31/dtcwt-lowpass-shape/"},{"title":"First Aid Basics","text":"First Aid Basics我们把每天的绝大多数时间花费在职场中。掌握一些基本的急救常识，在意外发生时可以保护到自己以及我们身边的人。 AHA Heart SaverAHA HS 培训是由美国心脏协会举行，面向普通人开设的急救培训课程。基本也是市面上普通人能考取的最专业的证书了。AHA 的理念是“全为生命”（Life is Why）。 考取 AHA 急救证书有很多好处： 在身边的人遇到紧急情况时，可以第一时间给予帮助。黄金四分钟对挽救生命至关重要，如果早一分钟干预，可能结果会完全不一样 在全球 180 多个国家享有救人免责条款，并且有使用体外自动除颤器（AED）的合法使用权 某些职业（健身教练、潜水员等）的上岗资质之一 可担任某些赛事急救志愿者 办理某些国家的签证可能有帮助 ….. AHA 的 HS 课程不仅有 CPR、AED 的培训，还包括了一些常见的内外科急症的处理方法。 通过考核后，你讲收获这样的一张证书。证书有效期为两年。 下面简单介绍一些职场上可能遇到的突发状况，以及处理方式。 通用请先确认现场环境安全。如果你自己也受伤了，就无法帮助他人。 有无菌意识。如果可能，请穿戴个人防护设备（PPE），包括手套、护目镜等。血液可能会传播多种疾病。 要及时寻求帮助。多个人密切配合可以提高救援效率。如果你在施救，记得让他人帮忙拨打 120，并取来急救箱。拨打 120 时，不要主动挂断电话。可以将手机调至免提模式，并放在身旁，随时与接线员沟通现场状况。可以派他人去迎接急救人员。完整的回答接线员的问题并不会延缓救援的到来速度。 创伤急症鼻出血 让患者坐下，且身体前倾（不要仰头） 用清洁敷料捏住鼻翼两侧柔软的部分（不要填充） 施加恒定的压力，并持续几分钟，直到鼻血止住 如果长时间无法止血，或患者呼吸困难，拨打 120 扭伤 用清洁敷料覆盖开放性伤口 在受伤部位放置一块毛巾，在毛巾上方放一个装有冰水的袋子 冷敷最多 20 分钟 电击伤电击伤可能导致体内外烧伤并伤及器官。即使表面看不出来，内部的创伤也可能非常严重。 如果现场有水（如城市内涝），请不要接近事发区域 及时拨打 120 并联系主管机构切断电源 这里不建议大家贸然施救。因为作为非专业人士，即使你关闭了电闸，也无法确定接触伤者的那根电线是否断电。自己的安全永远是最重要的。 环境急症蜜蜂蜇伤 用硬而钝的物体刮出毒刺，比如身份证。不要拔出毒刺，因为可能挤压到毒囊 用流水和肥皂清洗 用毛巾裹住一袋冰水，冷敷不超过 20 分钟 观察患者至少 30 分钟，以确定是否出现严重过敏反应 内科急症低血糖低血糖除了我们常见的困倦、饥饿、多汗、身体虚弱等症状外，还有可能表现为急躁不安、意识不清。 如果患者无法坐直或吞咽，不要逼迫他进食，立刻拨打 120 请患者吃些含糖食物，包括橙汁、软糖、全职牛奶等 让其静坐或躺下 15 分钟内未好转，拨打 120 抽搐抽搐由大脑异常放电引起，多数可在几分钟内自然停止。 移开患者身边的家具或物品 在头部下方放一块毛巾 拨打 120 记录抽搐时间，让患者静静地抽一会儿。不要撬开嘴巴垫入任何物品 抽搐结束后，如果患者呕吐，请让他翻身侧卧。 脑卒中当血液停止流入大脑的某些区域，可能导致脑卒中。及时接受治疗可以减少损伤并提高恢复几率。 识别脑卒中可以使用 FAST 方法。 Face，是否有一侧面部低垂或麻木 Arm，是否有一次手臂无法抬起 Speech，是否言语不清 Time，及时拨打 120 并送医 心脏病发作心脏病发作是流经心脏的血液被血栓阻塞引起的。通常表现为胸部不适、气促、恶心冷汗等。如果患者年龄较大，则从鼻子以下、肚子往上的部分疼痛，都应该怀疑心脏病，包括牙痛。 许多人心脏病发时都会否认，并表示自己还好。怀疑心脏病发作时，不管患者是否愿意承认，都应该立即拨打 120 并采取措施。 务必让患者平静休息 取来急救箱和 AED 如果患者不过敏且没有严重出血，也无脑卒中表现，可以吞服 1 剂阿斯匹林 窒息吃东西时可能引起气道阻塞。某人发生窒息时，可能表现为起立并抓住自己的脖子。 患者不能说话时即为严重的气道阻塞。如果可以说话，则让他咳嗽。 海姆立克急救法： 站于患者身后 双臂环绕患者腰部 一手握拳，另一只手抓住拳头 大拇指侧放在肚脐略上方的位置 快速持续向斜后方冲击腹部 如果你自己发生了气道阻塞，可以用椅背来冲击自己的腹部。 视频 https://www.youtube.com/watch?v=PlK7Q0kPuMk 一分钟处。 心肺复苏施救标准： 拍打并呼喊患者，如果无反应 &amp;&amp; 观察呼吸 5 - 10 秒，如果无呼吸 患者有反应或有呼吸，则不需要 CPR。 胸外按压 除去衣物 双手叠放，掌根位于胸骨下半部（男性的两乳头连线中心处） 每分钟按压 100 - 120 次 深度至少 5 厘米 以胸外按压为主，即使人工呼吸，也不要暂停 10 秒以上 人工呼吸 让患者抬头打开气道 包住患者嘴巴，吹气两次 观察到胸腔起伏即位吹气成功 胸外按压：人工呼吸 = 30 ： 2 注意，每两分钟（5 组）必须换人以保证按压质量，即使不感觉疲惫。 https://www.youtube.com/watch?v=-NodDRTsV88 AED牢记 AED 的位置。 AED 通过电流刺激来除颤。打开后，按语音提示操作。 视频 https://www.youtube.com/watch?v=hHhiL1XZ3J8 1分40秒处。 先开始 CPR，等待 AED 送达 AED 送达后，立即使用 AED 电击后立刻继续 CPR 最后减少熬夜时间、规律运动，防患于未然。祝大家健康，永远让我没有练手的机会！","link":"/2020/06/08/first-aid-basics/"},{"title":"First Time Using a Total Station","text":"First Time Using a Total Station全站仪（Total Station）是一种可以用来测量物体到机器角度、距离等数据的仪器。学土木工程或测绘的同学们对它都非常熟悉，但是作为一个 ECE 专业的学生，平时的确没什么机会接触到全站仪，感觉很好玩因此简单记录一下。 原理全站仪通过发射红外激光照射到棱镜上，计算反射回来的光线相位差来得到距离，误差非常小，可达到 0.1mm 的级别。中间黑色的部分是一个望远镜，用来瞄准棱镜。固定之后，可以左右、上下旋转进行瞄准。也可以打出一个红色的激光点来辅助瞄准。底部的支架末端是尖的，在野外测绘时可以插入泥土方便固定。由于我们是在室内，为了防止打滑，因此额外使用了一个底座方便固定。 棱镜（prism）用来接收激光，并按相同的光路反射回去。它的底部有一截螺杆，用来固定。棱镜长这样： 操作装上电池开机后，首先调整旋钮，让全站仪水平。之后左右转动仪器，并用旋钮上下转动仪器，通过望远镜的目镜瞄准远处的棱镜。我打开了红色激光来辅助瞄准，因此对准棱镜后能看到强烈的反射光线。 之后按照屏幕提示，点击 Go to work，进入 Total Station Setup 界面。选择 Set orientation （Station is known. Aim at a target to set the orientation）。之后输入原点坐标。这里有一个小技巧是可以把 Northing、Easting 和 Elevation 分别设置为 1000、2000 和 3000，这样后续使用数据时，就能很快反应过来是对应的哪个数据（当作 magic number）。当然设置成全 0 也是没问题的。之后选择棱镜的型号，我用的这款是 Leica Mini 360。 设置完成后，再次点击 Go to work，选择 Survey 进入测绘模式。由于已经对准棱镜，点击 Dist 按钮，机器就会测量出距离、角度等信息。 可以看到，棱镜距离机器的水平距离是 4.9 米。 锁定跟踪全站仪最有意思的地方是它可以锁定并自动跟踪棱镜。左上角的🔒图标表示当前棱镜已锁定，这个时候移动棱镜，机器就会自动旋转追踪。如果离得比较远，即使棱镜的移动速度较快，也不会跟丢（感谢某清华 PhD 友情出镜）。 数据导出测量的数据可以用 U 盘拷出。也可以将 USB 连接到电脑上实时获取数据，并通过 ROS 以 2hz 的频率发布。这样棱镜安装在机器人上，就可以实时得到机器人的准确位置信息了。","link":"/2022/01/08/first-total-station/"},{"title":"Advanced Filter on Kibana","text":"Advanced Filter on Kibana背景在 Kibana 上，我们经常使用 Filter 来过滤掉无用的信息。比如，我想关注 _id 为 123 的用户的一些指标，只需要添加一个这样的 Filter 就可以了： 但有的时候，我们会遇到一些更复杂的场景：比如，我现在想关注 id 尾号后两位介于 20 - 30 之间的用户。这个时候，平常用的简单的 Filter 就无法胜任了。 解决方法点击 Edit Query DSL，就可以编写 ElasticSearch Query DSL。这个 DSL 的规则看起来很复杂，学习门槛比较高。但好处是，它同样支持 Script Query ，编写脚本就可以指定查询规则了！ 示例如下： 1234567891011121314{ &quot;query&quot;: { &quot;bool&quot;: { &quot;filter&quot;: { &quot;script&quot;: { &quot;script&quot;: { &quot;source&quot;: &quot;doc['_id'].value % 100 &gt;= 20 &amp;&amp; doc['device_id'].value % 100 &lt;= 30&quot;, &quot;lang&quot;: &quot;painless&quot; } } } } }} 大功告成！😊","link":"/2020/10/10/elasticsearch-query-script/"},{"title":"FM Radio Receiver with GNU Radio","text":"FM Radio Receiver with GNU RadioGNU Radio 是用于设计、仿真、部署高可用无线电系统的框架。GNU Radio Companion（GRC）提供了一套具有图形界面的、面向 flow graph 的、模块化的信号处理方案，比较简单易用。最终，这个 flow graph 会生成一段 python 代码。 本文中就尝试了使用 GNU Radio + RTL-SDR 来实现一个 FM 接收机。 FlowGraph 概览信号处理中往往会有很多个阶段，每个阶段做一些不同的处理和变换，比如滤波、校验、检测等等。GRC 中，么个步骤叫做一个 block，在 flow graph 中也正好对应一个方格。GRC 本身就自带了非常多的 block，只需要配置参数就好了，很便于使用。我们当然也可以自己编程来实现自己的 block。 下图是实现 FM 接收机最终的 flow graph。 GRC 里并没有内置 RTL-SDR Source Block。作为一个框架，它本身也不应该特殊支持某个特定型号的设备。我们可以自己安装： 1sudo apt-get install gr-osmosdr 下面简要介绍一下这个 flow graph 的结构。第一个 Options 没有什么实际作用，只是一些基本信息。Generate Options 我选择了 QT GUI 是因为我正在使用 Linux 操作系统，就没有选用另一个 Windows 版本的 GUI 框架了。Parameter 和编程语言中的变量作用一致。所谓的 QT GUI Range 就是一个 GUI 的滑块条，运行时就可以在图形界面中滑动来选择数值了。GRC 这一点做的还是很棒的，build GUI 变得非常容易。RTL-SDR Source 是和硬件沟通的桥梁，输出分为两路，一路输入给 GUI Frequency Sink，其实就是一个 FFT 的展示。另外一路输入到 Low Pass Filter 中滤波。滤波后输入到 Wide Band FM Receive 中，最终重采样，乘以一个常数（放大），并输入到音频输出中。这样就可以听到 FM 广播了。 运行结果如下： 实际收听到的声音非常的清晰锐利。 基本概念复习在这里复习一些基础知识，这有助于我们明白参数的意义。 Decimation 抽样我们通过抽样对原始序列做下采样，这是为了减轻储存和计算的负担。概念很好理解，就是只保留 Dth 个样本。在时域中： 1y[n] = x[nD], D = 1,2,3.... D 就被称为 Decimation Rate。时域上的采样会导致频域的扩展，即 w_y = Dw_x 。 NBFM vs WBFM所谓窄带调频，就是频率偏移远小于载波频率，而宽带调频相反。WBFM 可以携带更多的信息，且抗干扰能力更强，因此多用于广播。NBFM 更节约带宽，因此主要用于业余无线电和对讲机。","link":"/2020/05/05/fm-receiver-with-grc/"},{"title":"X11 Forwarding on macOS","text":"X11 Forwarding on macOS通过 VSCode 的 Remote - SSH extension 直接在远程服务器上编写代码是非常方便的，体验和直接在本地开发没有什么区别。但是，当我们想使用 matplotlib 之类的库展示图片的时候，就需要额外做一些配置了。 安装 X11 Window System新版的 macOS 已经不再直接集成 X11 了，需要自己手动安装。我们可以使用 XQuartz 这一开源项目，并通过 homebrew 安装： 1brew cask install xquartz 重启电脑，输入 xterm ，如果弹出 X-terminal，则安装成功了。在 mac 上 echo $DISPLAY 显示如下： 1/private/tmp/com.apple.launchd.UK8U5sVjPZ/org.macosforge.xquartz:0 之后可以 ssh 到服务器，随便打开个 GUI 应用验证下： 12ssh -X &lt;username&gt;@&lt;ip&gt; -p &lt;port&gt;gedit 注意服务器也要允许 X11 forwarding，可以在 /etc/ssh/sshd_config 中增加 X11Forwarding yes 来启用。之后重启下 ssh 守护进程：sudo service sshd restart 。 在服务器上 echo $DISPLAY ，显示： 1localhost:10.0 配置 VSCode编辑 ~/.ssh/config 文件，允许 Forward X11: 123Host myHost HostName myHost ForwardX11 Yes 这样就不需要连接 ssh 时手动 -X 了。 直接打开 VSCode 的 terminal（本地），会发现 DISPLAY 环境变量是空的。这个时候要开启 VSCode 的如下 setting： 1terminal.integrated.inheritEnv 通过 VSCode 的 SSH - Remote extension，连接到远程服务器。打开 VSCode 的 terminal，会发现远端的 DISPLAY 环境变量也是空的，而如果我们非 VSCode built in 的终端 ssh 到远端，就是没有问题的。因此我们需要手动给 DISPLAY 变量赋值。 编辑 launch.json ： 123456789101112131415{ &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;Python: Current File&quot;, &quot;type&quot;: &quot;python&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;${file}&quot;, &quot;console&quot;: &quot;integratedTerminal&quot;, &quot;env&quot;: { &quot;DISPLAY&quot;: &quot;localhost:10.0&quot; }, } ]} 这里比较 tricky 的地方在于，由于不是自动配置的，因此我们需要额外保持一个终端通过 ssh 连接着服务器，来保证 X11 forward 的进程是启用的。且这里的 DISPLAY 变量值要保证一致。否则就会得到 connection refused 错误。 运行编写代码，通过 matplotlib 展示图像吧： 12plt.imshow(img)plt.show() 注意，这里不要试图将 matplotlib 的 backend 改为 TkAgg 等，保持默认即可。 通过 VSCode debug&amp;run 运行程序： 成功弹出 X11 窗口🎉，大功告成！ ps：远程打开窗口感觉响应略慢，也可以考虑直接用 imsave 保存下来查看。 References[1] https://stackoverflow.com/questions/3453188/matplotlib-display-plot-on-a-remote-machine [2] https://stackoverflow.com/questions/59063892/is-there-any-way-to-show-figures-in-vscode-remote-ssh-windows [3] https://github.com/microsoft/vscode-remote-release/issues/267","link":"/2020/12/24/forwarding-x11/"},{"title":"Fixing Tensorboard Plugins Not Loading on Safari","text":"Fixing Tensorboard Plugins Not Loading on SafariI’m planning to develop a customized plugin for Tensorboard. After downloading the official example plugin and installing it, I found it works on Chrome but only shows a white screen on Safari. The console error message shows like this: 1W1117 22:38:41.826974 13009694720 application.py:558] path /data/static/index.js not found, sending 404 ReasonIt’s obviously caused by a path issue. On Chrome, when I click the plugin tag, it sends a request to:1http://localhost:6006/data/plugin/example_raw_scalars/static/index.jsBut on Safari, it sends to the wrong path:1http://localhost:6006/data/static/index.jsI searched the source code and suspect this line of code uses relative path, and may behave differently on Safari and Chrome:1module_json = json.dumps(&quot;.&quot; + module_path) A Temporal WorkaroundIf we manually append the missing path in plugin.py, it works on Safari. But clearly, Chrome will fail because of the repeated path. Is there a way to make both browsers work? 1234def frontend_metadata(self): return base_plugin.FrontendMetadata( es_module_path=&quot;/plugin/example_raw_scalars/static/index.js&quot; ) # works on Safari Since now Chrome will request this file:1/data/plugin/example_raw_scalars/plugin/example_raw_scalars/static/index.jsA workaround will be to copy the index.js file to this long address. Now, we have two copies of index.js, one serves for Safari and the other one serves for Chrome. To let the installer copy the resource files in plugin/... folder, we need to modify the setup.py file: 1234package_data={ &quot;tensorboard_plugin_example_raw_scalars&quot;: [&quot;static/**&quot;, &quot;plugin/example_raw_scalars/static/**&quot;],} Otherwise, only the files in static folder are copied and other files are still missing. We also need to make a copy of the _serve_static_file function, and rename the new one with _serve_static_file_chrome. Then, tell Tensorboard also to load files in the plugin folder: 1234567def get_plugin_apps(self): return { &quot;/scalars&quot;: self.scalars_route, &quot;/tags&quot;: self._serve_tags, &quot;/static/*&quot;: self._serve_static_file, &quot;/plugin/example_raw_scalars/static/*&quot;: self._serve_static_file_chrome, # add this } Now let’s fix the file paths in the _server_static_file_chrome function: 12345678910def _serve_static_file_chrome(self, request): &quot;&quot;&quot;Returns a resource file from the static asset directory. Requests from the frontend have a path in this form: /data/plugin/example_raw_scalars/static/foo This serves the appropriate asset: ./static/foo. Checks the normpath to guard against path traversal attacks. &quot;&quot;&quot; static_path_part = request.path[len(_PLUGIN_DIRECTORY_PATH_PART_CHROME) :] Where _PLUGIN_DIRECTORY_PATH_PART_CHROME is defined as: 12_PLUGIN_DIRECTORY_PATH_PART_CHROME = &quot;/data/plugin/example_raw_scalars/plugin/example_raw_scalars/&quot; Build and run the plugin, it should work on both Safari and Chrome now. 🎉 PS: I also submitted an issue on Github. Let’s see if this can be confirmed as a bug.","link":"/2022/11/17/fix-tb-plugin/"},{"title":"Writing the Very First LLVM Pass","text":"Writing the Very First LLVM Pass这篇文章记录了编写第一个 LLVM Pass 的过程，主要跟随 LLVM 官方的 Hello Pass 教程。 编译 LLVM虽然 Pass 最终会被 opt 动态链接，但是我们仍需要编译 LLVM 来获得开发环境。具体编译过程可以参考之前的博客。 编写第一个 Pass由于 Hello Pass 已经内置在 LLVM 的工程中了，所以这里我换了个名字叫 MyPass。首先进入 llvm/lib/Transforms 新建一个文件夹 MyPass ，并 cd 进入。 新建 CMakeLists.txt 和 MyPass.cpp 文件。将以下内容输入 CMakeLists 文件： 123456add_llvm_library( LLVMMyPass MODULE MyPass.cpp PLUGIN_TOOL opt) 并在 llvm/lib/Transforms/CMakeLists.txt 文件最后添加 add_subdirectory(MyPass) 。 在 MyPass.cpp 中编写第一个 Pass 的代码：除了打印出函数的名称之外，什么也不做。 12345678910111213141516171819202122232425262728#include &quot;llvm/Pass.h&quot;#include &quot;llvm/IR/Function.h&quot;#include &quot;llvm/Support/raw_ostream.h&quot;#include &quot;llvm/IR/LegacyPassManager.h&quot;#include &quot;llvm/Transforms/IPO/PassManagerBuilder.h&quot;using namespace llvm;namespace { struct MyPass : public FunctionPass { static char ID; //给 LLVM 用于识别 Pass MyPass() : FunctionPass(ID) {} //构造函数 bool runOnFunction(Function &amp;F) override { errs() &lt;&lt; &quot;Hello: &quot;; errs().write_escaped(F.getName()) &lt;&lt; '\\n'; return false; } };}char MyPass::ID = 0;static RegisterPass&lt;MyPass&gt; X(&quot;hello&quot;, &quot;my pass&quot;, false, false);static RegisterStandardPasses Y( PassManagerBuilder::EP_EarlyAsPossible, [](const PassManagerBuilder &amp;Builder, legacy::PassManagerBase &amp;PM) { PM.add(new MyPass()); }); 编译 Pass回到一开始编译 LLVM 的 build 文件夹，编译新建的 Pass。由于我之前是用的 ninja 来编译的 LLVM，所以这里仍然只需要 ninja 一下就可以了。编译会很快完成。之后进入 build/lib 文件夹，可以看到新编译出来的 LLVMMyPass.dylib 文件（如果在 Linux 下会是 .so）。 运行找个自己喜欢的地方随便写一点代码，我在这里写了个 hello.c ： 1234int main() { printf(&quot;Hello world!\\n&quot;); return 0;} 之后编译出 IR 代码： 1clang hello.c -O0 -S -emit-llvm -o hello.ll 然后就可以用 load 命令将编译出来的 Pass 载入 opt。由于我是在自己的文件夹中安装的编译好的 LLVM，没有配置环境变量，所以使用了绝对路径： 1~/Documents/LLVM/install/bin/opt -load ~/Documents/LLVM/llvm-project/build/lib/LLVMMyPass.dylib -hello hello.ll &gt; /dev/null 这里的 -hello 即之前代码中 RegisterPass 中传入的参数。 控制台打印出： 1Hello: main 可见，这个用于打印函数名称的 Pass 正确的运行起来了。 集成到 Xcode首先到 Build Settings 中的 User-Defined 中，添加 CC 和 CXX ，指明是用我们自己编译的 clang 来编译程序： 1/Users/wangluyuan/Documents/LLVM/install/bin/clang 之后在 Apple Clang - Custom Compiler Flags 中，设置 Other C Flags 和 Other C++ Flags，load 我们的 pass： 1-Xclang -load -Xclang /Users/wangluyuan/Documents/LLVM/llvm-project/build/lib/LLVMMyPass.dylib 这是除了刚才通过 opt 运行 Pass 之外的第二种运行 Pass 的方式。 这个时候会报错 unknown argument: -index-store-path，需要将 Build Settings 中的 Enable Index-While-Building 设置为 No。 此时编译程序，就可以看到我们的输出了！ 可以看到我们的 Pass 输出了 AppDelegate 中的几个方法名称 👏","link":"/2020/01/27/first-llvm-pass/"},{"title":"GRU Forward and Backward Pass","text":"GRU Forward and Backward PassGRU 是 LSTM 的一个变体。LSTM 的一些操作显得冗余，例如它既有记忆门，又有遗忘门。GRU 中就把这两个门合并成了一个。另外 LSTM 分别维护着 cell state 和 hidden state，也显得重复了。GRU 在这个基础上做了简化，因此参数会更少、形式也更简洁。 Forward PassGRU 的结构如下图所示： 运算公式如下： 注意，这里最后一行的 ht 的计算公式和 PyTorch 的实现是一致的；而 PyTorch 的实现和 Wikipedia 或是网上常见的公式不一致。更常见的公式中，nt 和 ht-1 的位置是调换的。 但这其实并不是 PyTorch 的 bug，两者交换位置没有本质区别。更详细的讨论可以参考 Github 上的 issues：https://github.com/pytorch/pytorch/issues/20129 代码也比较简洁。由于是课程作业的代码，就不放出完整版本了： 1r = self.sigmoid(np.dot(self.Wrx, x) + self.bir + np.dot(self.Wrh, h) + self.bhr) 其中 Sigmoid 实现如下： 1234567class Sigmoid(): def forward(self, x): self.state = (1 / (1 + np.exp(-x))) return self.state def derivative(self): return (self.state) * (1 - self.state) Backward Pass求导会稍微困难一些。好在我们可以根据矩阵的维度得到一些提示。一些核心的公式如下，其他的参数求导很类似，就不详细赘述了： 部分代码如下： 12345d_z = delta * (-1.0 * self.n + self.hidden)d_z_act = d_z * self.z_sigmoid.derivative()self.dWzx = np.dot(x, d_z_act).Tself.dbiz = np.sum(d_z_act, axis=0)","link":"/2021/03/31/forward-backward-gru/"},{"title":"Forward & Backward Pass of Batch Normalization","text":"Forward &amp; Backward Pass of Batch Normalization原论文地址：https://arxiv.org/pdf/1502.03167.pdf 标准化过后的数据更利于机器学习。在神经网络中，数据分布不均匀的情况不仅仅会发生在输入的原始数据中，也会发生在隐含层中。我们就是通过在激活函数之前插入一个 BN 层，来解决这一问题。 Forward Pass首先来看 Batch Normalization 的公式： 不难写出以下代码： 1234567sample_mean = np.mean(x, axis=0)sample_var = np.var(x, axis=0)k = np.sqrt(sample_var + eps)normalized_x = (x - sample_mean) / kout = gamma * normalized_x + beta 其中，x 是 (N, D) 维度的数据，即本次 batch 有 N 条样本，每个样本的维度是 D。 为了方便在 test time 做 batch normalization，还要同时计算一个 running mean 和 running variance 当作估计值。 123456running_mean = momentum * running_mean + (1 - momentum) * sample_meanrunning_var = momentum * running_var + (1 - momentum) * sample_var# test timex1 = (x - running_mean) / np.sqrt(running_var + eps)out = gamma * x1 + beta Backward Pass正向传播还算直观。接下来就要计算反向传播的梯度，以方便更新 gamma、beta 等参数。我们可以借助计算图，更容易地推导这几个要求解的导数：$$\\frac{\\partial out}{\\partial x}, \\frac{\\partial out}{\\partial \\gamma}, \\frac{\\partial out}{\\partial \\beta}$$计算图如下： 其中，浅绿色的文字代表正向传播的中间变量的值；橙色的文字代表反向传播的导数值；浅蓝色的文字代表了变量的维度。我们重点看其中的两个步骤。 红圈 1 这是我们反向计算的第一步。导数 dout 经过了一个加法运算。我们知道 x + y 对 x 或 y 求导，结果都是 1。根据链式法则，上一级的导数不会发生变化，也就是加法运算相当于导数的一个分配器 —— 导数被分流到两侧，而不发生变化。正常来说，d_beta 应该就等于 1 * d_out。但是如果我们看维度，就会发现 beta 本身的维度是（D），而 out 的维度是（N，D）。套用 numpy 中的概念来说，就是做加法的时候，beta 被 broadcast 了。也就是 beta 中某一个值对变化率（导数）的影响产生了 N 次。那在反向计算梯度时，就要把这 N 次累加起来。从 shape 来看，自然也就从（N，D）转化为（D）了。 红圈 2 这个步骤的导数计算就更加不直观了。但是本质上来说，这也是一个求和，因此导数也是会被派发给每个变量而不产生变化的。从这个角度思考，我们只需要将维度（D）的矩阵转化为维度（N，D）就可以了，因此构造一个维度为（N，D），元素全部为 1 的矩阵就可以了。从正向计算的角度思考，我们是通过求和的方式来让维度塌缩的，这和红圈 1 很类似。 通过计算图，我们也就可以确定哪些变量是可以在正向计算时缓存下来的了。 References[1] 关于Batch_Normalization的公式推导和代码实现 [2] Understanding the backward pass through Batch Normalization Layer","link":"/2020/12/02/fw-bw-batch-norm/"},{"title":"FlowNet and FlowNet 2.0","text":"FlowNet and FlowNet 2.0FlowNet 是第一篇利用 CNN 直接做 Dense Optical Flow Estimation 的工作（End-to-end）。由于我们并没有一个真正的传感器去直接获取到光流，所以光流的数据集很少，且规模较小。KITTI 是一个常用的真实世界的数据集（自动驾驶场景），它是用激光雷达获取三维世界中的运动关系，再转换到二维图像的光流。这样操作首先会有一定的误差，其次这个数据集中给出 label 的像素也是相对比较稀疏的（大约只有 50% 的像素有 label）。FlowNet 的另外一个贡献就是提供了 Flying Chairs 这个合成数据集。 虽然 FlowNet 证明了用深度学习做光流预测是可行的，但是精度上来看并没有撼动传统方法的 SOTA 地位，特别是在小位移的情况下。FlowNet 2.0 在没有显著增加运算量的情况下，将误差大幅降低了超过 50%。这样，FlowNet 2.0 的精度可以和 SOTA 方法相比较，且速度更快。 FlowNet-SFlowNet-S 代表 FlowNetSimple，它的结构如下图所示： 整体的结构比较常规，输入是两张图像 stack 到一起，因此是 6 个 channel。随着卷积和 pooling 运算，feature map 的尺寸逐渐缩小（pooling 是必要的，不但加快训练速度，而且还将更大范围内的信息聚合）。因此最后还需要提供一个 refinement 网络来把图像尺寸放大，最后生成高分辨率的光流。 RefinementRefinement 网络的结构如下： 这里通过所谓 upconvolution 的操作来对 feature map 进行放大。Upconvolution 包含两个运算，一个是 unpooling，即 pooling 的反运算，跟随一个卷积运算。在放大的同时，还将之前的 feature map 和本次预测的低分辨率的光流一起叠加，从而实现 refine。每次放大都使图像尺寸扩大两倍。作者连续这样操作了 4 次，最终的图像仍比输入图像小了 4 倍。但是作者发现继续重复操作没有什么收益了，因此最后直接通过双线性插值的方法放大到输入尺寸。 FlowNet-C这里的 C 代表 Correlation。除了 FlowNet-S 之外，文章还提出了一个更 fancy 的结构： 上下两层网络应该是共享权重的，分别对两张图片做操作。给了两张图片的 feature map 之后，该怎么样去找到匹配呢？作者在这里设计了一个 correlation layer。两个像素 x1 和 x2 的 correlation 定义为，在周围的一个 patch 之内做内积，之后累加求和。 当然这样的运算的复杂度比较高。文章提出一个减少运算量的算法，即设定一个 max displacement D，只计算 x2 在 x1 周围一段距离内的数值，而不计算 x2 周围完整的 patch。当然这个时候 D 就变成了一个超参数。 FlowNet 2.0在 FlowNet 2.0 中，作者首先发现训练策略对精度的影响较大。其次，作者发现 FlowNetC 比 FlowNetS 更优。作者还改进了网络结构，将多个子网络进行了堆叠。特别是引入了 FlowNet-SD 来有针对性地解决小位移情况下精度不足的问题。网络结构如下： 其中，Warped 代表 Image2 根据生成的光流做 warp 后的结果。理想情况下，如果 flow 是完美的，Warped 应该和 Image1 一致。其误差即为图中的 Brightness Error。FlowNet-SD 在 FlowNet-S 上做了轻微的改动，但是单独在小位移的数据集上进行了训练。Fusion 是一个较为简单的结构，先把分辨率进行了压缩，之后缩放到原始大小。","link":"/2022/07/10/flownet-explained/"},{"title":"Function Level Code Coverage for iOS","text":"Function Level Code Coverage for iOS在之前的博客中提到过，如果直接使用 Xcode 集成的代码覆盖率工具，提交 App 的时候似乎会被拒绝。这就导致如果我们想让线上的用户参与覆盖率测试就会受到困难，只能局限在公司内部进行测试。为了解决这个问题，就需要自己实现一套覆盖率检测工具。 思路最简单的想法当时是 hook msg_send 函数，但这个思路有一些缺点： 只能统计 Obj-C 的方法调用，对 C/C++ 方法无效 统计力度只能局限在函数调用级别，而不能精确到每一行代码 所以，最佳方案仍是仿照前人的做法，通过插桩来完成。由于这一套插桩逻辑很复杂，这里为了验证思路，只讨论简化成函数级别的代码覆盖工具的实现。即，统计哪些函数被调用了，哪些函数从未调用。 仿照 GCOV 的逻辑，我们可以编写一个 LLVM Pass。主要分为以下几步： 编译时，统计 iOS 程序中所有的函数名，并保存成 note 文件 编译时，对 iOS 程序中每个函数的开头进行插桩 运行时，由桩代码统计函数执行与否，并生成 data 文件 程序运行结束，比较 data 与 note 文件，得到函数覆盖率报告 核心代码实现在一个简单的 iOS 工程中，在 ViewController.m 中定义要插入的 C 函数： 1234extern void _mark_executed_func(char *funcName) { NSString *string = [NSString stringWithUTF8String:funcName]; NSLog(@&quot;%@&quot;, string);} 这里为了简便起见，只打印外部传入的函数名称。 为了插桩，编写一个 FunctionPass： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &quot;llvm/Pass.h&quot;#include &quot;llvm/Support/raw_ostream.h&quot;#include &quot;llvm/IR/LegacyPassManager.h&quot;#include &quot;llvm/Transforms/IPO/PassManagerBuilder.h&quot;#include &quot;llvm/IR/Module.h&quot;#include &quot;llvm/IR/Function.h&quot;#include &quot;llvm/IR/IRBuilder.h&quot;#include &quot;llvm/IR/Instructions.h&quot;#include &quot;llvm/IR/DebugLoc.h&quot;#include &quot;llvm/IR/DebugInfo.h&quot;#include &lt;string&gt;using namespace llvm;namespace { struct FuncCoverage : public FunctionPass { static char ID; FuncCoverage() : FunctionPass(ID) {} bool runOnFunction(Function &amp;F) override { if (F.getName().startswith(&quot;_mark_executed_func&quot;)) { return false; //不能再给桩函数插桩了 } LLVMContext &amp;context = F.getParent()-&gt;getContext(); //拿到当前Module的Context BasicBlock &amp;bb = F.getEntryBlock(); Instruction *beginInstruction = dyn_cast&lt;Instruction&gt;(bb.begin()); FunctionType *type = FunctionType::get(Type::getVoidTy(context), {Type::getInt8PtrTy(context)}, false); Constant *beginFun = F.getParent()-&gt;getFunction(&quot;_mark_executed_func&quot;); if (Function *fun = dyn_cast&lt;Function&gt;(beginFun)) { IRBuilder&lt;&gt; Builder(&amp;bb); CallInst *inst = CallInst::Create(fun, {Builder.CreateGlobalStringPtr(F.getName())}); auto SP = F.getSubprogram(); DebugLoc DL = DebugLoc::get(SP-&gt;getScopeLine(), 0, SP); inst-&gt;setDebugLoc(DL); //设置DebugLoc，给debugger使用 inst-&gt;insertBefore(beginInstruction); } return false; } };}char FuncCoverage::ID = 0;static RegisterPass&lt;FuncCoverage&gt; X(&quot;func-coverage&quot;, &quot;A pass that can check function coverage.&quot;, false, false);static RegisterStandardPasses Y( PassManagerBuilder::EP_EarlyAsPossible, [](const PassManagerBuilder &amp;Builder, legacy::PassManagerBase &amp;PM) { PM.add(new FuncCoverage()); }); 编译，并设置 Xcode 的编译选项，加载我们的 Pass。 这里需要设置 DebugLoc，否则会命中断言报错。这里我卡了比较久： 1inlinable function call in a function with debug info must have a !dbg location 运行这个含有红、蓝两个按钮的程序： 12345678//...- (void)onClickRedButton { NSLog(@&quot;red&quot;);}- (void)onClickBlueButton { NSLog(@&quot;blue&quot;);} 可以看到，每次点击按钮，都会打印出函数名称： 证明我们插桩成功了👏 缺陷 &amp; 改进由于我对 LLVM 非常不熟悉、且从未系统学习过编译原理，又找不到什么靠谱的教程，在编写 Pass 的时候可谓困难重重。因此，这个 Demo 仍存在一个重要的缺陷，但解决起来应该不会太难。 Demo 工程虽然能运行，但是比较 tricky。这是因为，在 Pass 中只能 Call 本 Module 的函数，而找不到外部的函数。想要运行，就要借助增量编译。先把整个工程编译一遍（不带 Pass），然后修改带有桩函数的文件，再加入 Pass 只编译此文件，才能完成插桩。要解决这个问题，就要让 IR 代码声明外部函数，这样 linker 才能链接到桩函数。在这个问答中提到，可以这样做函数声明： 12345You may only call a function from the same Module, and you may not use NULL as the callee.If the function is defined in another module, you need to first declare it in the module in which you want to make the call, then make the call using the declaration.To declare it, create an identical function in the new module (via Function::Create) and just don't assign it a body. 但由于精力限制，我还未做此尝试。 References: https://www.jianshu.com/p/b2f9efea49c3 https://www.jianshu.com/p/4d392b16d831 使用LLVM IR编程 一个古老的 LLVM 官方教程，版本 2.6，当前最新版本 11: http://releases.llvm.org/2.6/docs/tutorial/JITTutorial1.html","link":"/2020/02/02/func-level-ios-code-coverage/"},{"title":"Use GitHub Actions to Deploy Hexo Articles","text":"Use GitHub Actions to Deploy Hexo ArticlesThis article is used to test GitHub Actions 背景GitHub 前不久推出了用于 CI/CD 的 GitHub Actions，所有公共仓库都可以免费使用。不仅提供 Window，Linux （Ubuntu），macOS 三大操作系统，每个 VM 还配有双核处理器、7 GB RAM 和 14 GB 的 SSD 硬盘。可以说是非常香了。 我的博客使用 Hexo 撰写。此前，为了方便多台设备之间同步我的博客环境，我已经将 Hexo 源文件单独放置在了 hexo 分支下的 BeBeBerr.github.io/hexo 目录中。这样切换编写博客的设备时，只需要 pull 下来最新的源文件就好了。编写完成之后，自然是 clean generate deploy 一串操作。既然有了 GitHub Actions，就可以将部署的操作自动化了。 目标是：博客撰写完成，push 到远程仓库后自动部署。 配置 GitHub Actions首先修改 Hexo 的 _config.yml 文件，将 deploy.repo 改成 1git@github.com:BeBeBerr/BeBeBerr.github.io.git 的 SSH 形式，不再使用之前的 HTTP。 之后，执行 1ssh-keygen -f github-deploy-key 生成 SSH Key。公钥填到仓库设置的 Deploy Keys 中，记得勾选写权限。 由于 Actions 也是公开的，所以私钥绝对不能直接写到配置文件里。GitHub 在仓库的设置中提供了 secrets 项，可以将环境变量加密，只对指定的 Actions 开放。 密钥配置完成后，就可以新建 Action 的配置了。如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344name: Hexo-Deploy-CIon: push: branches: [ hexo ] # 在 hexo 分支发生 push 的时候触发jobs: # jobs 默认是并行的 build_and_deploy: runs-on: ubuntu-latest steps: # steps 之间是串行的 - name: Checkout uses: actions/checkout@v2 # actions 是 GitHub 官方仓库，提供了一些基础的 Actions。这里的作用是把仓库 checkout 出来，后面就可以访问了 with: ref: hexo # 当然是 checkout hexo 分支 - name: Setup Node.js Env uses: actions/setup-node@v1 # 类似的，这个 action 用于设置 node.js 环境 - name: Config SSH Key &amp; Git env: SSH_KEY: ${{ secrets.hexo_deploy_ssh_key }} # 通过环境变量获取私钥 run: | mkdir -p ~/.ssh/ touch &quot;~/.ssh/known_hosts&quot; echo &quot;$SSH_KEY&quot; | tr -d '\\r' &gt; ~/.ssh/id_rsa chmod 700 ~/.ssh chmod 600 ~/.ssh/deploy_key chmod 600 ~/.ssh/known_hosts ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts git config --global user.name 'wangluyuan' git config --global user.email 'mail@luyuan.wang' - name: Setup Hexo Env run: | npm i -g hexo-cli - name: Deploy run: | cd hexo npm i hexo clean hexo g hexo d 配置完成，push 之后 action 就会被触发了。虽然每次都不得不重新配置一遍 node 和 Hexo 环境，但是整体速度非常让人满意：一般 30 秒内就能运行完毕。 现在，撰写博客就更加方便了。","link":"/2020/03/08/github-action-hexo-deploy/"},{"title":"Intro to Computer Graphics - Building 3D GitHub Contributions Graph","text":"Intro to Computer Graphics - Building 3D GitHub Contributions Graph有这样一款插件，可以把 GitHub 的 contribution graph 用 3D 的形式展现出来，效果非常的炫酷。正好我最近正在看一些图形学的东西，干脆就自己实现一个可以动态旋转的 3D 图像来练练手。 想到放到 web 上来展示更便于分享，于是就使用了 WebGL + Three.js 框架。毕竟单纯使用 WebGL 操作还是太繁琐了，连 shader 都要自己写。 效果效果如下，还是比较好看的： 也可以访问 www.luyuan.wang 点击最下方的 statistics 按钮来查看。美中不足就是因为工作比较忙，这一年来都没什么时间写自己的代码，contributions graph 比较稀疏😂。 图形学概述如果知道物体的信息，怎么把图像画到屏幕上去呢？我们都知道屏幕是有像素阵列组成的，通过扫描的方式依次去给每个像素设置不同的 RGB 值。屏幕是一个光栅设备，绘制的这一过程就称为光栅化（Rasterization）。 那么已知物体的信息，怎么直到该点亮屏幕上的哪些像素点呢？这就要使用所谓的 MVP 变换。MVP 是 Model - View - Projection 的简写。通俗来说，Model 是指找来模型（物体），View 是把摄像机的位置摆放好，Projection 就是拍照。在图形学中，我们习惯把摄像机放在原点的位置，以 y 轴为正上方方向（up at y axis），并看向 -z 的方向（look at -z axis）。 View / Camera Transformation现实中，物体是随意摆放的，相机也是随意摆放的。为了把相机挪动我们习惯的原点，而拍摄到的相片内容不变，就要把所有的物体跟着一起转动过去。所谓“山不来就我，我就山”。 假设相机原始的位置是 e ，look at g, up to t。首先我们需要移动 e 到原点的位置，然后再旋转 g to -z ，t to y 。当然，第三个轴自然也就跟着转动过去了（右手系）。 经过推导，可得： 而最终的变换矩阵则为：$$M_{view} = R_{view}\\cdot T_{view}$$那我们为什么要做这样的变换呢？答案是为了更方便做下一步：投影。 Projection Transformation有两种投影方式，正交投影和透视投影。正交投影中，原本平行的线经过投影后仍然平行。透视投影则是我们日常肉眼见到的样子，所谓近大远小。两个平行的铁轨不再平行，而是相交于远处的一点🛤️。当我们把相机拉到无穷远处，也就没有了所谓的近大远小（远近的概念失去意义），这个时候看到的画面就是正交投影了。 正交投影的矩阵为： 透视投影可以分成两步，首先先把空间进行挤压，然后再做正交投影。 最终的透视投影矩阵为：$$M_{persp}=M_{ortho}\\cdot M_{persp\\rightarrow ortho}$$ Viewport Transformation投影矩阵会把世界压缩到 [-1, 1] ^ 3 的立方体里。我们还需要根据屏幕大小，把它变换到屏幕的尺寸上。这一步就称为视口变换。 光栅化我们平时在说图像性能时，经常会说“每秒能渲染多少个三角形”。三角形在图形学里非常重要，这有以下几个原因： 三角形的表现力很强，用三角形可以近似表示出非常复杂的曲面。 三个顶点构成的三角形一定在一个平面上 三角形的内部、外部很好区分（有很简单的算法） 三角形内部有 well-defined 的插值算法 通过刚刚的变换，物体（很多很多个三角形）已经变换到屏幕空间了。那么该怎么决定点亮哪些像素呢？要知道物体时连续的，而像素时离散的。答案很简单，通过用像素中心点的位置进行采样就可以了。 好的，现在我们已经能在屏幕上绘制出物体了。 着色 Shading单纯的画出物体，只能看到一些色块，显得不够真实。这个时候就需要对它们进行着色，比如，在不同的光线下，物体的颜色会发生变化。 一种简单的 shading model 是 Blinn-Phong 反射模型。他简化了光线的传播规律，把我们看到的反射光分为三项：高光、漫反射、环境光。通过对这三项进行叠加，可以给出一个不错的效果。 图中最左侧就是 Phong 的效果，Blinn-Phong 是 Phong 的一种改进算法。是不是比右侧没有 shading 的球看起来真实许多呢？当然，Phong 模型到底也是一个简单的模型，虽然能给出不错的效果，但离可以欺骗肉眼还有一定的差距。要想达到非常逼真的效果，简单的光栅化就不够了，就需要用到光线追踪技术。 现代的显卡都具有编程能力，可以通过 GLSL 语言来编写自定义的 Shader 程序。 Texture贴图的原理很简单，就是给一张图片，上面带有三角形顶点的映射关系。这样我们就可以根据三角形的顶点，把图片给“贴”到对应的模型的顶点处。这个映射关系是由设计师在设计贴图时编辑进去的，可以认为是已知量。 实现思路上面简要介绍了计算机图形学最基本的一些原理。那么这个 3D 的 contributions graph 到底是怎么画出来的呢？其实很简单，只需要根据贡献的次数来绘制一些高度不同的长方体、打上光照、再进行旋转就可以了。至于原始的数据，可以考虑直接爬取 GitHub 网站，调用 API 拼凑反而显得困难了。 实现细节首先，我们来定义相机的参数： 123456const fov = 75;const aspect = 2; // the canvas defaultconst near = 10;const far = 1000;const camera = new THREE.PerspectiveCamera(fov, aspect, near, far); 在介绍 Projection Matrix 的地方有一张图，可以看到 fov 是相机视线的夹角大小。Aspect 是画面的长宽比，这里暂时设定一个默认值，实际应该根据 canvas 的长宽比设置。 1234camera.position.x = 0;camera.position.y = -400;camera.position.z = 200;camera.lookAt(new THREE.Vector3(0, 0, 0)); 接下来我们设置了相机的位置，可见 x 轴是原点处，y 轴向后退了一些，z 轴向上升高了一部分。接下来旋转相机，让它看向原点的方向。 123456789101112131415for (var week = 0; week &lt; 53; week++) { for (var day = 0; day &lt; 7; day++) { //...... let geometry = new THREE.BoxGeometry(9.5, 9.5, depth); let material = new THREE.MeshPhongMaterial({ color: color }); let cube = new THREE.Mesh(geometry, material); cube.position.x = currentX; cube.position.y = currentY; cube.position.z = (depth / 2); scene.add(cube); //...... }} 接下来依次绘制长方体。首先要构造一个几何形体 geometry，就是一个 box。长款都一样，高度由 contribution 次数决定。然后要构造材质，为了有一个真实的光照效果，使用了 Phong 材质。几何形体 + 材质，就构成了一个网格 mesh。我们可以想象，这样的一个立方体是由 6 个面组成的，每个面是一个长方形，可以由 2 个三角形拼接形成。那么一个立方体就需要 12 个三角形。 绘制顶部的说明文字就比较 tricky，因为 three.js 并没有提供特别直观的 2D 文字 API。这里的思路是绘制一个 2D 的长方形表面，然后贴一个纹理上去。纹理贴图的内容就是文字。这是利用了 three.js 支持 canvas 作为贴图的特性。 1234567891011// draw text picutrevar canvas = document.createElement('canvas');context.fillText(text, x, y);// generate texture with that picturevar texture = new THREE.Texture(canvas);texture.needsUpdate = true;const geometry = new THREE.PlaneBufferGeometry(250, 100);// apply textureconst material = new THREE.MeshBasicMaterial({ map: texture, side: THREE.DoubleSide });material.transparent = true;const mesh = new THREE.Mesh(geometry, material); 这里只需要把材质本身设置成透明的，就看不出来 canvas 上没有文字的部分啦！ 结束语至此，一个 3D 的 GitHub contributions 图就画完了。虽然非常简单，但也算是利用图形学的知识的一次小小的实战，还是挺有意思的。","link":"/2020/06/27/github-graph-3d/"},{"title":"iOS-Layout学习笔记","text":"iOS Layout 学习笔记关于 iOS 布局系统的一些知识在我之前的博客中已经写过了，这里再补充一些。 优先级每个约束都有优先级，范围从 1 到 1000。优先级为 1000 的约束是必须的，小于 1000 的约束是可选的。Auto Layout 会优先满足高优先级的约束，如果一个可选的约束得不到满足，Auto Layout 会跳过它。 应用：左右两个 View A 和 B，当我们让 view A 消失时，view B 向左平移。 这是京东的一道面试题。面试官举出的应用场景是：左边是一个 loading indicator，在网络请求时一致播放加载动画，右边是一个 label。当请求完成后，需要把 indicator 移除，让 label 平移过来。 我们当然有很多种方法来实现这个需求，但显然通过合理设置约束的优先级能够更优雅地解决这个问题。只需要给 View B 添加一个到 A 一段距离的必须的约束，再给 B 添加一个到屏幕边缘的可选约束就好了。当 A 还在画面中时，可选的约束和必须的约束产生冲突得不到满足，因此 B 距离 A 一段距离。当我们把 A remove 掉之后，与 A 相关的约束也就不在了，那么可选的约束就可以满足，B 因此变为距离屏幕边缘一段距离。 通过设置优先级，我们不再需要更新约束，而只要简单的调用 removeFromSuperview 把 A 移除就可以了。 12345678910111213141516_leftView.backgroundColor = UIColor.blueColor;[_leftView mas_makeConstraints:^(MASConstraintMaker *make) { make.left.equalTo(self.view).with.mas_offset(20); make.top.equalTo(self.rightView); make.width.mas_equalTo(50); make.height.mas_equalTo(50);}]; _rightView.backgroundColor = UIColor.greenColor;[_rightView mas_makeConstraints:^(MASConstraintMaker *make) { make.left.equalTo(self.leftView.mas_right).with.mas_offset(40); //required make.left.equalTo(self.view).with.mas_offset(20).priority(800); //optional make.top.equalTo(self.view).with.mas_offset(100); make.width.mas_equalTo(50); make.height.mas_equalTo(50);}]; AutoresizingAutoresizing 是苹果在 iOS2 时引入的技术，用于描述父控件的 Frame 变化时，子控件应如何跟随变化。但它不能描述同级的 view 之间的关系。因此在 iOS6 之后有了 AutoLayout 技术，一般情况下就没必要再使用 AutoResizing 了。 查看一下 Autoresizing 的定义，发现是一些枚举值： 123456789typedef NS_OPTIONS(NSUInteger, UIViewAutoresizing) { UIViewAutoresizingNone = 0, UIViewAutoresizingFlexibleLeftMargin = 1 &lt;&lt; 0, UIViewAutoresizingFlexibleWidth = 1 &lt;&lt; 1, UIViewAutoresizingFlexibleRightMargin = 1 &lt;&lt; 2, UIViewAutoresizingFlexibleTopMargin = 1 &lt;&lt; 3, UIViewAutoresizingFlexibleHeight = 1 &lt;&lt; 4, UIViewAutoresizingFlexibleBottomMargin = 1 &lt;&lt; 5}; 我们可以发现，苹果通过把 1 左移不同的位数，构造出了掩码（mask）。在使用时，不同的 Autoresizing 类型只要按位或一下，就可以表示多个值的叠加。如 0010 与 0001 按位或，可以得到 0011，这样使用起来非常方便。 还有一点需要了解的就是，有时 Autoresizing 会和 AutoLayout 发生冲突而导致程序崩溃。这是因为 view 中有一个 Bool 类型的属性是 translatesAutoresizingMaskIntoConstraints ，顾名思义，它表示是否要把 Autoresizing 的设置翻译成等价的 AutoLayout。如果值为 true，又含有 Autoresizing 的信息，翻译过来的约束就可能和我们自己添加的约束产生冲突。这个时候只要把它设置为 false 就可以了。 sizeToFit VS sizeThatFits想要根据 label 文字长度改变 frame 时，还有在设置 toolBar 的一些设置中，都可以使用 sizeToFit 来让系统自动计算合理的 frame。事实上，sizeToFit 是 UIView 的方法，很多 view 都可以让系统来帮我们布局。 这两个方法的区别其实通过名字就很容易区分。sizeToFit 就是算出合理的尺寸后，改变自己的 size。而 sizeThatFits 就是算出合理的尺寸后，返回这个值，但不修改自己的 size，把决定权交给程序员。 Size Classes苹果为各种不同的设备、以及各个设备横屏、竖屏时的长宽分了三个等级：Compact，Regular，Any。我们在 Story Board 中可以看到 (w C h R) 的字样，改变设备和朝向后，这个值会跟着变化。Size Classes 可以说是对不同屏幕尺寸的一种抽象，让我们脱离开具体的尺寸数值。不过它只是对屏幕的分类，而不是布局方法，布局本身还是要通过 AutoLayout 来做。 使用 Size Classes 的好处是显而易见的：iPhone 横屏竖屏、iPad 各种 MultiTasking 状态、plus 机型横屏……众多情况都可以轻松解决。 在 Xcode9 的 Story Board 中怎么设置呢？首先我们要点击屏幕下方的 Vary For Traits 按钮，选中相应的 width 或 height。这个时候会进入 Size Classes 的编辑模式（底部变蓝）。选中之前 Any 状态设置的约束，把 installed 选项框取消选中。这个时候再添加约束，就是当前的 Size Classes 的约束了。之前的约束并没有被删掉，只是在当前状态下不加载了而已。完成后点击 Done 即可。可见通过 Story Board 拖动控件进行布局还是非常方便的。 如果这个时候你说：老板！我就想纯代码布局！可不可以嘛！ 当然可以！可以这样用： 1234UITraitCollection *collection = self.traitCollection;if(collection.horizontalSizeClass == UIUserInterfaceSizeClassCompact &amp;&amp; collection.verticalSizeClass == UIUserInterfaceSizeClassRegular) { //set your constrains} 在屏幕旋转等情况下，还会调用代理方法： 1- (void)willTransitionToTraitCollection:(UITraitCollection *)newCollection withTransitionCoordinator:(id&lt;UIViewControllerTransitionCoordinator&gt;)coordinator; 在这个代理方法中还要实现 Size Classes 改变后的约束。 可见，使用代码来完成 Size Classes 还是有些繁琐的。如果要同时适配 iPhone 和 iPad 的各种情况，就要啰啰嗦嗦写一大堆判断各种情况的代码，这点不如直接用 sb 布局方便。 UIStackViewUIStackView 是用于水平或垂直布局的控件，用以替换手工书写 AutoLayout。它的 subviews 的位置是根据对齐、间距、大小等属性决定的，并根据屏幕大小、方向动态进行调整。 UIStackView 的原理就是 AutoLayout，只不过是又抽象出了一层，让布局变得更加容易。我们还可以嵌套 UIStackView 来获得更精细的布局。和 Size Classes 类似，在 Story Board 中布局会比较方便，纯代码编写就显得冗长。 腾讯的一道面试题是：用 UIStackView 做布局有什么问题？答案是它是 iOS9 才引入的新控件，而大公司可能要支持的 iOS 版本比较多，就有兼容性的问题。我们平时做开发一般不必支持这么多个版本（而且随着 iOS12 即将在今年 6 月 WWDC 发布，这个问题将会进一步淡化），如果一定要支持早期版本，也有支持更多 iOS 版本的第三方的开源控件供我们使用。 关于 UIStackView 更详细的教程，可以参考Ray Wenderlich。 性能首先我们要谈一下屏幕显示原理。 CPU 把计算好要显示的内容提交给 GPU。GPU 会根据这些信息进行渲染，把渲染结果写入帧缓冲区。通常来讲，屏幕是一行一行刷新的，因此需要水平同步信号 HSync 和 垂直同步信号 VSync。每次刷新，屏幕都会从缓冲区取出数据进行绘制。这里的帧缓冲区（Frame Buffer）也就是我们通常所说的显存。 如果只有一个缓冲区，就会发生屏幕的闪烁。当屏幕去显存中去数据时，CPU 还没有完成全部的计算，也就是说缓存区的数据不完整，如果屏幕按照这个值来绘制，就会出现问题。下面的动图是我大二的时候利用 FPGA 制作视频小游戏时的情景，由于只使用了一个缓冲区，可以看到即使我没有完整的刷新屏幕（而是只刷新产生变化的部分），也存在明显的闪烁： 双缓存的原理是，GPU 向缓存区 A 提交数据，而显示器从已经有数据的缓存区 B 取数据绘制。只有在缓存区 A 写入完成后，显示器才切换至 A 取数据，同时 GPU 再向 B 区写数据。上面的例子中，如果当时使用了双缓存技术，运行效果将非常平滑（我当时没有在自己的项目中运用，但是却指导了其他小组的同学=.=）。可见有时产生性能问题不是说板子或者设备的性能不够，而是使用者没有完全发挥出它们的能力。同时我们再次验证了一句名言：“很多性能问题都可以通过缓存解决”。 iOS 设备是使用了双缓存的，安卓设备采用了三缓存。当 VSync 信号到来时，iOS 会通过 CADisplayLink 来通知 App。如果计算量过大，CPU 或者 GPU 没有在规定的时间提交数据，那么此帧就得不到刷新，画面将静止不动。这也就是我们所说的掉帧、卡顿的产生根本原因。 造成性能问题的原因有很多。在布局时，如果界面很复杂，又采用了 AutoLayout 技术，那么解这个多元方程组的时间将呈指数上升，占用大量的 CPU 时间。 ASDK (Texture)AsyncDisplayKit，现在更名为 Texture，是由 FaceBook 开源的异步渲染框架。由于 UIKit 不是线程安全的（为什么不做成线程安全的？一个是开发成本巨大，另一个是线程安全本身又会造成性能下降），ASDK 的思路就是能放在后台的，放在后台去做；实在不行的，尽量优化性能。 在布局方面，ASDK 同样支持手动布局，但是会做一些异步预加载的优化来提高性能。ASDK 还拥有 Automatic Layout （区别于 Auto Layout）来做自动布局。Automatic Layout 其实是制定了一套布局规则，通过 ASLayoutable 来松散耦合，不关心具体是 node 还是其他什么，因此可以复用这套布局逻辑。通过组合多个 Layout Specs 如 stack / inset 等完成复杂的布局，有点类似前端的 CSS。事实上，stack 和 UIStackView 也是类似的，但是 Layout Specs 本身不是依附于 UIView 的，而是单独存在的数据结构，因此它可以进行缓存、可以在后台计算，降低耦合的同时也提高了效率。由此来看，iOS 本身的布局系统其实并不先进，有很多值得向 CSS 等其他布局技术借鉴的地方。 参考自即刻技术团队的文章","link":"/2018/05/02/iOS-Layout%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"iOS 为 TableView 左滑删除添加图片","text":"iOS 为 TableView 左滑删除添加图片本文适用于 iOS11 起因最近做的项目中，PM 和设计想把 TableView 左滑删除、分享等按钮的文字替换成图片。我想既然 iOS11 自带的邮件应用中就是这样的，那实现起来应该很容易，就一口答应了。 开始开发的时候，我信心满满地在 Xcode 中敲下了配置左滑编辑功能的代理方法： 12345678func tableView(_ tableView: UITableView, editActionsForRowAt indexPath: IndexPath) -&gt; [UITableViewRowAction]? { let stickAction = UITableViewRowAction(style: .default, title: &quot;置顶&quot;) { (_, _) in // } stickAction.//??? return [stickAction] } 然后在自动补全中只看到了孤零零的 backgroundColor……什么！竟然没有配置图片的 API ！ 寻找解决方案要知道，左滑弹出的这些按钮无非也就是一些 Button，只要能拿到 Button，设置图片就很容易了。打开 Debug View Hierarchy，可以看到视图层级是这样的： 我们要找的按钮不就是这个 UISwipeActionStandardButton 类型的 Button 吗！只要拿到它就可以了。它的父视图是 UISwipeActionPullView 类型的 View，再往上一层就是我们的 UITableView 了。于是我到 Documents 上查了一下，想说看有没有调用的相关 API，发现竟然没有！震惊！看来又是私有属性！ 强行拿到 Button我们已知视图的类型和层级关系，拿到它也不困难。只要遍历 TableView 的子视图，找到 UISwipeActionPullView 类型的视图就可以了。注意这个类型是私有的，所以只能通过名字反射（抱歉这里借用了 Java 中反射的概念）进去： 1234567for each in self.tableView.subviews { if each.isKind(of: NSClassFromString(&quot;UISwipeActionPullView&quot;)!) { print(dump(each)) let btn = each.subviews.first! as! UIButton btn.setImage(UIImage(named: &quot;test&quot;), for: .normal) }} 离大功告成还剩最后一步！ 在合适的时机调用要想让代码成功执行，必须等待 TableView 已经配置好侧滑按钮。否则 UISwipeActionPullView 还没被实例化出来，肯定是找不到这个类型的变量的（我因为这个问题纠结了一个多小时，反应过来的时候想掐死自己）。 123456789func tableView(_ tableView: UITableView, willBeginEditingRowAt indexPath: IndexPath) { for each in self.tableView.subviews { if each.isKind(of: NSClassFromString(&quot;UISwipeActionPullView&quot;)!) { print(dump(each)) let btn = each.subviews.first! as! UIButton btn.setImage(UIImage(named: &quot;test&quot;), for: .normal) } }} 大功告成！ 写在最后首先，调用私有 API 是一件非常有风险的事情。有可能在审核的时候被苹果拒绝不说（这里应该还好），这些 API 和属性都是非常不稳定的。比如，在 iOS10 中表现会不一样。想兼容 iOS10 的话就要编写额外的代码，很麻烦。而且随着系统更新，这些方法可能会被苹果更改从而不再有效。 我不知道为什么这些很基本的东西苹果不愿意开放给开发者（类似的还有 UIAlertController，想自定义必须用 KVC 在运行时动态更改，而文档中明确写出不要继承它），但苹果自己却在使用。感觉很麻烦啊！唉。","link":"/2017/11/18/iOS-%E4%B8%BATableView%E5%B7%A6%E6%BB%91%E5%88%A0%E9%99%A4%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87/"},{"title":"Grad-CAM Overview","text":"Grad-CAM Overview我们经常在论文中见到下面这种 CNN 的可视化图，它能告诉我们神经网络在做预测时，更加关注哪部分的内容，从一定程度上解释了判定依据。比如下图中，神经网络预测的分类是 ‘cat’，猫所在的区域温度就显著更高；而狗的位置就没有反应。 那么这种可视化是怎么产生的呢？一种方式是通过注意力机制，在训练时就让神经网络去学习像素的权重。这样权重高的位置就是更重要的部分，自然也就是网络更关注的地方。但这需要我们去给网络加入相应的注意力模块，需要对网络进行修改并重新训练。而通过 Grad-CAM，我们不需要对网络做更改，就可以得到这样的可视化数据。 CAM在介绍 Grad-CAM 之前，必须先简单介绍一下 CAM，Class Activation Mapping。 这是 2016 年发表在 CVPR 的工作，具体工作原理如下： 输入的图片比较复杂，可以想象输出层的神经元对人和狗应该都有比较强烈的反应。CNN 中，每过一次卷积都会产生新的 feature map。最后一层 feature map 尺寸比较小，但是提取出了最抽象的特征，并蕴含着全局的信息。卷积天然就含有图片空间域的信息，而再之后的全连接层就会把空间域的信息丢失了，因此我们对最后一次卷积出来的 feature map 最感兴趣。 设最后一层 feature map 包含 n 个通道。CAM 通过全局平均池化（GAP）将每个通道压缩为一个值，变成 1x1xC 维度的 tensor，之后再通过 FC Layer 来做分类。假如输出层中，第二个神经元代表狗，那么与之相连接的权重 w1, w2, … wn 就体现了不同特征的重要程度。如图做一次加权，就可以得到热图了。 Grad-CAMCAM 的思路非常简洁，但是有一个缺点，就是必须依赖网络中存在 GAP 层。虽然许多现代的神经网络本身就含有 GAP 层，但是如果没有，就必须对网络进行修改再重新训练了。Grad-CAM 可以克服这一缺点，具体原理如下： 第一步，计算某个类相对 feature map 的导数：$$\\frac{\\partial y^{c\\space=\\space cat}}{\\partial A^k}$$这里 y_c 代表针对某一类的输出，比如 ‘cat’。A_k 代表最后一层，第 k 个通道的 feature map。 第二步，做全局平均池化：$$\\alpha_k^c = \\frac{1}{Z}\\sum_i\\sum_j \\frac{\\partial y^c}{\\partial A^k_{i, j}}$$这里得到的 alpha 值就相当于之前的权重，它反映了某个通道的重要程度，即某个特征对结果的贡献程度。 第三步，加权、ReLU：$$L^c_{Grad-CAM} = ReLU(\\sum_k \\alpha_k^c A^k)$$为什么需要 ReLU 呢？这里和激活函数没有关系，我们只是想把负数置为 0 而已。因为我们只关心对分类结果有正向影响的地方。负数的地方可能代表着图片中属于其他类别的地方。 最后计算出来的热图尺寸其实和最后一层的 feature map 是一致的，很小。但不要紧，直接插值缩放就好了。 PyTorch 实现为了计算 heatmap，我们需要拿到最后一层卷积的 feature map，以及输出结果相对它的导数。最后一层的 feature map 很好得到，因为是正向传播，直接改 forward 代码就可以了。但是导数的反向传播是 PyTorch 自动计算的，我们该怎么拿到呢？其实 PyTorch 提供了 foward_hook 和 backward_hook ，利用 hook 函数就可以很方便的得到这两个值。 123456789101112131415161718192021222324252627class GradCAM(): def __init__(self, model, layer_index=-6): # -6 is the last conv2d layer for mobilenet v2 self.model = model self.layer_index = layer_index self.register_hooks() def _forward_hook(self, module, input, output): self.feature_map = output def _backward_hook(self, module, grad_input, grad_output): self.feature_map_grad = grad_output[0] # grad_output is a tensor def register_hooks(self): _, layer = list(self.model.named_modules())[self.layer_index] layer.register_forward_hook(self._forward_hook) layer.register_backward_hook(self._backward_hook) def __call__(self, prediction, class_index): self.model.zero_grad() score = prediction[0, class_index] score.backward() alpha = self.feature_map_grad.mean(dim=(-1, -2), keepdim=True) heatmap = self.feature_map * alpha heatmap = heatmap.sum(1) heatmap = F.relu(heatmap) return heatmap 完整的代码上传到了 GitHub Gist 上：https://gist.github.com/BeBeBerr/5af065430dece675f2b585f260108998 Experiments使用上面的代码运行了两组实验： 顺序分别为原图、heatmap 本身、resize 后的 heatmap、heatmap 和原图的叠加。可以看到 heatmap 本身的尺寸是非常小的，在 MobileNet 中，最后一层卷积的输出只有 7x7。但是通过插值缩放后仍能体现出位置关系。可以看到飞机和耳机的关键区域温度是最高的，其他地方相对温度较低。这个实验结果符合直觉。 References[1] https://glassboxmedicine.com/2020/05/29/grad-cam-visual-explanations-from-deep-networks/","link":"/2021/06/12/grad-cam-overview/"},{"title":"iOS 核心动画","text":"iOS Core-Animation 动画熟悉 Core-Animation 框架Core-Animation ，中文译为“核心动画”，是 iOS 和 macOS 上一组非常强大的 API 。它的最底层是 GPU ，上层是 OpenGL ／ OpenGL ES 和 CoreGraphics ，这两个框架提供了一些接口来访问 GPU 。最上层 CoreAnimation 提供了大量封装好的 API 来实现简单或复杂的动画。程序员只需要编写很少的代码，比如修改几个参数，或者设置起始、终止状态，就可以制作出很精美的动画。 Core-Animation 是基于 Layer 的，而非 UIView 。利用 GPU 来计算，所以速度快、效率高，且不会拖累 CPU 造成程序卡顿。所有的动画都是在后台执行的，不会阻塞主线程。 基本动画的使用1. CABasicAnimationDemo - 模仿 iOS9 锁屏界面的“滑动以解锁”动画（在 iOS10 中这个动画已经被”按下主屏幕按钮以解锁“取代） 123456789101112131415161718192021222324252627282930313233343536373839404142let gradientLayer = CAGradientLayer() //创建一个&quot;梯度&quot;层gradientLayer.frame = CGRect(x: 0, y: 0, width: 200, height: 60)//设置起始位置和终止位置，由于是水平的，所以 0.5 也可以改成任何其他的值，没有其他影响gradientLayer.startPoint = CGPoint(x: 0, y: 0.5)gradientLayer.endPoint = CGPoint(x: 1, y: 0.5)//黑-白-黑的颜色渐变gradientLayer.colors = [UIColor.black.cgColor,UIColor.white.cgColor,UIColor.black.cgColor]gradientLayer.locations = [0,0.5,1] //每个颜色处于的位置，即白色在正中间，只要让这里动起来就可以了 let myview = UIView(frame: CGRect(x: 120, y: 200, width: 200, height: 60))myview.layer.addSublayer(gradientLayer) //把梯度层加入view.addSubview(myview) // CABasicAnimation 部分let gradient = CABasicAnimation(keyPath: &quot;locations&quot;)gradient.fromValue = [0,0,0.25]gradient.toValue = [0.75,1,1]gradient.duration = 3gradient.repeatCount = Float.infinity //无限循环gradientLayer.add(gradient, forKey: nil) //添加动画 let text:NSString = &quot;滑动以解锁&quot;//下面把文字转化为图片let textAttributes:[String:Any] = { let style = NSMutableParagraphStyle() style.alignment = .center return [NSFontAttributeName: UIFont.systemFont(ofSize: 25),NSParagraphStyleAttributeName: style]}() let image = UIGraphicsImageRenderer(size: CGSize(width: 200, height: 60)).image(actions: { _ in text.draw(in: CGRect(x: 0, y: 0, width: 200, height: 60), withAttributes: textAttributes)})let masklayer = CALayer() //遮罩层masklayer.frame = CGRect(x: 0, y: 0, width: 200, height: 60)masklayer.backgroundColor = UIColor.clear.cgColormasklayer.contents = image.cgImagemyview.layer.mask = masklayer //myview 其实是黑色的方块（带有动画），只露出来文字的形状 2. CAKeyFrameAnimation所谓的“关键帧动画”。与 BasicAnimation 的区别是： CABasicAnimation 只能设置起始和终止值，而 CAKeyFrameAnimation 可以用一个数组保存中间值，即记录下来“关键帧”的信息。 这里可以设置 path（其实 CABasicAnimation 也可以设置 path ），让动画沿着轨迹运动。但是设置 path 之后，value 值将被忽略。 Demo - 沿路径运动（ UIBeizerPath ） 123456let move = CAKeyframeAnimation(keyPath: &quot;position&quot;)move.path = UIBezierPath(rect: CGRect(x: 120+25, y: 200+25, width: 100, height: 100)).cgPathmove.duration = 3move.repeatCount = .infinity myview.layer.add(move, forKey: nil) 这里似乎不能直接设置反向运动。想要反向运动需要自己绘制一个反向的矩形。 Demo - 圆形进度条（ CAShapeLayer ） 1234567891011121314151617let shape = CAShapeLayer()shape.frame = myview.boundsshape.path = UIBezierPath(ovalIn: shape.frame).cgPathshape.fillColor = UIColor.clear.cgColorshape.lineWidth = 5shape.strokeColor = UIColor.red.cgColor myview.layer.addSublayer(shape) let anim = CAKeyframeAnimation(keyPath: &quot;strokeEnd&quot;) //strokeEnd 也是可以动的参数anim.values = [0,1]anim.keyTimes = [0,1]anim.duration = 3anim.autoreverses = trueanim.repeatCount = .infinity shape.add(anim, forKey: nil) 3. CATransitionDemo - 简单的转场动画（渐变效果） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import UIKitimport PlaygroundSupportclass ViewController: UIViewController, UIViewControllerTransitioningDelegate { let button = UIButton(frame: CGRect(x: 100, y: 100, width: 50, height: 50)) override func viewDidLoad() { view.backgroundColor = UIColor.white view.addSubview(button) button.backgroundColor = UIColor.red button.addTarget(self, action: #selector(ViewController.onClick), for: .touchUpInside) } func onClick() { let vc = YellowViewController() vc.transitioningDelegate = self present(vc, animated: true, completion: nil) } func animationController(forPresented presented: UIViewController, presenting: UIViewController, source: UIViewController) -&gt; UIViewControllerAnimatedTransitioning? { return Animator() } func animationController(forDismissed dismissed: UIViewController) -&gt; UIViewControllerAnimatedTransitioning? { return nil }}class YellowViewController: UIViewController, UIViewControllerTransitioningDelegate { override func viewDidLoad() { view.backgroundColor = UIColor.yellow }}class Animator: NSObject, UIViewControllerAnimatedTransitioning { let duration = 2.0 func transitionDuration(using transitionContext: UIViewControllerContextTransitioning?) -&gt; TimeInterval { return duration } func animateTransition(using transitionContext: UIViewControllerContextTransitioning) { let containerView = transitionContext.containerView let toView = transitionContext.view(forKey: .to)! containerView.addSubview(toView) toView.alpha = 0 UIView.animate(withDuration: duration, animations: { toView.alpha = 1 }) }}PlaygroundPage.current.liveView = ViewController() 问题1. CoreAnimation 的工作机制CoreAnimation 是基于 layer 的动画，通过 GPU 来渲染。而基于 view 的动画是通过调用 drawRect 方法使用新参数不断的重绘内容，使用 CPU 来不断的计算，因而效率很低。 2. 为什么动画结束后返回原状态？为什么动画在移动过程中我们不能进行操作？因为在动画运行时，我们看到的并不是该控件本身，而是一个假的“躯壳”，即 presentation layer 。真实的控件会被隐藏，而只有视觉层在做动画，所以移动的过程中不能做任何操作。一旦动画结束， presentation layer 就会被移除，真实的控件又会显示出来，这就是为什么动画结束后会返回到原状态：因为动画并没有修改控件本身的属性，结束后又回到了 model layer 的值。有时候会为了不让动画结束后跳回原状态而设置 fillMode 参数，但是这也这是让 presentation layer 停留在最后的位置。如果你的控件是可以操作的，那就不可以这么做。","link":"/2017/06/04/iOS-%E6%A0%B8%E5%BF%83%E5%8A%A8%E7%94%BB/"},{"title":"Getting Started to iOS Code Coverage","text":"Getting Started to iOS Code Coverage获得代码覆盖率报告可以让我们更精准地进行测试。LLVM 本身就通过编译插桩提供了这样的能力，因此可以很简便地实现这一功能。但根据 Technical Q&amp;A QA1964 提到的内容，带有 LLVM instrumentation 的 App 在提交的时候会被以下理由拒绝。因此如果要在线上做覆盖率检测，可能需要我们自己来实现。 1Invalid Bundle - Disallowed LLVM instrumentation. Do not submit apps with LLVM profiling instrumentation or coverage collection enabled. Turn off LLVM profiling or code coverage, rebuild your app and resubmit the app. 下面先介绍如何使用 Xocde 本身集成的代码覆盖率检测工具 gcov。第三方的 Xcode Coverage 提供了一些便利的工具，但暂时先不使用。 设置 Build Settings首先在 Build Settings 中打开以下两个设置选项： 12Instrument Program Flow = YesGenerate Legacy Test Coverage Files = Yes 这样，编译的时候会生成记录 Basic Block (BB) 和代码映射关系的 notes 文件，由编译器生成。运行时会生成记录代码执行情况的 data 文件，由实际要执行的程序生成。 找到 gcda 和 gcno 文件为了找到 .gcno 文件所在的路径，需要在 Build Phases 中增加一个 Run Script 脚本，导出相应的环境变量。 123scripts=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot;echo $( dirname &quot;${BASH_SOURCE[0]}&quot; )export | egrep '( BUILT_PRODUCTS_DIR)|(CURRENT_ARCH)|(OBJECT_FILE_DIR_normal)|(SRCROOT)|(OBJROOT)|(TARGET_DEVICE_IDENTIFIER)|(TARGET_DEVICE_MODEL)|(PRODUCT_BUNDLE_IDENTIFIER)' &gt; &quot;${scripts}/env.sh&quot; 通过 echo 出来的路径可以让我们找到 env.sh 文件，在里面可以看到 OBJECT_FILE_DIR_normal 等更多的环境变量。在我的环境中，这个路径是： 1~/Library/Developer/Xcode/DerivedData/test-eurtcozdclpemgfxnumfljldtdjk/Build/Intermediates.noindex/test.build/Debug-iphonesimulator/test.build 进入当前路径下的 Objects-normal/x86_64 ，就可以看到包括 .gcda 文件在内的编译产物了。因为我在使用模拟器，因此架构名称是 x86_64 。 运行程序，以生成 .gcda 文件。使用模拟器的话，生成的 .gcda 的文件也会存放于这个路径下。而使用真机的话，.gcda 文件就会处于沙盒的 Documents 目录下。 这里注意，只有在应用正常退出（双击 Home 键 kill 掉程序）后，.gcda 文件才会生成。 解析并生成报告我们将 .gcno 和 .gcda 文件拷贝到源代码目录下，然后 cd 进入到源代码的顶层目录下。这是因为 .gcno 文件记录了代码的相对路径，如：test/ViewController.m ，如果目录的相对位置与之不符，解析时会出现错误。 之后，需要安装用于解析这两种文件的工具 lcov 。之后执行命令： 1lcov -c -b &lt;base dir&gt; -d &lt;filename&gt; -o &lt;output&gt;.info 生成 .info 文件。之后执行： 1genhtml cov.info 打开 index.html 就可以直观的 html 报告了🎉🎉🎉 在这个例子中，我放置了红色、蓝色两个按钮，并在运行时只点击红色按钮。从报告中可以看到，蓝色按钮的回调函数从未被覆盖到。 lcov 还可以通过 -a 来增加其他的 .info 文件，从而整合多人的覆盖率。 原理浅析LLVM 通过编译插桩，修改 IR 代码从而实现了代码执行情况的统计。其中，一个重要的概念是 Basic Block (BB) 。 Basic Block Graph一个 BB 的定义是：只有一个顺序的代码结构，只有一个入口和一个出口。这意味着中间没有 jump 指令，只有最后一行代码能让程序执行到其他的 BB。这意味着，只要当前的 BB 中第一行代码被执行，块内的代码就都会被顺序的执行一次。 如果跳转是有条件的，那么就会产生一个分支（ARC）。这种情况下，一个 BB 就会有两个可能的终点。把每一个 BB 当作节点，每一个 ARC 当作边，就会构成一个有向图。运行时，根据 ARC 的条件，就可以推算出 BB 的执行次数。根据 .gcno 的映射关系，就可以得到代码的覆盖率。 下面以一个真实的例子演示。出于简便起见，我们编写一段简单的程序 hello.c ： 12345678910#include &lt;stdio.h&gt;int main(int argc, char **argv){ if (argc &gt; 1) { printf(&quot;Hello, how are you doing?\\n&quot;); } else { printf(&quot;Haha, I'm doing great!\\n&quot;); } return 0;} 之后，编译并得到 .gcno 文件： 1clang -ftest-coverage -fprofile-arcs hello.c -o hello 运行可执行文件，得到 .gcda 文件。由于是二进制的文件，较难阅读（具体格式可参见 gcov-io.h 中的描述）。但我们可以使用： 1gcov -dump hello.gcda 把内容解析出来。内容如下： 12345678910111213141516171819202122232425===== main (0) @ hello.c:3Block : 0 Counter : 1 Destination Edges : 1 (1), Lines : 3,Block : 1 Counter : 1 Source Edges : 0 (1), Destination Edges : 2 (0), 3 (1), Lines : 4,Block : 2 Counter : 0 Source Edges : 1 (0), Destination Edges : 4 (0), Lines : 5,6,Block : 3 Counter : 1 Source Edges : 1 (1), Destination Edges : 4 (1), Lines : 7,Block : 4 Counter : 1 Source Edges : 2 (0), 3 (1), Destination Edges : 5 (1), Lines : 9,Block : 5 Counter : 1 Source Edges : 4 (1),File 'hello.c'Lines executed:66.67% of 6hello.c:creating 'hello.c.gcov' 根据这些信息，我们可以画出这样的图，其中含有代码执行次数和行号信息： 插桩前后对比通过生成 IR 代码，我们可以对比出插桩前后的区别： 左边为原始代码，右边为插桩后。用粉色标记出来的地方即插入的桩代码，可见是插在每个 BB 前面的。从 load - add - store 的结构中也能看出计数的过程。 References： [1] iOS 覆盖率检测原理与增量代码测试覆盖率工具实现，美团技术团队 https://www.jianshu.com/p/0431b23adba3 [2] https://github.com/yanxiangyfg/gcov [3] http://www.c-s-a.org.cn/csa/ch/reader/create_pdf.aspx?file_no=6776&amp;flag=1&amp;year_id=2019&amp;quarter_id=2 [4] https://blog.csdn.net/yanxiangyfg/article/details/80989680 [5] https://github.com/llvm-mirror/llvm/blob/release_70/lib/Transforms/Instrumentation/GCOVProfiling.cpp [6] https://github.com/llvm-mirror/compiler-rt/blob/release_70/lib/profile/GCDAProfiling.c","link":"/2020/01/29/getting-started-to-iOS-code-coverage/"},{"title":"iOS 蓝牙开发初步","text":"iOS 蓝牙开发初步注意：CoreBluetooth 是基于 BLE 4.0 版本的。 官方教程：Core Bluetooth Programming Guide CoreBluetooth 简介低功耗蓝牙技术是基于蓝牙 4.0 版本的，它在低功耗设备之间定义了一系列通信协议。CoreBluetooth 框架是低功耗蓝牙通信协议的一个抽象：它帮开发者隐藏了许多底层技术的细节，使得开发能与低功耗蓝牙设备交互的 App 变得更容易。 中心设备和外围设备是 CoreBluetooth 里最重要的两个角色。不同角色有不同的任务：外围设备拥有其他设备所需要的数据；中心设备用外围设备提供的信息去完成某些任务。举例来说：一个装备了低功耗蓝牙技术的心率探测器为一个 iOS App 提供了房间的温度，而 App 将这些数据用用户友好的方式呈现出来——就像传统的服务器-客户端结构那样。 外围设备的数据结构外设可能会包含多个服务（services），或者提供一些关于连接信号强度的信息。一个服务是指为了完成某种功能所需要的数据和行为的集合。 服务本身由特征（characteristics）或者包含的服务（其他服务的引用）组成。一个 characteristic 提供了外设服务的更多细节。举例来说，心率监视器的服务只描述了它可能含有一个描述身体传感器位置的特征，和一个心律测量值的特征。 当中心设备成功建立了和外设的连接之后，它就可以发现外设提供的所有服务和特征。中心设备也可以通过读或者写特征的值来与外设交互。比如你的 App 会从温度控制器中获得一个温度，也会提供一个温度值给控制器，使它调节室温。 中心设备、外设和外设数据的表现方式除非特别设置，多数情况下本地设备会以中心设备的方式工作。中心设备是一个 CBCentralManager 对象。这个对象用来管理已发现或已连接的远程外围设备。包括扫描、发现和连接正在广播的外设。外设用 CBPeripheral 对象表示，外设的服务用 CBService 表示。类似的，服务的特征用 CBCharacteristic 对象表示。 在 macOS 10.9 和 iOS 6 之后，Mac 和 iOS 设备也可以用作低功耗蓝牙外设，向其他设备提供数据。本地设备作为外设时，用 CBPeripheralManager 表示。这些对象涌来管理发布的服务。远程中心设备用 CBCentral 表示。Peripheral Manager 也涌来读或写中心设备发出的请求。 可以看到，本地设备作为中心设备和外围设备时，使用的类和类的作用是对偶的。 简单应用构建外围设备由于模拟器上不能操作蓝牙，所以必须使用真机进行调试。因此可能需要两部 iOS 设备，一台用来做中心设备，另外一台做外设。如果不想自己写外设的代码，也可以使用 LightBlue 软件模拟外设。这里我用了 Arduino Uno 单片机，配合蓝牙 4.0 模块作为外设。 使用时，需要给蓝牙模块 Vcc 引脚接 5V 的电压，Gnd 引脚接 Arduino 的“接地”。蓝牙模块的 Rx 接 Arduino 的Tx，Tx 接 Rx。 用 Arduino 操作蓝牙通信非常简单，因为 Arduino 屏蔽了底层的细节，将蓝牙看作普通的串口。因此直接操作串口既可以了。打开 Arduino IDE，将下面的代码下载到单片机。 12345678910111213void setup() { // put your setup code here, to run once: Serial.begin(9600);}int i = 0;void loop() { // put your main code here, to run repeatedly: Serial.println(i); i++; delay(2000);} 这里波特率设为 9600 符号／秒。在 loop 中，每间隔 2 秒发送一个数字，同时数字加一。需要注意的是，由于 Arduino 下载程序也需要使用串口，所以会和蓝牙模块连接的串口冲突。下载程序时，需要暂时断开 Rx 和 Tx 引脚。 构建中心设备需要以下几个属性： 123var manager: CBCentralManager!var peripherals = [CBPeripheral]()var connectedPeripheral: CBPeripheral? peripherals 用来存放扫描到的设备，connectedPeripheral 代表需要操作的外设。 在 viewDidLoad() 中，对 manager 初始化： 1manager = CBCentralManager(delegate: self, queue: DispatchQueue.main) 代理选择 self，线程选择主线程。为了设置代理，需要遵守 CBCentralManagerDelegate 协议，并实现该协议的 required 方法： 12345678func centralManagerDidUpdateState(_ central: CBCentralManager) { switch central.state { case .poweredOn: manager.scanForPeripherals(withServices: nil, options: nil) default: print(&quot;未开启蓝牙&quot;) }} 用 manager 的方法，必须保证蓝牙状态处于 poweredOn。如果蓝牙已开启，则开始扫描外围设备。填 nil 表示不做过滤，扫描一切外围设备。扫描到外设会自动调用下面的方法： 123456func centralManager(_ central: CBCentralManager, didDiscover peripheral: CBPeripheral, advertisementData: [String : Any], rssi RSSI: NSNumber) { if peripheral.name! == &quot;BT05&quot; { peripherals.append(peripheral) manager.connect(peripheral, options: nil) }} 利用外设的名字判断我要连接的设备。我的蓝牙模块名称默认是“BT05”。如果发现了该设备，进行连接。注意，必须持有该外设对象的引用，否则会报错。所以将它添加到数组中。使用数组是因为在一般的应用中，可能不止需要一个外设，这里并不是必须的。 连接到外设后，会调用下面的方法： 12345678func centralManager(_ central: CBCentralManager, didConnect peripheral: CBPeripheral) { connectedPeripheral = peripheral peripheral.discoverServices(nil) peripheral.delegate = self print(peripheral.name!) manager.stopScan()} 去查看已连接外设的服务。参数传 nil 同样是查看所有服务，不加过滤。将连接的外设的代理设为 self，因此需要遵守 CBPeripheralDelegate 协议。 发现了外设的服务，会调用下面的方法： 1234567func peripheral(_ peripheral: CBPeripheral, didDiscoverServices error: Error?) { for each in peripheral.services! { if each.uuid.uuidString == &quot;FFE0&quot; { peripheral.discoverCharacteristics(nil, for: each) } }} 遍历外设的所有服务，用 uuid 来判断感兴趣的服务。注意这里的 uuid 是服务的 uuid 而不是外设的 uuid。可以通过下载软件 LightBlue 查看服务的 uuid 码，这里是 FFE0。一旦发现，就去获取该服务的特性（characteristic）。 发现了特性会调用下面的方法： 123456func peripheral(_ peripheral: CBPeripheral, didDiscoverCharacteristicsFor service: CBService, error: Error?) { for each in service.characteristics! { peripheral.readValue(for: each) peripheral.setNotifyValue(true, for: each) }} 遍历所有的 characteristic，读取它的值并允许接受广播。这样每次 characteristic 的值变化后，都会调用下面的方法： 1234func peripheral(_ peripheral: CBPeripheral, didUpdateValueFor characteristic: CBCharacteristic, error: Error?) { let str = String(data: characteristic.value!, encoding: .utf8) print(str!)} 这里把接收到的值转换为字符串，并用 UTF-8 编码。之后把收到的字符串打印出来。 测试用面包线把单片机和蓝牙模块连接好，上电。把程序放到真机上调试，在控制台输出： 每隔两秒，输出一个数字，且每次加一。这里没有从 0 开始是因为单片机一上电，就自动开始工作了，不会等到蓝牙连接好再往串口上写数据。测试成功。 今天学习了 CoreBluetooth 的基本概念，并了解了基本的操作流程。可以看到使用 CoreBluetooth 流程比较多，如果不了解基本的概念可能会比较懵。不过总体来说逻辑一层套一层非常严谨，不难理解。接下来我会尝试用蓝牙构建稍复杂的应用。","link":"/2017/07/04/iOS-%E8%93%9D%E7%89%99%E5%BC%80%E5%8F%91%E5%88%9D%E6%AD%A5/"},{"title":"iOS 布局与自动布局","text":"iOS 布局与自动布局关于AutoLayout的苹果官方教程 Key PointsLayout Process 布局过程参见 Core Layout Runtime 相比于 Frame 布局，Cocoa Auto Layout 除去显示（display）以外，还在之前增加了两个更多的过程：updateConstraintsIfNeeded 和 layoutIfNeeded 。这些过程按顺序进行：更新约束、布局、显示。如果你手动唤起显示，那么显示会唤起布局，布局会唤起更新约束（显示依赖布局，布局依赖约束）。 你可以认为更新约束的传递就像是测量的传递。例如，如果你改变了一个按钮的标题，那么文字会被测量，并且约束会被设置以向布局系统通知信息。 详细过程： 更新约束，被称为测量阶段。这个过程自下而上（从子视图到父视图），为下一步的布局做准备。可以调用 setNeedsUpdateConstraints() 去触发此步骤，约束发生改变时亦会自动触发。但是当自定义 view 的时候，如果一些改变会影响布局，需要用 updateConstraintsIfNeeded() 手动通知AutoLayout。自定义 view 通常需要重写 updateConstraints 方法，在其中添加 view 需要的局部约束。SnapKit 的示例代码中，约束就是在这个方法中添加的。注意⚠️：updateConstraints() 方法不应该手动直接调用。 布局，自上而下（从父视图到子视图）。应用上一步的信息去设置 view 的 center 和 bounds 。可以通过 setNeedsLayout() 方法去触发此步骤，但此方法不会立即触发布局过程。想要立即更新布局，可以调用 layoutIfNeeded() 方法。自定义的 view 可以重写 layoutSubviews() 方法获得更多自定义效果。该方法会被 layoutIfNeeded() 方法自动触发，不要手动直接调用。 显示，此过程将 view 渲染到屏幕，此过程与是否使用 AutoLayout 无关，自上而下（父视图到子视图），通过调用 setNeedsDisplay() 方法触发。 以上三个过程不是单向的。如果在 layout 的过程中改变了 constraints，那么 update constraints 过程又会被再次触发。如果 layoutSubview() 方法中唤起了另外的布局过程，那么有陷入死循环的风险。 死循环举例： 1234567891011121314151617181920212223class myView: UIView { override func layoutSubviews() { print(&quot;layoutSubviews&quot;) self.constraints.first?.constant += 5 //修改约束，会再次唤醒更新约束过程；之后又会唤起布局过程，无限循环 }}class ViewController: UIViewController { let myview = myView() override func viewDidLoad() { super.viewDidLoad() view.addSubview(myview) myview.translatesAutoresizingMaskIntoConstraints = false myview.backgroundColor = UIColor.red } override func viewDidAppear(_ animated: Bool) { myview.addConstraint(NSLayoutConstraint(item: myview, attribute: NSLayoutAttribute.width, relatedBy: NSLayoutRelation.equal, toItem: nil, attribute: .notAnAttribute, multiplier: 0.0, constant: 10)) myview.addConstraint(NSLayoutConstraint(item: myview, attribute: NSLayoutAttribute.height, relatedBy: NSLayoutRelation.equal, toItem: nil, attribute: .notAnAttribute, multiplier: 0.0, constant: 10)) view.addConstraint(NSLayoutConstraint(item: myview, attribute: NSLayoutAttribute.centerX, relatedBy: NSLayoutRelation.equal, toItem: self.view, attribute: .centerX, multiplier: 1.0, constant: 0)) view.addConstraint(NSLayoutConstraint(item: myview, attribute: NSLayoutAttribute.centerY, relatedBy: NSLayoutRelation.equal, toItem: self.view, attribute: .centerY, multiplier: 1.0, constant: 0)) view.layoutIfNeeded() }} Content Hugging Priority &amp; Content Compression Resistance Priority 控件的两个优先级参数像 ImageView，Label，Button 这样的控件可以根据内容计算出大小。比如 Label 中的文字越多，Label 也就越长。这个大小被称为固有值。如果设置了约束，比如设置 label 的左边距屏幕边界100，右边距边界100，则 label 可能会被拉长。 Content Hugging Priority 表示控件抗拉伸的优先级。数字越大，控件越不容易被拉伸。默认值是251。 Content Compression Resistance Priority 表示控件抗压缩的优先级。数字越大越不容易被压缩。默认值是750。 这里两边的约束都是100，label 本应该被拉长以满足约束的要求。如果把右边的约束优先级修改为10，左边优先级不变，为默认的1000，Content Hugging Priority 为默认的251，高于10。所以优先满足左边的约束和 label 的固有大小，因此右边的约束无效了。 Frame &amp; Alignment Rect 两个不同的矩形自动布局参照的是 Alignment Rectangle 而不是 Frame。比如一个控件的阴影并不会影响到自动布局。应该牢记在自动布局中，Frame 没有视觉大小重要。 AutoLayout Constraints 自动布局的约束视图的布局体系由一系列线性方程所确定，每个约束都可看作是一个方程的表示。 多数的约束都由两项组成，但是当你设置一个视图的长度、宽度为一个常数时，第二个属性（attribute）会被设为Not An Attribute，比例系数会变成0.0。 Cassowary 布局算法Cassowary 是上世纪 90 年代的一个布局算法，它通过将布局问题抽象成线形等式和不等式约束，求解这个多元方程组来算出 x，y，width 和 height。AutoLayout 就是对 Cassowary 的一个实现。 AutoLayout Performance 自动布局的性能AutoLayout 的性能瓶颈就是 Cassowary 求解多个方程组的效率问题。因此有人建议在 TableView 中不要用 AutoLayout 设置动态高度的 Cell，而是自己手动计算。 网上有人对 AutoLayout 和 Frame 做了性能对比测试，可见当 view 很多时，AutoLayout 的速度会慢很多。 Masonry &amp; SnapKit 自动布局库一个简单易用的 AutoLayout 库，可以告别系统自带 api 冗长的代码。Masonry is for Obj-C, SnapKit is for Swift. GitHub地址：https://github.com/SnapKit ComponentKit and its layout 视图框架ComponentKit 是 FaceBook 开源的响应式视图框架，不支持 Swift。 GitHub地址：https://github.com/facebook/componentkit Constraints Priority 约束优先级每个约束都有优先级（Priority），范围从1～1000。优先级为1000的约束为必须的（required），其余的为可选的（optional）优先级的绝对大小没有意义，重要的是相对大小。Auto-Layout 会优先满足优先级高的约束。如果一个可选的约束不能被满足，Auto-Layout 会跳过它转而计算下一个约束。 即使可选的约束可能会不被满足，但它依然对布局有影响。系统会选择最接近这个约束的解决方案，不被满足的约束可以看作是一股将视图拉向它的力。 可选的约束经常和不等式配合工作： 123456789// A single equal relationshipBlue.leading = 1.0 * Red.trailing + 8.0// Can be replaced with two inequality relationshipsBlue.leading &gt;= 1.0 * Red.trailing + 8.0Blue.leading &lt;= 1.0 * Red.trailing + 8.0 你可以对上面的两个不等式设置不同的优先级。大于等于不等式的优先级可以设为必须的（1000），小于等于可以设置得低一些（250）。这意味着蓝色的视图与红色视图的距离不能小于8，但是其他的约束可能把它拉得更远。当时可选的约束会把蓝色视图拉向红色视图，保证它尽可能地逼近 8 个点的距离。 AutoLayout with hidden UIViews layouts 隐藏的视图的自动布局如果一个 view 被隐藏了，只是试图上看不到了，但是其他的视图距它的约束没有变。如果想让其他的视图跟着变化，可能要修改约束的值，或移除约束，这样代码会过于繁琐。 如下图，如果我们隐藏第一个 Button，第二个 Button 的位置不会改变。而很多情况下我们希望让第二个 Button 位置往左平移，就像第一个按钮真的不存在一样。 Variable row heights (iOS7 &amp; iOS8) 变化的行高iOS7 和 iOS8 下代理方法调用顺序不同。iOS7 先调用 heightForRowAtIndexPath 方法，后调用 cellForRowAtIndexPath 方法；而 iOS8 与之相反。 AutoLayout in UITableView for dynamic cell 表格视图中动态的 CellTableViewCell可以自适应高度，但这个功能不是默认实现的。只有当以下的两个属性被设置后，系统才会使用AutoLayout计算每行的实际高度。 123tableView.estimatedRowHeight = 85.0tableView.rowHeight = UITableViewAutomaticDimension 注意：你不能改变预先定义好的部分的布局，如 textLabel , detailTextLabel, imageView。 Questions &amp; AnswersPros and cons of AutoLayout &amp; Frame Layout 不同布局方式的优缺点分析UI 布局有以下三种主要方法： Frame layout：直接用代码设置每个控件的 Frame。 使用 auto-resizing masks：可以自动调整子视图与父视图之间的位置关系。 使用 auto-layout。 使用 frame layout 最直接，最灵活。当需要发生变化的时候，所有的改变都有你自己来控制。它带来的问题就是过于繁杂。即使一个很简单的界面，为了适配各种可能的情况，都要花费大量的精力去设计、调试、维持。Frame 的性能高。 使用 auto-resizing masks 可以部分地解决上述问题。但它只是完整的解决方案中的一个子集，无法适应所有可能的情况。而且它只能应对来自外部的改变，如 macOS 中用户调整了窗口大小、iOS中的横屏和分屏。而内部的改变如本地化、app 展示的内容改变这类的问题无法解决。 使用 auto-layout 可以动态地解决内部改变和外部改变。它不直接设置控件的大小和位置，而是通过约束去考虑控件之间的相对关系。功能强大，但可能有点抽象，跟传统的方法不太一致。 AutoLayout 性能低，而且代码冗长蹩脚。 How to get real frame after AutoLayout 自动布局之后怎样获得控件真实的 Frame在 layoutSubviews() 中对子视图设置约束，首次获取的 frame 不会是自动布局后真实的尺寸，而是一开始默认的值。也就是说在 layoutSubviews() 方法中获取 frame 时，布局还没有完成： 123456789101112131415class myView: UIView { var mysubview = UIView() override func layoutSubviews() { print(&quot;layoutSubviews&quot;) self.addSubview(mysubview) mysubview.translatesAutoresizingMaskIntoConstraints = false mysubview.backgroundColor = UIColor.green mysubview.addConstraint(NSLayoutConstraint(item: mysubview, attribute: NSLayoutAttribute.width, relatedBy: NSLayoutRelation.equal, toItem: nil, attribute: NSLayoutAttribute.notAnAttribute, multiplier: 0.0, constant: 20)) mysubview.addConstraint(NSLayoutConstraint(item: mysubview, attribute: NSLayoutAttribute.height, relatedBy: NSLayoutRelation.equal, toItem: nil, attribute: NSLayoutAttribute.notAnAttribute, multiplier: 0.0, constant: 20)) self.addConstraint(NSLayoutConstraint(item: mysubview, attribute: NSLayoutAttribute.centerX, relatedBy: NSLayoutRelation.equal, toItem: self, attribute: NSLayoutAttribute.centerX, multiplier: 1, constant: 0.0)) self.addConstraint(NSLayoutConstraint(item: mysubview, attribute: NSLayoutAttribute.centerY, relatedBy: NSLayoutRelation.equal, toItem: self, attribute: NSLayoutAttribute.centerY, multiplier: 1, constant: 0.0)) print(mysubview.frame.height) print(mysubview.frame.width) }} 但是这个方法实际上是多次调用的，在最后一次调用时 frame 就是真实的了。 在 ViewController 中，假设约束是在 viewDidLoad 中设置的，若在 viewDidLoad 中获取 frame，那么 frame 不是真实的。在 viewDidAppear 中获取 frame，是真实的。但是在 viewDidLayoutSubviews() 中获取，仍然不是真实的，这是因为此时 AutoLayout 还没有完成。需要在前面加一句 view.layoutIfNeeded() ，再获取就是真实的了。 Using AutoLayout to create equal width spacing 使用自动布局构建等间距效果最简单的方法（无需添加约束）就是在 Interface Builder 中创建一个 StackView，并设置它的 spacing 参数。 也可以添加约束来实现，设置约束值相同就可以了。当然也可以在代码中设置约束大小相同。 Some reasons for application crash when updating the constraints after removing the views which has some mutual constraints relationship 移除具有共同约束关系的控件后更新约束导致的应用崩溃的一些原因暂时没有发现应用崩溃。移除约束依赖的视图后，相应的约束也自动被移除了，而使用默认的 Frame 值在屏幕上绘制。","link":"/2017/04/25/iOS-%E5%B8%83%E5%B1%80%E4%B8%8E%E8%87%AA%E5%8A%A8%E5%B8%83%E5%B1%80/"},{"title":"Google Slides 图片导出为文件","text":"Google Slides 图片导出为文件最近在写 report 的时候遇到一个问题：我需要从一个 gif 动图里抽帧出来制作图表，但是原始的 gif 文件在另外的电脑里，没办法直接拿到。不过在之前准备 presentation 的时候，我们通过 Google Slides 制作了幻灯片，因此可以看到这些 gif 动图。 本来以为下载 gif / 普通图片是一件很容易的事情，但是右键点击图片发现并没有提供下载 / 另存为文件的选项。点击 File 菜单，也只有对整个 slides 整体操作的选项，并不支持将其中某张图片导出。这个时候就想到如果 Google Slides 不可以，那我可以把整个文档导出为 pptx 的格式，在 Keynote 中再导出文件（我用的是 macOS，且并没有安装 Office 套件）。 尴尬的是，在 Keynote 中虽然我可以对这些动图进行编辑，但是也没有找到导出的选项。但既然我们已经有了 pptx，理论上可以直接解析文件包内容，来看到原始的图片文件。解决办法是将 .pptx 文件重命名为 .zip，再进行解压。但是在 macOS 上，如果直接右键解压，会弹出警告说文件类型不兼容，无法解压。所以需要通过命令行来解压： 1mv &lt;file_name&gt;.pptx &lt;file_name&gt;.zip &amp;&amp; unzip &lt;file_name&gt;.zip 解压之后就能看到全部的原始文件了，问题解决🎉","link":"/2022/05/06/export-image-google-slides/"},{"title":"iOS图片裁剪、旋转、格式转换","text":"iOS图片裁剪、旋转、格式转换在使用 CoreML 对图片进行识别时，有时模型需要接收特定格式的图片，这就需要我们先对图片做好处理，再传递给模型。比如，我在一个识别人脸面部表情的程序中，就需要先裁剪出人脸区域，做成适当大小的灰度图，再交给 MLModel 进行识别。 此篇文章汇总了一些对图片进行处理的函数。 CMSampleBufferRef 转 UIImage123456789101112131415161718- (UIImage *)getImageFromSampleBuffer:(CMSampleBufferRef) buffer { CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(buffer); CVPixelBufferLockBaseAddress(imageBuffer, 0); void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer); size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer); size_t width = CVPixelBufferGetWidth(imageBuffer); size_t height = CVPixelBufferGetHeight(imageBuffer); CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB(); CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst); CGImageRef quartzImage = CGBitmapContextCreateImage(context); CVPixelBufferUnlockBaseAddress(imageBuffer, 0); CGContextRelease(context); CGColorSpaceRelease(colorSpace); UIImage *image = [UIImage imageWithCGImage:quartzImage]; CGImageRelease(quartzImage); return image;} CGImageRef 转 CVPixelBufferRef这个函数中对图像做了一些翻转变化，而且还将图片转为了 8 位的灰度图，请注意色彩空间等地方。 1234567891011121314151617181920212223242526272829303132333435363738- (CVPixelBufferRef) pixelBufferFromCGImage: (CGImageRef) image { NSDictionary *options = @{ (NSString*)kCVPixelBufferCGImageCompatibilityKey : @YES, (NSString*)kCVPixelBufferCGBitmapContextCompatibilityKey : @YES, }; CVPixelBufferRef pxbuffer = NULL; CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, CGImageGetWidth(image), CGImageGetHeight(image), kCVPixelFormatType_OneComponent8, (__bridge CFDictionaryRef) options, &amp;pxbuffer); if (status!=kCVReturnSuccess) { NSLog(@&quot;Operation failed&quot;); } NSParameterAssert(status == kCVReturnSuccess &amp;&amp; pxbuffer != NULL); CVPixelBufferLockBaseAddress(pxbuffer, 0); void *pxdata = CVPixelBufferGetBaseAddress(pxbuffer); CGColorSpaceRef rgbColorSpace = CGColorSpaceCreateDeviceGray(); //灰度 CGContextRef context = CGBitmapContextCreate(pxdata, CGImageGetWidth(image), CGImageGetHeight(image), 8, CVPixelBufferGetBytesPerRow(pxbuffer), rgbColorSpace, kCGImageAlphaNone); NSParameterAssert(context); CGContextConcatCTM(context, CGAffineTransformMakeRotation(0)); //CGAffineTransform flipVertical = CGAffineTransformMake( 1, 0, 0, -1, 0, CGImageGetHeight(image) ); //CGContextConcatCTM(context, flipVertical); CGAffineTransform flipHorizontal = CGAffineTransformMake( -1.0, 0.0, 0.0, 1.0, CGImageGetWidth(image), 0.0 ); CGContextConcatCTM(context, flipHorizontal); CGContextDrawImage(context, CGRectMake(0, 0, CGImageGetWidth(image), CGImageGetHeight(image)), image); CGColorSpaceRelease(rgbColorSpace); CGContextRelease(context); CVPixelBufferUnlockBaseAddress(pxbuffer, 0); return pxbuffer;} CVPixelBufferRef 转 UIImage12345678910111213141516171819202122- (UIImage *)imageFromPixelBuffer:(CVPixelBufferRef)pixelBufferRef { CVImageBufferRef imageBuffer = pixelBufferRef; CVPixelBufferLockBaseAddress(imageBuffer, 0); void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer); size_t width = CVPixelBufferGetWidth(imageBuffer); size_t height = CVPixelBufferGetHeight(imageBuffer); size_t bufferSize = CVPixelBufferGetDataSize(imageBuffer); size_t bytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(imageBuffer, 0); CGColorSpaceRef rgbColorSpace = CGColorSpaceCreateDeviceRGB(); CGDataProviderRef provider = CGDataProviderCreateWithData(NULL, baseAddress, bufferSize, NULL); CGImageRef cgImage = CGImageCreate(width, height, 8, 32, bytesPerRow, rgbColorSpace, kCGImageAlphaNoneSkipFirst | kCGBitmapByteOrderDefault, provider, NULL, true, kCGRenderingIntentDefault); UIImage *image = [UIImage imageWithCGImage:cgImage]; CGImageRelease(cgImage); CGDataProviderRelease(provider); CGColorSpaceRelease(rgbColorSpace); CVPixelBufferUnlockBaseAddress(imageBuffer, 0); return image;} 生成灰度图1234567891011121314- (UIImage*)grayImage:(UIImage*)sourceImage { int width = sourceImage.size.width; int height = sourceImage.size.height; CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray(); CGContextRef context = CGBitmapContextCreate (nil, width, height,8,0, colorSpace,kCGImageAlphaNone); CGColorSpaceRelease(colorSpace); if (context ==NULL) { return nil; } CGContextDrawImage(context,CGRectMake(0,0, width, height), sourceImage.CGImage); UIImage *grayImage = [UIImage imageWithCGImage:CGBitmapContextCreateImage(context)]; CGContextRelease(context); return grayImage;} 图片裁剪123456789101112- (UIImage*)getSubImage:(CGRect)rect cgImage:(CGImageRef)cgImage { CGImageRef subImageRef = CGImageCreateWithImageInRect(cgImage, rect); CGRect smallBounds = CGRectMake(0, 0, CGImageGetWidth(subImageRef), CGImageGetHeight(subImageRef)); UIGraphicsBeginImageContext(smallBounds.size); CGContextRef context = UIGraphicsGetCurrentContext(); CGContextDrawImage(context, smallBounds, subImageRef); UIImage* smallImage = [UIImage imageWithCGImage:subImageRef]; UIGraphicsEndImageContext(); CGImageRelease(subImageRef); return smallImage;} 图片旋转1234567891011121314151617181920212223242526- (UIImage*)rotateImageWithAngle:(UIImage*)vImg Angle:(CGFloat)vAngle IsExpand:(BOOL)vIsExpand { CGSize imgSize = CGSizeMake(vImg.size.width * vImg.scale, vImg.size.height * vImg.scale); CGSize outputSize = imgSize; if (vIsExpand) { CGRect rect = CGRectMake(0, 0, imgSize.width, imgSize.height); //旋转 rect = CGRectApplyAffineTransform(rect, CGAffineTransformMakeRotation(vAngle*M_PI/180.0)); outputSize = CGSizeMake(CGRectGetWidth(rect), CGRectGetHeight(rect)); } UIGraphicsBeginImageContext(outputSize); CGContextRef context = UIGraphicsGetCurrentContext(); CGContextTranslateCTM(context, outputSize.width / 2, outputSize.height / 2); CGContextRotateCTM(context, vAngle*M_PI/180.0); CGContextTranslateCTM(context, -imgSize.width / 2, -imgSize.height / 2); [vImg drawInRect:CGRectMake(0, 0, imgSize.width, imgSize.height)]; UIImage *image = UIGraphicsGetImageFromCurrentImageContext(); UIGraphicsEndImageContext(); return image;} CGImageRef 转 CVPixelBufferRef123456789101112131415161718192021222324252627282930313233343536373839404142434445464748- (CVPixelBufferRef) pixelBufferColorfulFromCGImage: (CGImageRef) image{ NSDictionary *options = @{ (NSString*)kCVPixelBufferCGImageCompatibilityKey : @YES, (NSString*)kCVPixelBufferCGBitmapContextCompatibilityKey : @YES, (NSString*)kCVPixelBufferIOSurfacePropertiesKey: [NSDictionary dictionary] }; CVPixelBufferRef pxbuffer = NULL; CGFloat frameWidth = CGImageGetWidth(image); CGFloat frameHeight = CGImageGetHeight(image); CVReturn status = CVPixelBufferCreate(kCFAllocatorDefault, frameWidth, frameHeight, kCVPixelFormatType_32BGRA, (__bridge CFDictionaryRef) options, &amp;pxbuffer); NSParameterAssert(status == kCVReturnSuccess &amp;&amp; pxbuffer != NULL); CVPixelBufferLockBaseAddress(pxbuffer, 0); void *pxdata = CVPixelBufferGetBaseAddress(pxbuffer); NSParameterAssert(pxdata != NULL); CGColorSpaceRef rgbColorSpace = CGColorSpaceCreateDeviceRGB(); CGContextRef context = CGBitmapContextCreate(pxdata, frameWidth, frameHeight, 8, CVPixelBufferGetBytesPerRow(pxbuffer), rgbColorSpace, (CGBitmapInfo)kCGImageAlphaNoneSkipFirst); NSParameterAssert(context); CGContextConcatCTM(context, CGAffineTransformIdentity); CGContextDrawImage(context, CGRectMake(0, 0, frameWidth, frameHeight), image); CGColorSpaceRelease(rgbColorSpace); CGContextRelease(context); CVPixelBufferUnlockBaseAddress(pxbuffer, 0); return pxbuffer;} 以上各个函数基本都要操作指针，所以一定要注意手动释放内存，否则会造成非常严重的内存泄漏。","link":"/2018/07/20/iOS%E5%9B%BE%E7%89%87%E8%A3%81%E5%89%AA%E6%97%8B%E8%BD%AC%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2/"},{"title":"iOS动画学习笔记","text":"iOS 动画学习笔记这次的主题还有一项是关于一些高级点的动画。 转场动画在这个例子中，我们实现一个通过轻扫手势控制的转场动画。呈现新界面时，会从底部滑动上来；返回时会滑动下去。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import UIKitclass TransitionAnimator: NSObject, UIViewControllerAnimatedTransitioning { let duration = 0.5 var isPresenting = false func transitionDuration(using transitionContext: UIViewControllerContextTransitioning?) -&gt; TimeInterval { return duration } func animateTransition(using transitionContext: UIViewControllerContextTransitioning) { let container = transitionContext.containerView let fromView = transitionContext.view(forKey: .from)! let toView = transitionContext.view(forKey: .to)! container.addSubview(toView) var animation = {} if isPresenting { toView.frame = CGRect(x: 0, y: toView.bounds.height, width: toView.bounds.width, height: toView.bounds.height) animation = { toView.frame = CGRect(x: 0, y: 0, width: toView.bounds.width, height: toView.bounds.height) } } else { toView.frame = CGRect(x: 0, y: -toView.bounds.height, width: toView.bounds.width, height: toView.bounds.height) animation = { toView.frame = CGRect(x: 0, y: 0, width: toView.bounds.width, height: toView.bounds.height) } } UIView.animate(withDuration: duration, animations: { animation() }) { _ in //⚠️注意，这里一定要通知动画完成，否则动画不结束，第二个VC将失去响应。 transitionContext.completeTransition(true) } }}class TransViewController: UIViewController, UIViewControllerTransitioningDelegate { let animator = TransitionAnimator() override func viewDidLoad() { super.viewDidLoad() view.backgroundColor = UIColor.red let swipe = UISwipeGestureRecognizer(target: self, action: #selector(handleSwipe(sender:))) swipe.direction = .up view.addGestureRecognizer(swipe) } func animationController(forDismissed dismissed: UIViewController) -&gt; UIViewControllerAnimatedTransitioning? { animator.isPresenting = false return animator } func animationController(forPresented presented: UIViewController, presenting: UIViewController, source: UIViewController) -&gt; UIViewControllerAnimatedTransitioning? { animator.isPresenting = true return animator } @objc func handleSwipe(sender: UISwipeGestureRecognizer) { let vc = SecondVC() vc.transitioningDelegate = self present(vc, animated: true, completion: nil) }}class SecondVC: UIViewController { override func viewDidLoad() { view.backgroundColor = UIColor.yellow let swipe = UISwipeGestureRecognizer(target: self, action: #selector(handleSwipe(sender:))) swipe.direction = .down view.addGestureRecognizer(swipe) } @objc func handleSwipe(sender: UISwipeGestureRecognizer) { dismiss(animated: true, completion: nil) }} 这个例子比较简单，由于是 swipe 手势，因此是不支持交互式转场的。不过苹果也为我们提供了交互式转场动画的 API，可以参见唐巧大大的博客，或苹果的官方教程。 UIKit 力学苹果在 iOS7 中将一个轻量级 2D 物理引擎引入到了 UIKit 中，因此我们在 UIKit 中也可以很方便地去实现一些物理效果，而不必使用游戏引擎。 UIDynamic 提供了几种基本的规则：重力、碰撞、锚定、链接等。可以很方便的实现一些用其他方法难以实现的特效。它同样可以和 CollectionView 配合起来，实现一些炫酷的效果。 不过我在使用 UIDynamic 的时候遇到了一点问题：我试图去实现一个弹球的小游戏——用户通过手势拖动底部的横杆，小球碰到横杆会反弹，碰到屏幕边缘同样反弹（就像打砖块那样）。小球一开始可以受到一个方向随机的瞬时推力，产生初始速度。之后，可以通过 override collisionBoundingPath 属性来指定小球的碰撞边界是圆形，而不是默认的方形。但是：如何让小球无损地反弹？ 12345collision.translatesReferenceBoundsIntoBoundary = truelet itemBehavior = UIDynamicItemBehavior(items: [ball])itemBehavior.elasticity = 1.0animator.addBehavior(itemBehavior) 我们先让小球遇到 view 的四壁全部反弹，之后，指定碰撞为完全弹性碰撞。这个时候，小球不应该损失任何能量，但是我们可以看到小球还是在碰撞几次之后，速度逐渐减慢了下来。 或许是设置 boundary 的问题？毕竟我们没有给 boundary 设置 elasticity 属性。那我们转变一个思路，使用另一个物体当作边界，并把它锚定： 1234let floorBehavior = UIDynamicItemBehavior(items: [floor])floorBehavior.elasticity = 1.0floorBehavior.isAnchored = trueanimator.addBehavior(floorBehavior) 然而效果还是一样的。 这个问题导致我的想法最终失败了。查了一圈，也没有发现解决方案或类似问题。我不知道是还有什么隐藏的 API 我没有发现，或是我的思路是错误的，还是说 UIDynamic 并不支持这样的操作。看来做游戏（哪怕是如此简单的小游戏），还是乖乖用游戏引擎吧！ 小任务：水波纹进度条先来看一下效果： 过于细节的地方无需赘述，主要讲述一下思路： 首先，我们用 sin 函数来模拟水波纹的形状。我们通过贝塞尔曲线画出几个周期的 sin 函数，这里 dx 取的 0.5，因为步长越小，结果会越精确，但是别忘了屏幕像素是有限的，太过精确只会浪费性能而没有意义： 123456789101112131415161718192021222324252627func generateWaveLayer() -&gt; CAShapeLayer { let width = self.bounds.width let height = self.bounds.height var currentX: CGFloat = 0.0 let dx: CGFloat = 0.5 let totalLength = width * 2.0 let wavePath = UIBezierPath() wavePath.move(to: CGPoint(x: 0, y: 0)) while currentX &lt;= totalLength { let y = 5.0 * sin(currentX * (8.0 * CGFloat.pi / totalLength)) wavePath.addLine(to: CGPoint(x: currentX, y: y)) currentX += dx } wavePath.addLine(to: CGPoint(x: totalLength, y: height)) wavePath.addLine(to: CGPoint(x: 0, y: height)) wavePath.close() let waveLayer = CAShapeLayer() waveLayer.path = wavePath.cgPath waveLayer.fillColor = UIColor(red: 30.0/255.0, green: 144.0/255.0, blue: 255.0/255.0, alpha: 1.0).cgColor return waveLayer } 我们可以看到，这里的 layer 是比自己的 view 要宽的。这是因为对它做一个无限循环的平移动画就可以模拟水面的波动效果了。由于 sin 是周期函数，所以动画结束瞬间回到原点重复动画在用户看来就是连续的： 123456789func addWaveAnimation(to animateLayer: CAShapeLayer) { let animation = CABasicAnimation(keyPath: &quot;position.x&quot;) animation.duration = 3.0 animation.fromValue = 0.0 animation.toValue = self.bounds.width animation.repeatCount = MAXFLOAT animateLayer.add(animation, forKey: nil)} 修改水平面，其实就是在调节 frame.y。但是 layer 是在播放动画的，为了修改 frame 和动画本身产生冲突，我们给这个 layer 单独一个 view ： 12345678self.addSubview(visibleView)visibleView.frame = self.bounds waveLayer = generateWaveLayer()waveLayer.frame = CGRect(x: -self.bounds.width, y: 0, width: self.bounds.width * 2.0, height: self.bounds.height) visibleView.layer.addSublayer(waveLayer)addWaveAnimation(to: waveLayer) 然后调节 visibleView 的 frame： 123func changeWaterLevel(to relativeLevel: CGFloat) { visibleView.frame = CGRect(x: 0, y: (1.0 - relativeLevel) * self.bounds.height, width: self.bounds.width, height: self.bounds.height)}","link":"/2018/05/28/iOS%E5%8A%A8%E7%94%BB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"iOS多线程学习笔记","text":"iOS 多线程学习笔记线程 vs 进程线程又被称为轻量进程，是进程中执行运算的最小单位。进程是资源费配的基本单位。一个程序至少拥有一个进程，一个进程至少拥有一个线程。线程拥有自己的堆栈和局部变量，但没有单独的地址空间，而进程的内存是独立的。一个线程崩溃，整个进程都会崩溃。但在操作系统的保护模式下，一个进程崩溃不影响其他进程，因此多进程的程序比多线程的程序及健壮。但是进程上下文切换比线程上下文切换更消耗资源。 为什么会有多线程/多进程呢？因为 CPU 的速度和内存或是其他挂在总线上的设备的速度严重不匹配，CPU 要快得多。人们想要提高资源利用率，于是可以让 CPU 轮流处理多个任务（分时间片）。由于切换速度很快，在用户看来就是并行执行了。只有在 CPU 具有多个核心时，才可能实现真正的多线程。事实上，由于线程数量要远远多于 CPU 核心数（在写这篇文章时，我的电脑运行着 356 个进程，1289 个线程，而我的处理器只有两个核心），实际上还是要轮流处理😉 在 iOS 中，一个正在运行的应用程序就是一个进程。每个程序中可以开启多个线程，以防止阻塞 UI 线程造成卡顿。 线程的状态 &amp; 生命周期当一个线程被 new 出来之后，对它发送 start 信号就会进入就绪（Runnable）状态。线程开启（start）后会被放入可调度线程池中。 当 CPU 调度当前线程时，它会进入运行（Running）状态；当 CPU 转而去调度其他线程，它就又返回就绪状态等待调度。 当调用了 sleep 方法是在等待同步锁时，就进入阻塞（Blocked）状态。阻塞状态时，线程对象会被移出线程池，不可调度。而一旦 sleep 时间到，或者得到同步锁，就又返回就绪状态。 当线程执行完毕，或是出现错误而强制退出时，就进入死亡（Dead）状态。线程对象会被销毁。 线程安全当多个线程对数据进行写操作时，有可能会出现数据不一致的情况。一般来说，我们通过添加同步锁来对数据进行保护，保证每个时刻只有一个线程在操作数据。如果在多线程下，运行结果仍和单线程下一致（或者说符合预期），那么我们就说这是线程安全的。 如果加锁不当，或者是出现了循环依赖、资源竞争等情况，就会出现线程永久阻塞的死锁状态。如果没有外力作用，这些线程永远无法执行下去，在实际使用中一定要避免死锁产生。我们也可以监控死锁，不如设置时限，超时后采取措施解脱死锁状态。 iOS 中，有最基本的互斥锁，保证一个线程在访问对象时，其他线程不能访问。还有递归锁，可以解决对一个线程加两次锁时的死锁问题。此外还有根据条件来加锁的条件锁。 123456789//对一个线程加两次互斥锁导致的死锁问题let lock = NSLock()DispatchQueue.global().async { lock.lock() lock.lock() print(&quot;deadlock&quot;) lock.unlock() lock.unlock()} 这里简单解释下为什么 lock 两次就会死锁。假设这里的互斥锁是用信号量实现的，每次 lock 都会把信号量减一。如果一开始信号量是 1，那么 lock 一次信号量就降低到 0，其他线程就无法执行了。如果再 lock 一次，本线程就又把信号量减 1，同时发现信号量不再大于 0，于是自己也不能执行了。 多线程引用计数 由于对象可能在不同的线程被访问，所以引用计数必须是线程安全的。为了保证引用计数的读写操作是原子性的，retain / release / retainCount 都要被加锁。 atomic atomic 是 Objective-C 中的一个修饰属性的关键字，意思是原子性的。所谓原子，就是指不可继续划分的最小操作单位。被 atomic 修饰的属性的 getter 和 setter 会被加锁，从而保证了线程安全。 atomic 一定是线程安全的吗？可以这么说，但也不能这么说😜首先，atomic 是修饰属性的关键字。如果你的属性是一个指针，比如一个 NSMutableArray *array ，它可以保证这个指针的线程安全，但是无法保证指针指向的内存块（数组本身）的线程安全。因为你给指针指向的地址赋值，是和指针自身的 getter 和 setter 没关系的。 还有，就是 a = a + 1 这种情况。即使 a 是 int 类型的变量，并且也通过 atomic 关键字给它的 getter 和 setter 加锁。当你在进行 set 时，get 操作也会被阻塞（反之亦然），但是，仍会出现线程不安全的情况。比如，先安全地 get 到了 a，例如 a 的值为 1。之后进行加法运算，即运算 a + 1 = 2。如果在此时其他线程对 a 进行写操作，时不会被阻塞的。而运算完成之后，本线程又回对 a 进行一次写操作，就会出现数据不一致的情况。不过，单纯的对小于 64 位的基本类型数据做读写操作时，即使不加锁也是原子性的。因为 64 位机器的地址总线也是 64 位，读写可以在一次操作中完成。如果大于 64 位，就要分步来完成操作，有可能出现 A 线程写到一半，轮转给 B 线程操作的情况。 既然 atomic 可以一定程度上保证线程安全，那要不要把所有的属性都声明为 atomic 的呢？当然不要，要知道加锁和解锁操作是需要消耗更多资源的，在手机这样性能较弱的嵌入式设备中，除非必要，不然不要声明为 atomic 的。而在 Mac 上面就问题不大了。 如何封装一个线程安全的字典 这是大疆的一道面试题。首先我们要知道，字典不是线程安全的： 123456789101112131415var dic = [String: Int]()DispatchQueue.global().async { for _ in 1...10 { dic[&quot;\\(dic.count)&quot;] = dic.count NSLog(dic.description) }}DispatchQueue.global().async { for _ in 1...10 { dic[&quot;\\(dic.count)&quot;] = dic.count NSLog(dic.description) }} 控制台打印的前几行： 12345672018-04-13 15:03:24.053788+0800 test[24651:2363511] [&quot;0&quot;: 0]2018-04-13 15:03:24.053790+0800 test[24651:2363512] [&quot;0&quot;: 0] 2018-04-13 15:03:24.054146+0800 test[24651:2363512] [&quot;0&quot;: 0, &quot;2&quot;: 2] //缺少12018-04-13 15:03:24.054184+0800 test[24651:2363512] [&quot;2&quot;: 2, &quot;0&quot;: 0, &quot;3&quot;: 3]2018-04-13 15:03:24.054245+0800 test[24651:2363512] [&quot;4&quot;: 4, &quot;2&quot;: 2, &quot;0&quot;: 0, &quot;3&quot;: 3]2018-04-13 15:03:24.054254+0800 test[24651:2363511] [&quot;4&quot;: 4, &quot;2&quot;: 2, &quot;0&quot;: 0, &quot;3&quot;: 3] 2018-04-13 15:03:24.054281+0800 test[24651:2363512] [&quot;2&quot;: 2, &quot;6&quot;: 6, &quot;4&quot;: 4, &quot;3&quot;: 3, &quot;0&quot;: 0] //缺少5 可以看到数据是紊乱的。我们可以通过给 getter 和 setter 加锁或者利用串行队列的方式来封装一个线程安全的字典，下面是一个简单的示例： 12345678910111213141516171819202122232425262728293031323334353637struct SafeDictionary&lt;Key, Element&gt; where Key: Hashable { var dictionary = Dictionary&lt;Key, Element&gt;() var lock = NSLock() subscript(keyword: Key) -&gt; Element? { get { lock.lock() let value = dictionary[keyword] lock.unlock() return value } set { guard let newValue = newValue else { return } lock.lock() dictionary[keyword] = newValue lock.unlock() } } }extension SafeDictionary { var count: Int { lock.lock() let value = self.dictionary.count lock.unlock() return value } var description: String { lock.lock() let value = self.dictionary.description lock.unlock() return value }} 控制台打印： 1234562018-04-13 15:37:51.041003+0800 test[24761:2390589] [&quot;0&quot;: 0]2018-04-13 15:37:51.041003+0800 test[24761:2390590] [&quot;0&quot;: 0]2018-04-13 15:37:51.041580+0800 test[24761:2390590] [&quot;0&quot;: 0, &quot;1&quot;: 1]2018-04-13 15:37:51.041620+0800 test[24761:2390590] [&quot;0&quot;: 0, &quot;1&quot;: 1, &quot;2&quot;: 2]2018-04-13 15:37:51.041748+0800 test[24761:2390589] [&quot;4&quot;: 4, &quot;2&quot;: 2, &quot;1&quot;: 1, &quot;0&quot;: 0, &quot;3&quot;: 3]2018-04-13 15:37:51.041791+0800 test[24761:2390589] [&quot;4&quot;: 4, &quot;2&quot;: 2, &quot;1&quot;: 1, &quot;5&quot;: 5, &quot;0&quot;: 0, &quot;3&quot;: 3] //不再缺少某一项 线程间通信再使用多线程时，我们有时希望线程之间能互相传递数据，或是在一个线程中执行完毕任务后，跳到另外一个线程继续执行任务，比如在子线程完成耗时操作后，回到主线程更新 UI。 除了使用 GCD 切换到 main 队列以外，我们也可以通过函数： 1func perform(_ aSelector: Selector, on thr: Thread, with arg: Any?, waitUntilDone wait: Bool, modes array: [String]?) 来让指定的线程执行某个方法。 或者使用 NSMachPort （Mach 音 mak）或是 Pipe 来传递消息。如果有更高级的需求，可以使用 socket 来通信。 MainThreadChecker检查主线程是否卡顿有多种方法，比如监测 RunLoop 的状态，或是定时向主线程发送 ping 消息，检查主线程是否能及时返回 pong 消息等。我采用了监测主线程 RunLoop 状态变化的方法，思路如下： 我们开启一个子线程，实时读取主线程的 RunLoop 状态。如果当前任务很轻，没有卡顿，那 RunLoop 的状态应该是频繁跳动的。如果没有触发事件，也可能长时间处于休眠状态。我们检测 RunLoop 是否长时间处于 beforeSources 或是 afterWaiting 状态，如果很长时间都处于这两个状态而得不到更新，就意味着主线程正在处理很繁重的任务，即卡顿了。 下面是一个初步的 demo，有些地方还需要进一步优化： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566enum BYRunLoopState { case beforeSources case afterWaiting case others}class BYMainThreadChecker { var runLoopState = BYRunLoopState.others var isChecking = false var runLoopObserver: CFRunLoopObserver? func start() { addObserver() isChecking = true DispatchQueue.global().async { var lastTime = NSDate().timeIntervalSince1970 * 1000 while self.isChecking { let currentTime = NSDate().timeIntervalSince1970 * 1000 if self.runLoopState == .afterWaiting || self.runLoopState == .beforeSources { lastTime = currentTime } else { let dt = currentTime - lastTime if dt &gt; 50 { NSLog(&quot;卡了一下&quot;) //可以在此时拿到调用栈信息，方便调试。当前发生卡顿会打印消息多次，后期可以做一个优化，单次卡顿只收集一次信息。 } } } } } func stop() { isChecking = false removeObserver() } private func addObserver() { let runLoop = CFRunLoopGetCurrent() let observer = CFRunLoopObserverCreateWithHandler(kCFAllocatorDefault, CFRunLoopActivity.allActivities.rawValue, true, 0) { (observer, activity) in if activity == CFRunLoopActivity.beforeSources { self.runLoopState = .beforeSources } else if activity == CFRunLoopActivity.afterWaiting { self.runLoopState = .afterWaiting } else { self.runLoopState = .others } } CFRunLoopAddObserver(runLoop, observer, .commonModes) runLoopObserver = observer } private func removeObserver() { let runLoop = CFRunLoopGetCurrent() CFRunLoopRemoveObserver(runLoop, runLoopObserver, .commonModes) } }","link":"/2018/04/14/iOS%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"iOS手势学习笔记","text":"iOS 手势学习笔记这次的主题是手势稍微高级一点的用法。 GestureRecognizer 的代理方法UIGestureRecognizerDelegate 中定义了以下方法： 1optional public func gestureRecognizerShouldBegin(_ gestureRecognizer: UIGestureRecognizer) -&gt; Bool 当手势识别器的状态试图转换到 UIGestureRecognizerStatePossible 状态时调用，如果 return 了 false，则手势的状态会被转换到失败。 手势识别器的状态机如下图： 1optional public func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldRecognizeSimultaneouslyWith otherGestureRecognizer: UIGestureRecognizer) -&gt; Bool 当两个手势可能会互相阻塞时会调用这个方法。如果返回 true，则两个手势可以同时响应。这个方法默认返回 false，即一般情况下响应了一个手势就不会响应另一个手势了。 需要注意，返回 true 会保证两个手势能被同时响应，而返回 false 不能保证两个手势不能被同时响应。因为另一个手势的代理方法可能会返回 true，即“一真即真”。 1optional public func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldRequireFailureOf otherGestureRecognizer: UIGestureRecognizer) -&gt; Bool 每次试图去识别的时候都会调用，因此失败依赖可以惰性确定，并且可以设置给跨视图层级的识别器。 与上面的方法类似，因为牵扯到两个识别器，因此还是一真即真。 1optional public func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldBeRequiredToFailBy otherGestureRecognizer: UIGestureRecognizer) -&gt; Bool 与上面的方法对称。如果返回 true，则在自己 fail 之前，otherGestureRecognizer 不能识别手势，要等待 gestureRecognizer fail 之后才可以。 1optional public func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldReceive touch: UITouch) -&gt; Bool 在 touchesBegan 之前就会调用，如果返回 false，则会阻止识别器接收 UITouch。 1optional public func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldReceive press: UIPress) -&gt; Bool 与上面类似，会阻止识别器接受 UIPress。 那么 UIPress 是什么？直接 Google UIPress 并没有获得什么有用的资料，说明 UIPress 其实并不常用。苹果自己的文档写得也是让人看不懂，后来是看到了微软 Xamarin 的文档才稍微明白过来……原来它代表了远程控制器或游戏手柄上物理按钮按下的事件。UITouch - 屏幕触摸；UIPress - 按钮按下，名字起得还是可以的。 手势冲突怎么办手势冲突确实是比较棘手的问题，最根本的方法还是尽量避免多个手势叠加在一起。 如果真的有很多相似的手势要同时使用，我们可以使用上面的代理方法，优先识别一些手势，让另外的手势 fail 掉。 还有，如果界面上有非常非常多的 view 需要响应手势，那么与其在每个 view 上都添加手势识别器，不如把要用的几种识别器添加到最底层的 view 上。之后我们自己根据 view 的层级来分发手势，不过要多写一些判断响应者的代码。 自定义手势识别器首先需要注意的是，当你编写一个 UIGestureRecognizer 的子类时，是需要 import 头文件 UIGestureRecognizerSubclass.h 的。这个头文件中定义了很可能需要覆写的属性和方法。如果是 Swift： 12import UIKitimport UIKit.UIGestureRecognizerSubclass 接下来我们需要重写 touchesBegan 等方法，并设置 state 的属性，来控制状态机状态的跳转。下面是实现一个识别画圈的手势识别器的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273class CircleGestureRecognizer: UIGestureRecognizer { private var touchSamples = [CGPoint]() private var isCircle = false override func touchesBegan(_ touches: Set&lt;UITouch&gt;, with event: UIEvent) { super.touchesBegan(touches, with: event) guard touches.count == 1 else { state = .failed return } state = .began } override func touchesMoved(_ touches: Set&lt;UITouch&gt;, with event: UIEvent) { super.touchesMoved(touches, with: event) if state == .failed { return } let window = view?.window if let loc = touches.first?.location(in: window) { touchSamples.append(loc) state = .changed } } override func touchesEnded(_ touches: Set&lt;UITouch&gt;, with event: UIEvent) { super.touchesEnded(touches, with: event) isCircle = checkCircle() print(isCircle) state = isCircle ? .ended : .failed } override func reset() { super.reset() isCircle = false touchSamples = [] } private func checkCircle() -&gt; Bool { guard touchSamples.count &gt; 4 else { return false } let p1 = touchSamples.first! let p2 = touchSamples[touchSamples.count / 4] let p3 = touchSamples[touchSamples.count * 2 / 4] let p4 = touchSamples[touchSamples.count * 3 / 4] let centerX = (p1.x + p2.x + p3.x + p4.x) / 4.0 let centerY = (p1.y + p2.y + p3.y + p4.y) / 4.0 let center = CGPoint(x: centerX, y: centerY) let radius = (getDistance(from: p1, to: center) + getDistance(from: p2, to: center) + getDistance(from: p3, to: center) + getDistance(from: p4, to: center)) / 4.0 var count = 0 for point in touchSamples { if abs(getDistance(from: point, to: center) - radius) &lt; 30 { count += 1 } } return Double(count) / Double(touchSamples.count) &gt; 0.8 } private func getDistance(from point: CGPoint, to otherPoint: CGPoint) -&gt; CGFloat { return sqrt((point.x - otherPoint.x) * (point.x - otherPoint.x) + (point.y - otherPoint.y) * (point.y - otherPoint.y)) } } 这里判定是否是一个圆圈的算法比较简单。只是取了 4 个点，求出它们的平均坐标作为圆心，再求出它们到圆心的平均距离作为半径。接着，检查是否有足够多（大于 80% ）的点到圆心的距离误差小于某个值。当然这样的判断非常粗糙，如果想要达到比较精确的识别效果，应该使用更复杂的算法来做拟合。 小任务1：两个ScrollView 联动最简单的想法肯定是在一个 scrollView 的 didScroll 方法里，把另一个 scrollView 的 offset 设置为和自己一样的值。 12345func scrollViewDidScroll(_ scrollView: UIScrollView) { if scrollView == leftScrollView { rightScrollView.contentOffset = leftScrollView.contentOffset }} 这当然是一种可行的方法。但是当两个 scrollView 里面的内容不一样多时，就会出现一边还没滑完，另一边已经全部滑出去呈现一片空白的情况。如果需求不允许这样，当然就不行。仅仅是在 didScroll 里面再做限制的话，就会丧失回弹效果。虽然我感觉一般没有这么变态的需求…… 但接下来是开脑洞的时间：我们有没有别的方法呢？这里我想说的是，能不能把一个手势同时传递给两个 view 呢？ 我的第一反应是，既然触摸事件会从 superView 传递到 subView，那么我只要把第二个 scrollView 作为第一个 scrollView 的子视图，再允许两个手势同时响应就可以了。经过确认，两个 scrollView 确实可以同时响应手势，但由于把 scrollView 添加到另一个 scrollView 上了，它就也会跟着滚动。即它一边自己滚动，一边跟着底部的 scrollView 滚动。那如果我们想把它固定住，就要在 didScroll 方法里修改它的 frame…而且，scrollView 默认是 clipsToBounds 的，如果要让两个 scrollView 平行放置，还要自己去遮挡露出来的 content。这个想法似乎不是很好。 第二个想法是，我们还是让两个 scrollView 处于平行层级，利用 OC 强大的动态特性把手势传递过去。 首先，我们要修改右边的 scrollView 的 hitTest 方法，让手指在左边的 scrollView 上滑动时，也能响应手势： 123override func hitTest(_ point: CGPoint, with event: UIEvent?) -&gt; UIView? { return self} 好了，现在无论在哪里滑动，右边的 scrollView 都能响应了。但是有视图响应手势，手势就不会继续派发给平行的视图了。我们就需要自己传递过去。 我们知道 ScrollView 里面是内置了一个 panGestureRecognizer 的。ScrollView 这些滑动，包括滑动的各种物理效果，肯定也是在这个内置的 panGestureRecognizer 的 target 方法实现的。那么我们把这个 recognizer dump 出来看一下： 12345- &lt;UIScrollViewPanGestureRecognizer: 0x7ff5df417700; state = Possible; delaysTouchesEnded = NO; view = &lt;GestureAnimation.MyView 0x7ff5e081a400&gt;; target= &lt;(action=handlePan:, target=&lt;GestureAnimation.MyView 0x7ff5e081a400&gt;)&gt;&gt; #0 - super: UIPanGestureRecognizer - super: UIGestureRecognizer - super: NSObject 可以看到，内置的这个 panGestureRecognizer 的 target 是一个签名为 handlePan: 的方法。但这个方法是私有的，因此我们没有办法更改它的逻辑。但是不怕，我们可以通过 method swizzling 把这个方法替换成我们自己的方法。首先由于我们必须要保证方法只被替换一次，因此在 ViewController 里面写，而不要在 ScrollView 的子类 的 init 方法里写，因为替换的是整个类的实例方法，我们的程序中有两个 scrollView，会 init 两次： 123let m1 = class_getInstanceMethod(MyView.self, Selector(&quot;handlePan:&quot;))let m2 = class_getInstanceMethod(MyView.self, #selector(MyView.myHandlePan(gesture:)))method_exchangeImplementations(m1!, m2!) 这里的 MyView 是我写的 UITextView 的子类。现在，我们已经把 MyView 的父类 UITextView 的父类 UIScrollView 的 handlePan 方法和我们自己的 myHandlePan 方法替换了。这时如果去滑动 scrollView，会发现它开始调用我们自己的方法了！ UIScrollView 的回弹效果、减速效果等等是非常完美的，我们肯定不希望自己去实现这些效果，因此我们要做的是在我们的 myHandlePan 方法里再去调用原来的 handlePan 方法。这不过，这次我们又要调用右边的 scrollView 的 handlePan，又要调用左边的 handlePan，这样两个 scrollView 就能联动了。 1234@objc func myHandlePan(gesture: UIPanGestureRecognizer) { self.myHandlePan(gesture: gesture) other?.myHandlePan(gesture: gesture) //other 是左边的 scrollView 的引用} 诶，这里为什么调用的是 myHandlePan 呢？不应该是通过 performSelector 方法调用 handlePan 吗？这样不会递归吗？别忘了，我们可是交换了 myHandlePan 和 handlePan 的，调用 myHandlePan 其实是在调用原来的 handlePan。 但是这样写是不行的，我们会发现程序 crash 掉了，且完全没有报错信息！这是为什么呢？原来，仅仅标记了 @objc 的函数和属性并不能保证在运行时被调用，因为 swift 会做静态优化。现在，我们通过 dynamic 关键字来让它变成完全动态的： 1234@objc dynamic func myHandlePan(gesture: UIPanGestureRecognizer) { self.myHandlePan(gesture: gesture) other?.myHandlePan(gesture: gesture)} 运行程序，我们会发现右边的 scrollView 正常的在滑动，而左边的一动不动！我们费了半天劲却又回到了原点。这是为什么呢？ 是因为 other 是 nil 吗？毕竟向 nil 发送消息不会有反应。但我们 print 一下发现 other 并不是 nil。这时，我猜测是苹果在实现 handlePan 的时候，做了判断，检查传入的参数是不是与自己内置的 panGestureRecoginzer 一致： 1234567//我瞎猜的苹果的实现- (void)handlePan:(UIPanGestureRecognizer *)sender { if (sender != _panGestureRecognizer) { return; } //...} 嗯…苹果爸爸的代码还真是严谨呢。但是没关系，我们把左边的 panGestureRecognizer 属性也换掉就好了，即使它是 get-only 的又何妨，我们有 runtime： 1leftScrollView.setValue(rightScrollView.panGestureRecognizer, forKey: &quot;panGestureRecognizer&quot;) 好了，现在运行程序——大功告成！两个 scrollView 完美地联动了！这也说明我上面瞎猜的应该是正确的。用这种方法也算是费尽周折，足足花了我大半天的事件各种调试。不过这波操作还比较骚，我喜欢。 由此可见，OC 的动态特性确实是一件大杀器。不过，调用私有方法确实是不推荐的，除非万不得已，一般不要这样。当未来，UIKit 全部用 Swift 重写后，我们也可能会丧失这把利器吧！看 Swift 自己的 Runtime 怎么实现了。","link":"/2018/05/23/iOS%E6%89%8B%E5%8A%BF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"title":"iOS 自定义TabBar的正确姿势","text":"iOS 自定义TabBar的正确姿势看默认风格的 TabBar 久了未免会觉得有些审美疲劳，于是就想自定义 TabBar，加一些小动画。自定义 TabBar 并不困难，无非就是写一个 UITabBarController 的子类，然后在 storyboard 中设置一下嘛。事实上，我之前也写过这样的一个小 demo，放在了 gitlab 上：TabBarAnimation 。这次想在自己的小项目上应用一下，美滋滋地直接把代码拷贝过来，却出现了不少问题。经过一番周折，终于发现了自定义 TabBar 的正确姿势。 在 Demo 中的实现思路12345678910111213141516class CSTabBarController: UITabBarController { var imageViews = [UIImageView]() let mainView = UIView() override func viewDidLoad() { super.viewDidLoad() mainView.frame = self.tabBar.bounds self.view.addSubview(mainView) //balabal...... self.tabBar.removeFromSuperview() } func onClickTabBarButton(sender:UIButton) { //balabala...... }} 思路很简单。既然是自定义 TabBar，而且没办法在原来的 BarItem 上修改，那我就把原来的 TabBar 移除，然后在 view 上新建一个 view 冒充 TabBar 嘛！只要把原来 Item 的位置上放上按钮，就足以以假乱真了。而且在 demo 中，这个方法的确奏效。 出现的问题 &amp; 前期解决方案在 demo 中，我只做了 TabBar 的小动画，比较简单，所以没有暴露出来这些隐藏的问题。而放在一个实际的项目中，这些问题就变得不可容忍了，主要的问题有： TabBar 丢失了半透明、模糊效果。 顶部缺少了一条浅灰色的分界线。 即使设置了 hideBottomBarOnPush，TabBar 也不会隐藏。 作为一个优秀的开发者（大雾），这些小小的问题怎么能难倒我呢？既然丢失了模糊效果，那我就自己加一个 blurEffect layer 上去。缺少分界线，就自己画一条上去。不能隐藏这个问题比较麻烦，那就在每一个 viewWillAppear 中自己手动设置 isHide 嘛。虽然烦琐了点，但又不是不能用。 手动做完这些之后，本以为就没什么问题了。但显然我还是太天真了。前两个问题还好，第三个手动隐藏缺暴露了更多的问题，而且难以容忍： 隐藏和显示是突然出现的，而系统默认的是有一个向左滑动的动画效果，显得太过突兀。 进入下一级页面时（添加上去的自定义 view 刚刚隐藏），默认版本的 TabBar 突然出现了一下，即使已经把默认的 TabBar 从 superView 中移除了。虽然很细节，但如果用户仔细观察还是可以发现。 默认状态下，右滑回到上一级的过程中，TabBar 是跟随上一级的视图一起滑动的，而在这里就直接出现了。 如果在上面的状态下，用户一边滑动一边突然点按 TabBar 上的按钮，切换到另外的视图，那么 TabBar 就消失了。除非关闭程序再进入，否则就没有办法切换试图。虽然可能很少有用户这么做，但这对体验的影响非常大。 正确的姿势其实解决方案非常简单，就是不要直接添加到 view 中，而是添加到 TabBar 中。这样无论是模糊效果、分界线还是自动隐藏，都与默认的逻辑一样了。这里特别需要注意的是，如果添加完了没有任何效果，检查一下是不是在设置 frame 的时候，不小心设置成了 TabBar 的 frame。因为是添加到 TabBar 上面，所以应该设置为 TabBar 的 bounds（而如果项之前那样添加到 view 上，就需要用 frame）。单这样还不够，会出现和默认的 TabBar 重叠在一起的情况。所以需要在 viewWillAppear 中移除所有的子控件，再重新添加。 完整的代码（点击后有弹性放大效果、无提示文字）： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class CSTabBarController: UITabBarController { var imageViews = [UIImageView]() let mainView = UIView() override func viewDidLoad() { super.viewDidLoad() mainView.frame = self.tabBar.bounds mainView.backgroundColor = UIColor.clear let itemWidth = mainView.frame.width / CGFloat(viewControllers!.count) for i in 0..&lt;viewControllers!.count { let button = UIButton(frame: CGRect(x: itemWidth * CGFloat(i), y: 0, width: itemWidth, height: mainView.frame.height)) button.backgroundColor = UIColor.clear button.tag = i button.addTarget(self, action: #selector(CSTabBarController.onClickTabBarButton(sender:)), for: .touchUpInside) mainView.addSubview(button) var imageView = UIImageView() switch i { case 0: imageView = UIImageView(image: UIImage(named: &quot;home&quot;)?.withRenderingMode(.alwaysTemplate)) case 1: imageView = UIImageView(image: UIImage(named: &quot;schedule&quot;)?.withRenderingMode(.alwaysTemplate)) case 2: imageView = UIImageView(image: UIImage(named: &quot;setting&quot;)?.withRenderingMode(.alwaysTemplate)) default: break } if i &gt; 0 { imageView.tintColor = UIColor.gray } else { imageView.tintColor = UIColor.flatGreen } imageView.frame = CGRect(x: button.frame.midX - 11, y: button.frame.midY - 11, width: 22, height: 22) mainView.addSubview(imageView) imageViews.append(imageView) } } override func viewWillAppear(_ animated: Bool) { super.viewWillAppear(animated) let _ = tabBar.subviews.map({$0.removeFromSuperview()}) tabBar.addSubview(mainView) } func onClickTabBarButton(sender:UIButton) { if self.selectedIndex == sender.tag { return } for imageView in imageViews { imageView.tintColor = UIColor.gray } self.selectedIndex = sender.tag UIView.animate(withDuration: 1, animations: { self.imageViews[sender.tag].tintColor = UIColor.flatGreen }) let bigger = CABasicAnimation(keyPath: &quot;transform.scale&quot;) bigger.fromValue = 1 bigger.toValue = 1.3 bigger.duration = 0.1 let zoom = CASpringAnimation(keyPath: &quot;transform.scale&quot;) zoom.fromValue = 1.3 zoom.toValue = 1 zoom.duration = 0.5 zoom.damping = 5 imageViews[sender.tag].layer.add(bigger, forKey: nil) zoom.beginTime = CACurrentMediaTime() + 0.1 imageViews[sender.tag].layer.add(zoom, forKey: nil) }}","link":"/2017/09/02/iOS-%E8%87%AA%E5%AE%9A%E4%B9%89TabBar%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF/"},{"title":"iOS蓝牙开发-超声波测距仪","text":"iOS 蓝牙开发——超声波测距仪写在前面：本来的计划是做一个 pm2.5 测量仪的，毕竟北京的空气有时很糟糕。去网上找粉尘传感器，发现有 200 多的，有 20 多的。看了眼支付宝余额……默默选择了 20 块钱的。结果到手之后发现精度实在太低了，而且线头又短又软，适合焊接而不是插到面包板上🤦‍♂️只好先改成了超声波测距仪。 Pm2.5 测量……就以后再说吧…… 硬件电路这里用了 Arduino 单片机 + 蓝牙 4.0 模块 + 超声波测距模块构成硬件电路，结构比较简单。 蓝牙和超声波模块 Vcc 接 Arduino 5V 输出。特别要注意超声波模块的工作电压，如果模块本身的工作电压是 5V 却只给 3.3V 的话，会工作异常。二者 GND 接 Arduino GND。 蓝牙模块的 Tx 和 Rx 分别接 Arduino 的 Rx 和 Tx。超声波模块的 Echo 和 Trig 分别接两个 Arduino 的数字输入／输出引脚。 超声波测距仪工作原理超声波具有定向性好的特点，因此可以用来测距。此超声波测距模块需要给予 Trig 脚最少 10 微秒的高电平作为触发信号，之后便会自动发射超声波，并接收反射波。一旦接受到反射回来的声波，便会在 Echo 脚输出一段时间的高电平。该高电平持续时间就是声波的传播时间。因此，测量出超声波的传播时间，再结合已知的声音在空气中的传播速度，就可以算出距离。 此超声波测距模块的工作范围是 4 厘米到 4.5 米，且精度很高，达到毫米级。两次测量最好间隔 60 毫秒以上。 Arduino 编程123456789101112131415161718192021222324252627282930313233343536int trigPin = 7;int echoPin = 8;unsigned long startTime = 0;unsigned long endTime = 0; //时间可能会溢出void setup() { Serial.begin(9600); pinMode(trigPin, OUTPUT); pinMode(echoPin, INPUT);}void loop() { digitalWrite(trigPin, HIGH); delayMicroseconds(15); //至少给trig引脚10us的高电平 digitalWrite(trigPin, LOW); while(digitalRead(echoPin) == LOW); //等待echo引脚返回高电平 startTime = micros(); while(digitalRead(echoPin) == HIGH); endTime = micros(); if(startTime &gt; endTime) { //溢出，此次结果作废 return; } double deltaTime = endTime - startTime; double distance = (deltaTime / 1000000.0 * 340.0) / 2.0; //unit: m Serial.println(distance * 100); //unit: cm delay(1000); } 需要注意的一点是，Arduino 的时间值是从上电到当前的累积，用 long 型保存。因此上电时间过长的话，会产生溢出。虽然这种情况要等待很久才会发生，但最好还是做一个判断。 测量出高电平持续的时间，算出距离后直接写到串口上，蓝牙模块就会自动发送数据了。 iOS 客户端源代码已经放在了 GitLab 上。 上面是测量的过程中，用物体遮挡一段时间的结果。 上面是让障碍物先远离，再靠近，最后释放的结果。 每接受到一次新的数据，就会让图标重绘一次，就形成了图表不断变化的效果。 附：近期总结转眼间七月就要过去了，暑假已经过去一大半了。本来计划是 8 月前把算法什么的搞完，8 月能自在些。结果最近突然要学车，再加上又双叒叕生病了……没办法只能往后拖拖了……祝明天科目二考试顺利吧，赶紧学完车能歇歇了。","link":"/2017/07/30/iOS%E8%93%9D%E7%89%99%E5%BC%80%E5%8F%91-%E8%B6%85%E5%A3%B0%E6%B3%A2%E6%B5%8B%E8%B7%9D%E4%BB%AA/"},{"title":"iOS静默推送","text":"iOS 静默推送静默推送，更准确地说，后台更新通知（Background Update Notification）是苹果在 iOS7 开始支持的新功能。简单来说，它让我们拥有了在用户毫无察觉的情况下，唤起应用并执行代码的能力，赋予了极大的想象空间。 能力苹果在设计静默推送的时候，是希望开发者可以定时唤醒应用，下载最新的内容。这样，用户隔一段时间后打开应用，也能立刻看到最新的内容（比如当天的新闻等），而不用打开应用后再等待刷新。不过我们当然可以利用这个能力来做一些奇怪的事情 : ) 静默推送可以在不弹出横幅等通知的情况下（用户无感），将应用唤醒。经过测试，如果应用是处于挂起，或是被系统终止的情况下，都是可以唤醒的。也就是说，只要用户没有手动将程序从后台关闭就可以。苹果在官方文档上说，最长可以执行 30s 的代码，不过可以通过设置来讲后台执行代码的时间稍作延长。在实际使用中，我发现这并不是说每次都给你 30s 的时间随便执行代码，到时间就终止，而似乎是主线程一旦空闲，程序就会被终止掉（这点存疑）。也就是，如果你在子线程上执行诸如网络请求等代码，可能很快程序就被系统终止了，再也收不到回调。 与普通推送相比，静默推送不仅是无感，我们更关心的是它可以唤醒已经死掉的程序。 调试与配置走 APNS 推送显然是需要后台来做的。但是，借助工具，iOS 程序员也可以自行调试。比如，可以在 GitHub 上下载 Knuff 应用来调试。 配置好后，只要点击 push 按钮，手机上就会收到一条推送了！ 在 Knuff 界面上，可以看到需要配置的一些字段。Identity 是要选择推送证书，在应用最终上线时，服务端也是需要这个证书来进行验证的。可以在苹果开发者账号管理页面生成 p12 证书，生成证书时，记得选好类型，是 sandbox 还是 production。 Token 是设备的编号，否则，苹果的服务器怎么知道向哪台设备推送呢？当程序调用了 registerForRemoteNotifications 向苹果注册了推送后，在 1- (void)application:(UIApplication *)app didRegisterForRemoteNotificationsWithDeviceToken:(NSData *)deviceToken 方法中可以拿到 token。注意，一定要在 Capability 中勾选上 Remote notification，并使用真机调试。这个 token 并不是一成不变的，有可能会发生变动。 Payload 中就是要传给苹果的内容，其中 content-available 字段设置为 1 表示静默推送。 接收推送收到推送通知后，会调用 AppDelegate 中的 1- (void)application:(UIApplication *)application didReceiveRemoteNotification:(NSDictionary *)userInfo fetchCompletionHandler:(void (^)(UIBackgroundFetchResult result))completionHandler 方法。如果程序是被唤醒的，当然会先走启动逻辑，再来调用这个方法。在这里就可以开始书写自己的逻辑了。 延长执行时间在实际测试中，我发现往往程序执行还不到 30s，就被干掉了，因此怀疑是主线程一旦空闲，系统就不管子线程的死活了（不确定）。但是可能我在后台正在执行网络请求，这个时候就需要延长执行时间。 可以通过 background task 来获得更长的执行时间： 123self.backgroundTaskId = [[UIApplication sharedApplication] beginBackgroundTaskWithExpirationHandler:^{ NSLog(@&quot;end&quot;); }]; 系统即将要终止应用时，会调用这个回调方法。但是建议在系统强制终止程序前，通过 1[[UIApplication sharedApplication] endBackgroundTask:self.backgroundTaskId]; 手动通知系统任务完成。 后台传输很多情况下，在程序被唤醒后都要去下载/上传一个比较大的文件。即使通过上述方法延长了执行时间，可能也不足以等到文件传输完毕。好在苹果也提供了后台传输的方法，通过此方法，上传/下载任务会被交给操作系统执行，即使程序被 kill 掉，也可以继续完成传输任务。 通过 AFNetworking，可以这样开启后台传输： 1234567NSURLSessionConfiguration *config = [NSURLSessionConfiguration backgroundSessionConfigurationWithIdentifier:@&quot;your.identifier&quot;];self.manager = [[AFURLSessionManager alloc] initWithSessionConfiguration:config];NSMutableURLRequest *request = [AFHTTPRequestSerializer.serializer requestWithMethod:@&quot;PUT&quot; URLString:@&quot;https://your.url&quot; parameters:nil error:nil];request.timeoutInterval = 60.0;[[self.manager uploadTaskWithRequest:request fromData:nil progress:nil completionHandler:^(NSURLResponse * _Nonnull response, id _Nullable responseObject, NSError * _Nullable error) { //}] resume]; 当后台传输完毕后，系统会调用 1- (void)application:(UIApplication *)application handleEventsForBackgroundURLSession:(NSString *)identifier completionHandler:(void (^)(void))completionHandler 再次唤醒程序，并执行我们的代码。","link":"/2018/08/08/iOS%E9%9D%99%E9%BB%98%E6%8E%A8%E9%80%81/"},{"title":"Intro to CocoaPods","text":"Intro to CocoaPods就像 JavaScript 的 NPM，Python 的 pip，Java 的 Gradle，甚至 Ubuntu 的 apt-get 一样，我们在使用 Xcode 开发软件时也需要使用包管理工具。CocoaPods 就是这样的一款用 Ruby 编写第三方库依赖管理工具，每个 iOS Developer 都不会对它感到陌生。 作为一个优秀的工程师，我们除了要掌握 pod install ，pod update 这些命令的使用方法之外，对工具背后运行的原理有个简单的了解也是必要的。这样能帮助我们定位问题，以及在工具的基础上拓展出更适合我们的工具链。 CocoaPods 基本结构如前面所说，CocoaPods 使用 Ruby 开发的。Ruby 工程同样也有自己的包管理工具：RubyGems。其中一个叫做 Bundler 的 Gem 会解析 Gemfile 文件来管理依赖和版本。是的，作为一个包管理工具，CocoaPods 也是用包管理工具构建的。其中的几个核心的 Gem 为： CocoaPods/Specs用来保管第三方库的 Podspec 文件。当我们执行 pod install 等命令时，CocoaPods 就会去这里寻找组件指定版本的 Podspec 文件。 CocoaPods/CocoaPods这个 Gem 是面向用户的，当我们使用 pod 命令操作 CocoaPods 时，这个组件会被激活，并调用其他的 Gem 来最终完成操作。 CocoaPods/Core给 CocoaPods 提供基础支持，比如解析 Podfile、Podspec 文件等。 CocoaPods/Xcodeproj允许我们通过 Ruby 来操作 Xcode 工程配置，例如 .xcworkspace 、.xcconfig 等。 在字节跳动，我们也有一些其他的 Gem 来拓展额外的能力，比如 CocoaPods-BDTransform。这个工具由组件平台的同学开发，用来在无需重新 pod install 的情况下转换组件的源码模式、二进制模式、开发模式。 初探 Podfile即使是刚刚入门 iOS 的开发者，也很容易编写出这样的 Podfile： 1234567891011121314source 'https://github.com/CocoaPods/Specs.git'platform :ios, '9.0'inhibit_all_warnings!target 'MyApp' do pod 'GoogleAnalytics', '~&gt; 3.1'endpost_install do |installer| installer.pods_project.targets.each do |target| puts target.name endend 这样的 DSL 看起来非常简洁清晰，但其实，Podfile 就是一个标准的 Ruby 文件！能做到看起来不像是代码，而像是纯粹的描述文件，是利用了 Ruby 的一些语言特性。 Ruby 简介evalRuby 作为一门脚本语言，提供了 eval 方法来直接执行字符串形式的代码。它模糊了数据与代码的边界，提供了非常强的动态化能力。这让 CocoaPods 可以直接执行 Podfile 文件，获取其中的信息。可以想像，假如 Objective-C 也能直接 eval，那客户端程序员就再也不用发版了😊。 方法调用Ruby 中调用方法时，小括号是可选的。也就是说，下面的两种写法语法上都是正确的： 12puts 'hello'puts('world') 也就是说，Podfile 中的 source 'xxx.git' 、target xxxx 其实都是在调用不同的方法而已。Ruby 还允许方法名以问好或感叹号结尾，inhibit_all_warnings! 其实也就是调用了一个普通的函数。 BlockRuby 通过 block 来支持函数式编程。在一切皆对象的 Ruby 中，block 自然也是一个对象，支持作为参数传递。我们可以通过 yield 语句来调用传入的 block。一个接收 block 作为参数的函数如下： 1234567def doSomeThing yield if block_given?enddoSomeThing do puts 'hello world'end do-end 语句也可以替换成大括号： 123doSomeThing { puts 'world hello'} 由于 block 也是对象（Proc 类的实例），因此也可以显式的写成函数的参数： 1234567def doSomeThing(&amp;block) block.callenddoSomeThing { puts 'hello world'} Block 也可以接收参数，用两个竖线包裹起来参数名称就可以了： 1234567def printSomeThing yield 'hello!'endprintSomeThing do |someThing| puts someThingend 这样看起来就更像其他的语言了。Ruby 优雅是真的优雅，奇怪也确实有点奇怪… 回头看 Podfile，我们其实是向 target 和 post_install 函数中分别传入了一个 block 作为参数。 SymbolsRuby 中还有一个语法现象叫做 Symbol。它很像一个字符串，也可以和字符串互相转换，但它在运行时不可改变。Symbols 还有个好处是比较是否相等的复杂度是 O(1)。使用冒号就可以创造出一个符号： 12x = :my_stry = :my_str 这里两个变量将指向同一个内存区域。如果是字符串，则将会创造出两个字符串。我们经常利用 Symbols 来当作枚举值使用。 Podfile 中，我们向 platform 函数传递的第一个参数 :ios，就是一个 Symbol。 pod install 过程那么，在我们执行 pod install 命令之后，CocoaPods 都会执行些什么呢？ 我们找到 install.rb 文件，看一下源码： 12345678910111213141516module Pod class Command class Install &lt; Command #...... def run verify_podfile_exists! installer = installer_for_config installer.repo_update = repo_update?(:default =&gt; false) installer.update = false installer.deployment = @deployment installer.clean_install = @clean_install installer.install! end end endend 可以看到，首先 CocoaPods 调用 installer_for_config 方法，获取到了一个 installer 实例。把 update 属性设置为 false 以和 pod update 命令区分。即，pod update 会无视Podfile.lock 文件，重新分析依赖。最后，调用了 installer 的 install! 方法。 先看第一个方法： 1234567def installer_for_config Installer.new(config.sandbox, config.podfile, config.lockfile)enddef podfile @podfile ||= Podfile.from_file(podfile_path) if podfile_pathend config.podfile 方法就开始分析 Podfile 了。在 CocoaPods/Core 中，可以找到 from_file 方法的定义： 12345678910def self.from_file(path) case path.extname when '', '.podfile', '.rb' Podfile.from_ruby(path) when '.yaml' Podfile.from_yaml(path) else raise Informative, &quot;Unsupported Podfile format `#{path}`.&quot; endend 一般我们的 Podfile 都没有添加后缀，因此会进入到 from_ruby 方法中。 1234567 def self.from_ruby(path, contents = nil) contents ||= File.open(path, 'r:utf-8', &amp;:read) podfile = Podfile.new(path) do eval(contents, nil, path.to_s) end podfileend 毫不意外，CocoaPods 会直接 eval Podfile 的文件内容。Podfile 中的那些“配置项”，则定义在 podfile/dsl.rb 文件中。我们来看下最熟悉的 pod 方法（例如：pod 'GoogleAnalytics', '~&gt; 3.1'）： 123456789101112def pod(name = nil, *requirements) unless name raise StandardError, 'A dependency requires a name.' end current_target_definition.store_pod(name, *requirements)enddef store_pod(name, *requirements) get_hash_value('dependencies', []) &lt;&lt; pod nilend 它会把一个 pod 存入到 dependencies 数组中。 接下来，我们再看一下 install! 方法都做了什么。 12345678910111213def install! prepare resolve_dependencies download_dependencies validate_targets if installation_options.skip_pods_project_generation? show_skip_pods_project_generation_message else integrate end write_lockfiles perform_post_install_actionsend 在 install 的时候，会执行以下几个核心操作： 依赖决议，分析 Podfile、Podfile.lock、Manifest.lock 文件。Podfile.lock 文件记录了 pod install 后的依赖信息，Manifest.lock 文件记录了当前已经安装的依赖信息。如果正确 install 成功，两个文件的内容应该是一致的。 下载依赖。根据决议后的依赖版本进行下载。 校验生成的 target 是否合法。 生成 Pods 工程，并把依赖集成进去。 在 resolve_dependencies 中，CocoaPods 使用了一个叫做 Molinillo 的依赖解析算法。为什么需要解析依赖关系呢？想象一下，我们的主工程可能依赖 A、B 两个 pod；其中，A 又依赖 C、D；B 依赖 C、E，而它们之间可能依赖的版本还不一样。可以看到，实际的依赖关系会非常复杂，CocoaPods 必须把依赖关系分析清楚，才能知道具体要下载哪些 pod。 这里不具体介绍 Molinillo 的具体实现方式，只需要知道它会输入一个依赖列表，并将它转换成依赖图（一个合法的依赖关系图应该是一个有向无环图）。这个算法本身没有什么问题，是非常高效的。然而，当出现了循环依赖，或是版本号控制不严格的时候，就会造成频繁的入栈、出栈，造成解析速度的直线飙升，使 pod install 操作变得非常缓慢，达到小时级。大型项目中通常将依赖关系拍平，统一放在壳工程的 Podfile 中，再 hook 掉这个过程，从而完全跳过依赖解析。 References[1] CocoaPods 都做了什么？ [2] 美团外卖iOS多端复用的推动、支撑与思考","link":"/2020/10/06/intro-to-cocoapods/"},{"title":"iOS限制UIScrollView允许滑动角度","text":"iOS 限定 UIScrollView 允许滑动角度本文主要解决 UIScrollView 中自己添加的滑动手势与它本身自带的滑动手势冲突的问题。 最近做的项目中，有一个需求是在一个 UITextView 中，把手指滑动过程中覆盖的文字标记为红色（以备后续使用）。而由于文本可能很长，上下滚动 UITextView 的功能要保留，就像下面这样： 滑动把文本标记为红色比较简单。只需要在 UITextView 上添加一个 UIPanGestureRecognizer ，手指移动的时候找出坐标对应的文字就好了。要命的是，这会带来手势冲突：所有的滑动事件都被自己添加的这个手势捕获了，UITextView 没有办法上下滚动。一个直观的想法就是，我们可以给 UITextView 限定一个允许滚动的角度，比如，用户以 80～90 度的方向（非常竖直的方向）滑动时，认为是在滚动视图；而以一个较为水平的方向滑动时，认为在标记文字。 但是怎么去判定方向呢？我们固然可以在自己添加的手势中根据坐标算出来角度，但是这样没有办法限制住 UITextView 的滚动。UIScrollView 的代理方法也做不到限制它滚动。所以只能另辟蹊径了！ 首先，我们要覆盖掉 UITextView 自己判断是否执行手势的方法，借此来控制手势的成功与失败： 1234567891011class TextView: UITextView { override func gestureRecognizerShouldBegin(_ gestureRecognizer: UIGestureRecognizer) -&gt; Bool { if gestureRecognizer == self.panGestureRecognizer { let point = (gestureRecognizer as! UIPanGestureRecognizer).translation(in: self) if fabs(point.y) / fabs(point.x) &lt; 1 { return false } } return super.gestureRecognizerShouldBegin(gestureRecognizer) }} 这里我们用自己的 TextView 来继承了 UITextView。当 x 与 y 成一定比值时（这里是大于 45 度，因为 arctan(1) = 45度）返回 false 令手势失败。 然后，在自己的 ViewController 中，设置自己添加的手势必须要在 UITextView 自己的滑动手势失败后（即角度比较水平的时候）才开始识别。 1234567func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldRequiredToFailBy otherGestureRecognizer: UIGestureRecognizer) -&gt; Bool { if gestureRecognizer == textView.panGestureRecognizer { return false } else { return true }} 大功告成！ 但是程序一运行，发现不对劲了。每次滑动一段时间之后，文字才开始变红，这个体验就很不好了。仔细一想，原来是因为自己的手势必须要等待滑动手势失败之后才能开始识别。而这需要时间。所以我们只好把逻辑反过来，竖直滑动的时候让自己的手势失败；再让 UITextView 的手势等待我们自己的手势失败后再开始识别。 最终的代码： 12345678910111213141516171819202122232425262728293031323334353637383940class TextReciteViewController: UIViewController, UITextViewDelegate, UIGestureRecognizerDelegate { let textView = TextView() //要用自己的 TextView 而不是 UITextView 了 override func viewDidLoad() { super.viewDidLoad() //...... textView.delegate = self let panGesture = UIPanGestureRecognizer(target: self, action: #selector(TextReciteViewController.panToSelectText(gesture:))) panGesture.delegate = self textView.addGestureRecognizer(panGesture) //...... } @objc func panToSelectText(gesture: UIPanGestureRecognizer) { //把文字标记为红色 let location = gesture.location(in: textView) //...... } func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer, shouldBeRequiredToFailBy otherGestureRecognizer: UIGestureRecognizer) -&gt; Bool { if otherGestureRecognizer == textView.panGestureRecognizer { return true } else { return false } }}class TextView: UITextView { override func gestureRecognizerShouldBegin(_ gestureRecognizer: UIGestureRecognizer) -&gt; Bool { if gestureRecognizer is UIPanGestureRecognizer &amp;&amp; gestureRecognizer != self.panGestureRecognizer { let point = (gestureRecognizer as! UIPanGestureRecognizer).translation(in: self) if fabs(point.y) / fabs(point.x) &gt; 0.15 { return false } } return super.gestureRecognizerShouldBegin(gestureRecognizer) }} 最终就能实现一开始的动图啦！","link":"/2017/11/13/iOS%E9%99%90%E5%88%B6UIScrollView%E5%85%81%E8%AE%B8%E6%BB%91%E5%8A%A8%E8%A7%92%E5%BA%A6/"},{"title":"Intro to LLVM IR","text":"Intro to LLVM IR本文介绍 LLVM IR 的基本语法和结构。了解 LLVM IR 语法，对使用 LLVM 编译器也非常有帮助。 生成 IR 代码首先我们写一个最基本的 C 文件： 123int sum(int a, int b) { return a + b;} 简单的不能再简单了。然后，把它编译成 IR 代码： 1clang sum.c -emit-llvm -S -c -o sum.ll 这样就得到了编译后的 IR 代码： 1234567891011121314151617181920212223242526; ModuleID = 'sum.c'source_filename = &quot;sum.c&quot;target datalayout = &quot;e-m:o-i64:64-f80:128-n8:16:32:64-S128&quot;target triple = &quot;x86_64-apple-macosx10.15.0&quot;; Function Attrs: noinline nounwind optnone ssp uwtabledefine i32 @sum(i32, i32) #0 { %3 = alloca i32, align 4 %4 = alloca i32, align 4 store i32 %0, i32* %3, align 4 store i32 %1, i32* %4, align 4 %5 = load i32, i32* %3, align 4 %6 = load i32, i32* %4, align 4 %7 = add nsw i32 %5, %6 ret i32 %7}attributes #0 = { noinline nounwind optnone ssp uwtable &quot;correctly-rounded-divide-sqrt-fp-math&quot;=&quot;false&quot; &quot;darwin-stkchk-strong-link&quot; &quot;disable-tail-calls&quot;=&quot;false&quot; &quot;frame-pointer&quot;=&quot;all&quot; &quot;less-precise-fpmad&quot;=&quot;false&quot; &quot;min-legal-vector-width&quot;=&quot;0&quot; &quot;no-infs-fp-math&quot;=&quot;false&quot; &quot;no-jump-tables&quot;=&quot;false&quot; &quot;no-nans-fp-math&quot;=&quot;false&quot; &quot;no-signed-zeros-fp-math&quot;=&quot;false&quot; &quot;no-trapping-math&quot;=&quot;false&quot; &quot;probe-stack&quot;=&quot;___chkstk_darwin&quot; &quot;stack-protector-buffer-size&quot;=&quot;8&quot; &quot;target-cpu&quot;=&quot;penryn&quot; &quot;target-features&quot;=&quot;+cx16,+cx8,+fxsr,+mmx,+sahf,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87&quot; &quot;unsafe-fp-math&quot;=&quot;false&quot; &quot;use-soft-float&quot;=&quot;false&quot; }!llvm.module.flags = !{!0, !1, !2}!llvm.ident = !{!3}!0 = !{i32 2, !&quot;SDK Version&quot;, [3 x i32] [i32 10, i32 15, i32 4]}!1 = !{i32 1, !&quot;wchar_size&quot;, i32 4}!2 = !{i32 7, !&quot;PIC Level&quot;, i32 2}!3 = !{!&quot;Apple clang version 11.0.3 (clang-1103.0.32.29)&quot;} 语法简介分号 ; 表示注释。 整个 LLVM 文件是一个 LLVM 模块（module）。模块是 LLVM 最顶层的数据结构，每个模块包含一系列的函数，每个函数包含一系列的基本块（Basic Block，BB），每个 BB 包含一系列的指令。此外，模块还包括一系列用于支撑它的一系列外围实体，比如全局变量，外部函数，以及目标数据布局等。 目标数据布局最上方的 target datalayout 和 target triple 描述了目标机器的字节序、类型大小等信息，如指针位宽、首选对齐方式等。 函数声明1define i32 @sum(i32, i32) #0 { 函数的生命和 C 语言语法类似。此函数具有一个 i32 类型的返回值。iN 表示任意大小的整数，比如 i32，i64 和 i128 。浮点数类型有 double 和 float。向量的格式如 \\ 表示包含 4 个 i32 类型元素的向量。 全局标识符使用 @，如这里的函数名 @sum。 这个函数有两个 i32 类型的入参。 #0 记号映射到一组函数属性，被定义在文件的末尾： 1attributes #0 = { noinline nounwind optnone ssp...... 这些函数属性类似于 C/C++ 中的属性。例如，nounwind 表示函数未抛出异常，ssp（stack smash protector）表示使用栈粉碎保护器来防止攻击，提升安全性。 局部变量IR 中的局部变量和寄存器的作用类似，以 % 开头，名称任意，甚至可以用纯数字。例如： 1%add = add nsw i32 %0, %1 与一般的汇编语言寄存器不同，LLVM 使用静态单赋值（SSA）。在这种形势下，每个变量只能被赋值一次，不可被重复赋值。因此每个变量的值都可以立刻追溯到唯一一条指令。使用 SSA 导致 use-def chain 的生成变得简单，有利于编译器的设计。 此外，LLVM 对局部变量的最大数量没有限制。我们可以理解成有无穷多个寄存器。 基本块我在前面的博客中已经介绍过基本块的概念。在 LLVM 中，每个 BB 都会有一个标签。如果省略了标签，汇编器会自动添加上一个。 每个 BB 都需要一个结束符指令结尾，比如跳转到另一个 BB 或事函数返回。 第一个 BB 是入口基本块，不能作为任何分支指令的目标。 在 sum 文件中，只有一个基本块。函数中没有明确给出标签，但是以 ret 结束。 常见指令下面以上述代码为例，介绍常见的几个指令。 12%3 = alloca i32, align 4%4 = alloca i32, align 4 alloca 指令在当前执行的函数栈上分配内存，函数返回到调用者时会自动释放内存。此指令的返回值是一个指针。这里，分配了 i32 类型大小的空间，按 4 字节对齐。 12store i32 %0, i32* %3, align 4store i32 %1, i32* %4, align 4 store 指令有两个参数，一个是要被存储的值，另一个是存储的地址。格式是： 1store [volatile] &lt;ty&gt; &lt;value&gt;, &lt;ty&gt;* &lt;pointer&gt; 这里，%0 和 %1 的值就分别被存储到刚刚分配出来的内存上了。 12%5 = load i32, i32* %3, align 4%6 = load i32, i32* %4, align 4 load 指令可以从内存中读数据。它需要一个类型和一个地址。这里，%3 和 %4 对应的地址上的值被读出来，放进了 %5 和 %6 中。 1%7 = add nsw i32 %5, %6 add 指令的结构为： 1&lt;result&gt; = add &lt;ty&gt; &lt;op1&gt;, &lt;op2&gt; nsw 是 no signed wrap 的缩写，类似的还有 nuw，no unsigned wrap，表示已知不会溢出，因此允许进行一些优化。 最后，函数返回 %7 。 我们可以看到，中间的 store，load 操作完全是多余的，我们可以直接给参数相加，返回结果。这是因为 clang 默认使用 -O0 优化，即无优化。如果使用优化器，则会得到更简洁的代码。 Metadata文件最后方以 exclamation point（!）开头的部分是 metadata。LLVM 通过使用 metadata 来向优化器和代码生成器传递更多的信息。 References: http://llvm.org/docs/LangRef.html","link":"/2020/03/28/intro-to-llvm-ir/"},{"title":"Brief Intro to ViT","text":"Brief Intro to ViT最近 Transformer 非常流行。Transformer 本身应用在 NLP 中，直到 2020 年 Google 带来了视觉领域的应用 Vision Transformer（ViT）。其在图像分类上达到了接近 SOTA 的程度，标志着视觉中 self-attention 类网络也可以很好的代替 CNN 完成工作。许多人甚至认为 Transformer 开启了视觉的新时代，未来能完全取代 CNN。 在介绍 ViT 之前，我们不得不先了解一下 NLP 中的 Transformer。 Attention我们为什么需要注意力机制？简单来说，注意力机制就是给原始数据乘上一个权重，从而使得变换后的数据更利于学习。这个权重就是所谓的注意力系数。我们通过给 RNN 网络引入一个新的注意力模块，即一个新的神经网络，来负责学习怎样分配权重。 应用在自然语言时，比如 “Bank of the river” 这句话。如果只看 Bank，可能会联想到银行。但是如果引入注意力机制，Bank 和 river 就会产生很强的关联性。这样经过新的权重的处理后，Bank 对应的向量可能就会更偏向于“河岸”，而不是“银行”。这样就从直观上解释了为什么经过 self- attention 之后网络的效果会得到提升。 具体是怎样做这个权重的变换呢？下图展示了对向量 V3 做变换的过程： V3 分别和所有的向量 V1 - V4 相乘，得到一组 score S。这些 score 经过归一化之后即得到了权重 W。W 再分别和 V1 - V4 相乘再相加，即得到了 V3 所对应的 Y3。类似的，我们也可以得到 Y1，Y2 和 Y4。V3 被称为 Key，上下两组 V1 - V4 被称为 Query 和 Value。 但是这样的过程是没有“学习”的。因此引入一些矩阵 M-k，M-q 以及 M-v 与 K、Q、V 相乘，即三个 Linear 层。这样这些参数就可以随着训练更新了。 上图稍加转换，就得到了论文中提出的 Scaled Dot-Product Attention，仅多引入了一个 Scale 项和 Mask 项而已。Mask 是为了在训练过程中，网络不会提前看到未知的数据。 当 Q、K、V 相同时，即为 Self- Attention。 Multihead - AttentionMultihead - Attention 将 Q、K、V 分割成多块，然后并行处理，最后再连接到一起。这样不仅可以增加运算效率，还可以让不同位置的数据（比如一个句子中不同位置的单词）学习到不同的注意力模式。由于我们需要对句子中的每个词向量都分别计算注意力，而这个计算过程本身并不相关，因此完全可以并行处理。 RNN 的弊端RNN 有两个主要问题： 由于 RNN 需要接收上一个时刻的状态作为输入，因此不能很好的并行处理。训练速度较慢。 随着链条越来越长，梯度会逐渐变小，误差没有办法很好的传播到较久之前的时刻。 随着 LSTM / GRU 的提出，第二个问题一定程度上得到了解决。但是由于网络更加的复杂了，训练会变得更慢。 Transformer 的提出摒弃掉了 RNN 的结构，因此可以很好地并行化处理。 TransformerTransformer 的网络结构如下： 左右两部分分别是 Encoder 和 Decoder，这是为 Seq2Seq 类型的任务设计的，例如机器翻译。在 ViT 中，我们只需要 Encoder。不过两者非常相似，理解了 Encoder 也就理解了 Decoder。 首先，输入的数据要被 embed 成向量的形式，这个 embed 过程也是通过学习得到的。 Embed 得到的向量要加上 Positional Encoding。这带来了位置信息，否则网络就不知道一个词向量处于句子中的哪个位置。 接下来就是上面谈过的 Multi-Head Attention 了。Q 和 K 相乘得到了 score，更高的 score 代表了更强的注意力，小的 score 最终经过 Softmax 后会区域 0，即抹掉不相关的东西。这里要做 scale 是为了防止乘法得数过大带来不稳定。 处理过后得到的输出带有更多的上下文信息，也就有更强的表现力。结果通过残差模块和之前的层相连。 最终，Encoder 学习到的隐含表示将作为 Decoder 的一项输入。 ViT如上面所说，ViT 只用到了 Encoder 的结构： ViT 中，将图片拆分成了多个小块作为输入。论文中给出的是 16x16，也就是标题 An Image is Worth 16x16 Words 的由来。Transformer 的输出接上了一个 MLP 来实现最终的分类。 无需卷积？123456789101112131415161718class PatchEmbedding(torch.nn.Module): def __init__(self, in_channels=3, patch_size=16, emb_size=768, img_size=224): super().__init__() self.patch_size = patch_size self.projection = torch.nn.Sequential( torch.nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size), Rearrange('b e (h) (w) -&gt; b (h w) e'), ) self.cls_token = torch.nn.Parameter(torch.randn(1, 1, emb_size)) self.positions = torch.nn.Parameter(torch.randn((img_size // patch_size) ** 2 + 1, emb_size)) def forward(self, x): bs = x.shape[0] x = self.projection(x) cls_tokens = einops.repeat(self.cls_token, '() n e -&gt; b n e', b=bs) x = torch.cat([cls_tokens, x], dim=1) x += self.positions return x 在 Patch + Embedding 过程中，ViT 可以直接将图片切割成多个小块，再通过一层 Linear 来做 Embedding。然而实际上，使用 stride = kernel_size 的卷积运算来分块会带来更好的分类效果。因此 ViT 其实也是依赖了卷积的。 疑问（ToDo）想彻底理解 ViT 需要的背景知识比较多，比如 Transformer、Attention 等等。目前我仍有一些地方存在困惑： 为什么需要插入一个 class_token？ 通过 ViT 对 MNIST 进行分类确实达到了不错的效果。但是当我把 Multihead Attention 的实现更换成 Pytorch 自带的实现后，分类效果就显著下降了。虽然阅读了源码但是还没有查到问题所在。 没有问题的实现： 12345678910111213141516171819202122232425262728class MultiheadAttention(torch.nn.Module): def __init__(self, emb_size = 768, num_heads = 8, dropout = 0): super().__init__() self.emb_size = emb_size self.num_heads = num_heads # fuse the queries, keys and values in one matrix self.qkv = torch.nn.Linear(emb_size, emb_size * 3) self.att_drop = torch.nn.Dropout(dropout) self.projection = torch.nn.Linear(emb_size, emb_size) def forward(self, x, mask=None): # split keys, queries and values in num_heads qkv = einops.rearrange(self.qkv(x), &quot;b n (h d qkv) -&gt; (qkv) b h n d&quot;, h=self.num_heads, qkv=3) queries, keys, values = qkv[0], qkv[1], qkv[2] # sum up over the last axis energy = torch.einsum('bhqd, bhkd -&gt; bhqk', queries, keys) # batch, num_heads, query_len, key_len if mask is not None: fill_value = torch.finfo(torch.float32).min energy.mask_fill(~mask, fill_value) scaling = self.emb_size ** (1/2) att = F.softmax(energy, dim=-1) / scaling att = self.att_drop(att) # sum up over the third axis out = torch.einsum('bhal, bhlv -&gt; bhav ', att, values) out = einops.rearrange(out, &quot;b h n d -&gt; b n (h d)&quot;) out = self.projection(out) return out 使用 Pytorch 自带的实现（有问题）： 1234567class MultiheadAttention(torch.nn.MultiheadAttention): def __init__(self, embed_dim, num_heads, **kwargs): super().__init__(embed_dim, num_heads, **kwargs) def forward(self, x, **kwargs): x = super().forward(query=x, key=x, value=x, need_weights=False, **kwargs) return x[0] Update *使用 Pytorch 自带的 MultiheadAttention 的问题已经解决： 睡觉的时候突然想到会不会和计算图有关。因为将相同的 x 传入了三次，在反向传播计算梯度的时候，可能会把 K、Q、V 的梯度都累加到 x 上。于是把代码改成了这样： 1234567class MultiheadAttention(torch.nn.MultiheadAttention): def __init__(self, embed_dim, num_heads, **kwargs): super().__init__(embed_dim, num_heads, **kwargs) def forward(self, x, **kwargs): x = super().forward(query=x.clone().detach(), key=x.clone().detach(), value=x, need_weights=False, **kwargs) return x[0] 将其中两个从计算图中 detach 出来。之后网络性能果然正常了。经过实验，保留 key 或者 value 都可以达到不错的精度；保留 query 不行。 只学会框架的使用只能解决浅层的问题，当稍微复杂一些的问题出现时，就必须对底层工作原理有所了解才可能解决。但是不管怎么说，问题解决了还是值得开心一下的🎉 References ViT 原文 https://arxiv.org/pdf/2010.11929.pdf Transformer 原文 https://arxiv.org/pdf/1706.03762.pdf ViT 的介绍，运算步骤介绍的比较清楚 https://www.kaggle.com/abhinand05/vision-transformer-vit-tutorial-baseline/#data Transformer 的视频介绍 https://www.youtube.com/watch?v=TQQlZhbC5ps&amp;t=1s 另外一个非常好的视频介绍，从 self-attention 一直到 Transformer https://www.youtube.com/watch?v=yGTUuEx3GkA&amp;list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb&amp;index=10 Transformer 的 Pytorch 实现。作者非常热心，回复了我的邮件提问（虽然 sadly 并没有解决）https://towardsdatascience.com/implementing-visualttransformer-in-pytorch-184f9f16f632 使用 Transformer 训练 MNIST https://towardsdatascience.com/a-demonstration-of-using-vision-transformers-in-pytorch-mnist-handwritten-digit-recognition-407eafbc15b0 Pytorch 官方 Transformer 教程 https://pytorch.org/tutorials/beginner/transformer_tutorial.html#load-and-batch-data https://zhuanlan.zhihu.com/p/266311690","link":"/2021/03/06/intro-to-vit/"},{"title":"直观理解 Wavelets","text":"直观理解 Wavelets刚开始接触小波变换的时候完全搞不清楚其基本原理，对“多分辨率分析”、“时频分辨率”这些术语更是云里雾里。网络上好的教程极度稀缺。这时候就必须强烈推荐 The Wavelet Tutorial：http://users.rowan.edu/~polikar/WTtutorial.html ，真正做到了深入浅出，通读下来让人感觉受益匪浅。 Time Resolution大家都很熟悉傅立叶变换（FT）了。FT 用无限长的正弦、余弦函数把时域信号变换到频域。但是它只告诉了我们信号中有哪些频率，没有告诉我们这些频率出现在哪里。从理论上说，这些频率每个时间点都有，毕竟从频域能完美还原出时域信号——但这不能满足工程的需要。 以下图来说，这个信号主要包含了 4 个频率分量。一开始频率较高，随后频率变低。如果我们将 0-300 ms 和 300-600 ms 的信号交换位置，他们的傅里叶变换会非常相似。毕竟信号的主要频率成分还是这些，并没有改变。当然严格来说，频率肯定是变了的，但是改变的部分都是次要的频率。在工程上我们肯定只关注主要部分，那么只看频谱图就会给我们一种信号相同的感觉。 傅立叶变换没有时间分辨率！也就是说，它只适合用来分析平稳（stationary）信号，而现实中的信号往往都是非平稳信号。 Short Time Fourier Transform (STFT)一个对傅立叶变换的直观改进就是短时傅里叶变换。既然信号不是平稳的，那么我们可以把它分割成很多小段，然后假定很小的时间片段内信号可以看成是平稳的。STFT 通过窗函数分割原始信号，并在窗口内进行傅里叶变换。公式如下：$$STFT_X^{(\\omega)}(t,f) = \\int_t \\left[ x(t) \\cdot \\omega^*(t - t’) \\right] \\cdot e^{-j 2 \\pi f t} dt$$可以看到，现在的 STFT 函数是和时间和频率都相关的了！也就是我们既可以知道有哪些频率，又可以知道这些频率出现在哪里。下图中有对称的两组峰，是因为傅里叶变换本身就具有对称性。 Heisenberg 测不准原理测不准原理其实算是一种基本的自然法则，并不只局限于量子力学领域。在时频分析中，测不准原理是指时间分辨率和频率分辨率不能同时无限提高，而是存在互相制约的关系。提高时间分辨率，就会带来频率分辨率的下降，反之亦然。 以 STFT 为例，如果我们用较窄的时间窗来做变换，自然提升了时间分辨率。毕竟窗口窄了，分析时间的精度就高了。以极限的角度思考，假如窗口无限长，那么就退化回普通的傅里叶变换了，自然完全谈不上时间分辨率了。下图可以看到，从时间轴看过去（白色箭头）边缘非常清晰；而从频率轴看过去（紫色箭头），就是类似高斯分布的形状，包含了很长一段频率区间。 如果用较宽的窗口做变换，就正好相反。从频率轴的方向看，边缘非常锐利，几乎只有一个频率点有值。而时间轴上，很宽的范围内都有较大的值，甚至重叠在了一起。我们没有办法很好的分辨该频率具体出现在哪个时间点上。 Wavelet Transform由于测不准现象的存在，我们很难去选择某一个长度的时间窗。小波变换通过多分辨率的方式来解决这一问题，公式如下：$$CWT_x^\\psi(\\tau,s) = \\Psi_x^\\psi(\\tau,s) = \\frac{1}{\\sqrt{|s|}} \\int x(t) \\psi^* \\left( \\frac{t - \\tau}{s} \\right) dt$$小波变换首先需要一个母小波函数 $\\psi$ ，它只在有限长的时间内有能量。小波变换与两个变量相关，即尺度 s 和位移 t，也就是把母小波压缩 / 拉伸，并且对每个尺度都平移扫描整个信号。我们知道时域上压缩信号，就相当于频域上的拓展，因此尺度 s 越小，对应的频率就越高。位移 t 自然反应了时间信息。小波变换的时频图如下： 通过小波变换，我们在高频处获得了好的时间分辨率和差的频率分辨率。在低频处，我们获得了好的频率分辨率和差的时间分辨率。这很合理，因为高频往往代表着信号发生了突变，我们需要精确定位突变发生的时间。而低频分量往往分散在很广的时间范围内，因此不用对具体在哪里出现而特别关心。 ReferenceThe Wavelet Tutorial 写的非常好，非常感谢作者 Prof. Polikar 的付出：http://users.rowan.edu/~polikar/WTtutorial.html。然而其网站上所有 LaTeX 公式都没有渲染出来，读起来比较费劲。可以参考其 PDF 版本：https://web.iitd.ac.in/~sumeet/WaveletTutorial.pdf 一点小感想🤔 为什么互联网上大部分的资料 / 教程都很难懂呢？我想至少有以下三个原因： 他们不是写给普通人看的，也许搞数学的人就喜欢直接看公式，不用先建立一个感性的理解（By the math people, for the math people）。是我等凡夫俗子不能企及的高度，境界不够。 故弄玄虚，搞的高大上一些方能彰显作者水平。通俗易懂了岂不是显得很 low？ 不懂装懂，自己也不理解自己写的啥，把别人写的东西无脑粘贴一下，毕竟天下文章一大抄。这点在某些中文博客平台很常见，四处“转载”，毫无原创。 希望能有更多像 The Wavelet Tutorial 一样的“说人话”的文章吧！","link":"/2021/06/28/intuitive-wavelets/"},{"title":"How to Show Percentage Diagram on Kibana","text":"How to Show Percentage Diagram on Kibana我们经常通过 Kibana 来对一些线上监控数据做可视化。通过 Kibana 过滤、制作折线图等等都非常简单。然而有些场景下，我们并不关心数据的绝对值，而更想查看比例，例如某个 API 的失败率等。这个时候我们会希望绘制这样的一个折线图：x axis 为时间，y axis 为该接口的失败率。 计算比率很简单，做个除法就好。但是选中 Kibana 的 Visualize 就会发现，在 Y-Axis 的选项中并没有提供百分比或除法的选项。 解决方法由于 Kibana 并没有直接提供计算除法的方式，所以操作起来稍微繁琐一些。 Y-Axis Aggregation 仍选择 Count，Buckets X-Axis Aggregation 选择 Date Histogram。之后点击 Add sub-buckets - Split Series 中选择你需要展示的字段。比如我这里通过 Terms - is_success 区分接口成功和失败。这样，折线图就被分成两条线，一个是 is_success = true ，另外一个是 false。 之后点击 Metrics &amp; Axes，在 Y-Axes Mode 中选择 percentage。这样就会按百分比绘制了。把折线图改为 Area 可能会看得更清楚一些。效果如下图。","link":"/2020/07/21/kibana-visualize-percent/"},{"title":"Listening to FM Radio with RTL-SDR","text":"Listening to FM Radio with RTL-SDR【RTL-SDR 上手】 上大学的时候用 Pluto-SDR 做过一个简单的小项目。那个时候刚刚听说 SDR，认识还比较模糊，也就没想到什么好的玩法，导致白白浪费了不少宝贵的资源。最近工作压力比较大，总想找个别的东西玩一玩儿，就又想起了无线电 —— 也算是重操旧业了吧。 设备大三的时候玩的 Pluto-SDR 其实性能很好，而且是全双工的。但是价格较贵，要 RMB 1000+ 左右。其他类似的 SDR 平台，例如 HackRF 等也都差不多这个价位。只好退而求其次，买个 RTL-SDR 先尝试下，有意思的话再上更高端的型号。 RTL-SDR 性能差，一开始就是个电视棒而已，但是价格非常低廉（RMB 40 元左右），是入门 SDR 的不二选择。我这里买的是两个端口的型号，支持的频谱范围更广一点，价格在 100 元左右。 上手一些开源软件在 Linux 上的支持比 macOS 上更友好一些，因此还是在虚拟机上跑了个 Ubuntu。 首先把一些常用的工具安装上： 123456sudo apt-get updatesudo apt-get upgradesudo apt-get install gitsudo apt-get install cmakesudo apt-get install build-essential 接下来要装一个用于访问 USB 设备的 C 语言库： 1sudo apt-get install libusb-1.0-0-dev 然后安装 RTL SDR 的驱动程序： 123456789git clone git://git.osmocom.org/rtl-sdr.gitcd rtl-sdr/mkdir buildcd buildcmake ../ -DINSTALL_UDEV_RULES=ONmakesudo make installsudo ldconfigsudo cp ../rtl-sdr.rules /etc/udev/rules.d/ 这中间在 cmake 的时候出了一个问题，卡了一两个小时的样子。执行 cmake 的时候，报下面的错误： 12CMake Error at CMakeLists.txt:77 (message): LibUSB 1.0 required to compile rtl-sdr 奇怪的是，我们之前已经安装了 libusb 库。如果直接去 Google 这个错误的时候，会发现大家也都是在说需要安装 libusb。最开始是怀疑安装的有问题，但是卸载重装也没用，而且是能找到 header 文件的。 这个时候我注意到安装的库对应的架构师 AMD64，一开始还怀疑是虚拟机的原因，是不是虚拟化成 AMD 系列的 CPU 了。后来用 arch 命令看了下是 X86 的。就去 Ubuntu 的资源站看了下，发现没有 X86 架构的 libusb，只有 i386 。但是强行指定 i386 也没用。后来发现 AMD64 这个名字比较迷惑，其实 Ubuntu 下 AMD64 只用来指代 64 位操作系统，和 CPU 架构无关，闹了个乌龙 😭。 然后又仔细看了下 cmake 输出的 log 文件，发现有这么个错： 1CheckSymbolExists.c:(.text+0x1b): undefined reference to `pthread_create' 找不到 pthread，这就很诡异了，而且检查了本地的 pthread 库也没有问题。后来发现这是 cmake 的 bug 😓 参见 StackOverflow 上的问答 。 之后只好再仔细看 osmocom 官网 wiki ，发现还有一种用 autotools 编译的方法。想着即使编不过，也能给我个正常的错误提示吧，结果又出了奇怪的错，说有个宏找不到。 这个时候突然惊醒了我，不会是这个鬼 driver 的 master 分支不稳定吧！赶紧去 GitHub 的镜像看了下 release 的版本，发现最新的是 0.6.0。于是 checkout 到这个 tag 下，再编译，果然顺利通过了！所以是谁把 master 分支搞坏掉的，坑死我了。 之后就可以顺利的安装 gqrx 来收听 FM 广播了。调到 FM 87.6 MHz （北京文艺广播），效果还可以，虽然有一些杂音，但还是可以听清人声的。 总之，业余有个东西折腾下还是挺开心的。 参考有一个特别好的入门教程，在 https://ranous.wordpress.com/rtl-sdr4linux/ 但是我们都知道这种小众的网站都是不太稳定的，说不定哪天就打不开了…… 但是这个教程实在太好了，所以我就在我自己的服务器上备份了一下：http://share.luyuan.wang/sdr/（当然我的服务器就更不稳定了，哈哈） 还有一些很好的系列教程，如下： https://payatu.com/getting-started-radio-hacking-part-2-listening-fm-using-rtl-sdr-gqrx https://charlesreid1.com/wiki/DVB-T_USB_SDR https://luaradio.io/new-to-sdr.html","link":"/2020/04/10/listen-fm-rtl-sdr/"},{"title":"Ubuntu Won't Boot With Nvidia Driver Installed","text":"Ubuntu Won’t Boot With Nvidia Driver InstalledI recently got a new Alienware M15 R6 gaming laptop computer from my lab. After installing Ubuntu (dual boot with Windows), the next thing to do is to utilize its RTX 3080 GPU by installing Nvidia drivers. The problem was with Nvidia drivers installed, the whole system won’t boot up. It just shows a black screen with some system prompt text and stuck. How to fixBy pressing ctrl+alt+F2 I can enter TTY2 and use the command-line interface. I can also use the recovery mode to operate my computer. I have to run sudo apt-get purge nvidia* to remove all Nvidia drivers so that my computer can boot again. But this means I can’t run PyTorch or any other software using CUDA. It’s a big waste of the 3080 graphic card! At first, I thought the driver was not installed properly. Then I realized the driver was working because I can use the nvidia-smi command in the command-line mode. The problem is the XServer. If I use startx command and try to start the XServer in the command line, the whole system will freeze. After some digging, I found there are two Nvidia config files in /usr/shared/X11/xorg.conf.d folder. One is 10-nvidia.conf and the other one is 11-nvidia-prime.conf, and the ModulePath is different! The ModulePath in the nvidia-prime file is definitely wrong, those files and directories do not exist. I tried to copy files from one path to the other or change the ModulePath parameter, but none of these worked. Finally, I uninstalled nvidia-prime, and it worked! The backlight problemAnother problem is I cannot adjust the brightness of my screen. I checked the brightness number inside /sys/class/backlight/nvidia_0, and it was fine. It turns out Linux does not support Hybrid Graphics. I have to turn off this setting in BIOS.","link":"/2022/01/25/nvidia-driver-not-boot/"},{"title":"Intro to Tagged Pointer","text":"Intro to Tagged Pointer所谓 Tagged Pointer 就是指针不再指向数据，而是用其中的一部分直接表示该数据本身。这个词借鉴于 Tagged Architecture 。在 Tagged Architecture 中，每个字（word）的一部分被用来表示数据的类型（type），这部分就是所谓的 Tag。虽然本质上和 Tagged Pointer 有所区别，但该名称还是被一直沿用下来。 问题起因这个问题要追溯到将近两年前我的一篇博客 ，当时我正在学习 Obj-C 的内存管理。为了验证使用 autoreleasepool 可以解决循环中大量创建临时变量导致内存不断上涨的问题，我写了这样的一段代码： 12345678910int main() { for(int i = 0; i &lt;10000000; i++) { @autoreleasepool { NSNumber *num = [NSNumber numberWithInt:i]; NSString *str = [NSString stringWithFormat:@&quot;%d &quot;, i]; [NSString stringWithFormat:@&quot;%@%@&quot;, num, str]; //* 为什么这行是必要的？ } } return 0;} 当时在博客中遗留了一个问题，即为什么把其中一行代码注释掉，就观察不到内存上涨的情况了。当时也提出了一些猜想，和其他人讨论后也觉得站不住脚。直到最近又把这个问题抛出，得知 Tagged Pointer 的存在后，问题才算有了答案。 引入 Tagged Pointer2013 年苹果发布了第一款 64 位架构处理器的手机，iPhone5s。由于寄存器、数据总线宽度和字长都翻倍达到了 64 位，指针和其他一些较小的数据占用的空间也就变大了。而且由于字节对齐的要求，指针后 4 位将永远是 0。对于 NSNumber 等小对象来说，这就存在一种浪费。苹果因此引入了 Tagged Pointer，在 NSNumber、NSString、NSDate、NSIndexPath 等对象占用空间比较小的时候，直接把值本身存在指针里。由于无需 malloc、free、操作引用计数，号称可以在相关场景内存减半的基础上，带来 3 倍访问速度的提升和 100 倍的创建、销毁效率。 而引入 Tagged Pointer 之后，在数据大小允许的情况下，就可以直接放入指针中存储。具体来说，最后一位置 1，表示是 Tagged Pointer。60 位用来存数据，剩下的 3 位用来表示类型。 代码验证有了以上知识，我们很容易就能写出代码验证： 12345int main(int argc, const char * argv[]) { NSNumber *a = @1; NSLog(@&quot;%p&quot;, a); return 0;} 打印出来的结果是：0xaac4045801d025e1 。等一下，这和网上说的效果不一样呀？为什么是这样看起来毫无规律的数字呢？难道这个 NSNumber 指针并不是一个 Tagged Pointer？ 通过调试，我们可以看到这个对象虽然还是 __NSCFNumber * 类型，但是它的 isa 指针却是 0x0，也就意味着它的确是个 Tagged Pointer。那为什么指针的值这么奇怪呢？更奇怪的是，这个值每次运行还都不一样。 一开始我怀疑是因为我是在 macOS 运行的程序，后来尝试了在模拟器和真机上运行，也都没得到预期的效果。没办法，只好去查看一下 Obj-C 的开源代码。在 objc-internal.h 中，可以看到创建 Tagged Pointer 的函数： 12345678910111213141516171819202122232425static inline void * _Nonnull_objc_makeTaggedPointer(objc_tag_index_t tag, uintptr_t value){ // PAYLOAD_LSHIFT and PAYLOAD_RSHIFT are the payload extraction shifts. // They are reversed here for payload insertion. // assert(_objc_taggedPointersEnabled()); if (tag &lt;= OBJC_TAG_Last60BitPayload) { // assert(((value &lt;&lt; _OBJC_TAG_PAYLOAD_RSHIFT) &gt;&gt; _OBJC_TAG_PAYLOAD_LSHIFT) == value); uintptr_t result = (_OBJC_TAG_MASK | ((uintptr_t)tag &lt;&lt; _OBJC_TAG_INDEX_SHIFT) | ((value &lt;&lt; _OBJC_TAG_PAYLOAD_RSHIFT) &gt;&gt; _OBJC_TAG_PAYLOAD_LSHIFT)); return _objc_encodeTaggedPointer(result); } else { // assert(tag &gt;= OBJC_TAG_First52BitPayload); // assert(tag &lt;= OBJC_TAG_Last52BitPayload); // assert(((value &lt;&lt; _OBJC_TAG_EXT_PAYLOAD_RSHIFT) &gt;&gt; _OBJC_TAG_EXT_PAYLOAD_LSHIFT) == value); uintptr_t result = (_OBJC_TAG_EXT_MASK | ((uintptr_t)(tag - OBJC_TAG_First52BitPayload) &lt;&lt; _OBJC_TAG_EXT_INDEX_SHIFT) | ((value &lt;&lt; _OBJC_TAG_EXT_PAYLOAD_RSHIFT) &gt;&gt; _OBJC_TAG_EXT_PAYLOAD_LSHIFT)); return _objc_encodeTaggedPointer(result); }} 其中调用了 _objc_encodeTaggedPointer 函数给指针编码： 123456extern uintptr_t objc_debug_taggedpointer_obfuscator;static inline void * _Nonnull_objc_encodeTaggedPointer(uintptr_t ptr){ return (void *)(objc_debug_taggedpointer_obfuscator ^ ptr);} 看到这里一口老血直接喷出来了，原来苹果在这里做了混淆！找到这个用于混淆的值初始化的文件 objc-runtime-new.mm ： 1234567891011121314151617181920212223242526/************************************************************************ initializeTaggedPointerObfuscator* Initialize objc_debug_taggedpointer_obfuscator with randomness.** The tagged pointer obfuscator is intended to make it more difficult* for an attacker to construct a particular object as a tagged pointer,* in the presence of a buffer overflow or other write control over some* memory. The obfuscator is XORed with the tagged pointers when setting* or retrieving payload values. They are filled with randomness on first* use.**********************************************************************/static voidinitializeTaggedPointerObfuscator(void){ if (sdkIsOlderThan(10_14, 12_0, 12_0, 5_0, 3_0) || // Set the obfuscator to zero for apps linked against older SDKs, // in case they're relying on the tagged pointer representation. DisableTaggedPointerObfuscation) { objc_debug_taggedpointer_obfuscator = 0; } else { // Pull random data into the variable, then shift away all non-payload bits. arc4random_buf(&amp;objc_debug_taggedpointer_obfuscator, sizeof(objc_debug_taggedpointer_obfuscator)); objc_debug_taggedpointer_obfuscator &amp;= ~_OBJC_TAG_MASK; }} 原来是苹果爸爸为了让程序更安全，故意随机混淆 Tagged Pointer 来增加攻击的难度。而老版本的操作系统上是没有这步混淆的。这也就是为什么网上古老的博客上说法完全复现不了。苹果爸爸的一片苦心坑死我了～ 查看真实的值好在苹果的这个混淆只是一个简单的 XOR，而且用于混淆的值是 external，且只在第一次使用的时候被初始化（天时地利人和啊！），因此我们可以很简单的把原始的值再异或回来： 12345extern uintptr_t objc_debug_taggedpointer_obfuscator;NSNumber *a = @(0);long long result = (long long)a ^ (long long)objc_debug_taggedpointer_obfuscator;NSLog(@&quot;%llx&quot;, result); 在输入 0 的时候，可以看到输出是 0x27 ，也就是 100111 ；输入是 1 的时候，输出是 0x127 即 100100111 。这里又有点奇怪，不是说好最后一位是 1，三位表示类型，60 位表示原始数值吗？从苹果的源码可以看到 OBJC_TAG_NSNumber = 3，即 011 。现在无法解释的就只剩前面的 0010 了。 如果换一种写法： 1NSNumber *a = @(1.0); 就可以发现，最终打印出来的值是 101010111 。也就是说，还有 4 位在表示着这个数值的类型，是 double 还是 int。考虑到 mac 的 x64 架构是小端序，因此排布会和 iPhone 上有差异。在 mac 上，以 NSNumber 为例，应该是这样的： 而如果是 NSString，情况将更加复杂。苹果采用了一套非常复杂的机制来对字符串进行编码，甚至会根据英文字母的词频来使用不同的对照表。也即是说，同样长度的字符串，内容不一样的话，有可能一个会被转成 Tagged Pointer，而另外一个不会。细节可以参考：Tagged Pointer Strings 面试题发现多篇博客都提到了这道面试题，我在这里也跟个风： Question: 执行以下代码会发生什么？ 123456789101112131415161718@interface ViewController ()@property (nonatomic, copy) NSString *name;@end@implementation ViewController- (void)viewDidLoad { [super viewDidLoad]; dispatch_queue_t queue = dispatch_get_global_queue(0, 0); for (int i = 0; i &lt; 1000; i++) { dispatch_async(queue, ^{ self.name = [NSString stringWithFormat:@&quot;abcdefghijklmn&quot;]; }); }}@end Answer： 会崩溃在 objc_release 里。因为对变量赋新值，在 ARC 下编译器会帮我们添加 [obj release] 来给引用计数减 1 。并发情况下调用 release 就会导致崩溃。解决方法很简单，只需要加锁，比如改成 atomic 就可以了。 那如果改动一行，变成如下的代码呢？ 1self.name = [NSString stringWithFormat:@&quot;abc&quot;]; 答案是不会崩溃，因为 Tagged Pointer 不是真正的对象，不会调用 release 操作。神奇！ 回到最初因为数据比较小，NSNumber 和 NSString 正好都成为了 Tagged Pointer，并没有实际的堆上对象内存分配，自然内存不会持续上涨。而碰巧加上关键的那行之后，字符串拼接导致长度较长，超出了 Tagged Pointer 能承载的范围，于是就开始真的给 NSString 对象分配内存了，这才能出现大量创建临时变量的前提。 参考了大量的博客和文章，其中一些写的非常深入： 深入理解 Tagged Pointer Tagged Pointer Strings 聊聊伪指针 Tagged Pointer","link":"/2020/01/08/intro-to-tagged-ptr/"},{"title":"ORB Feature Extraction with OpenCV","text":"ORB Feature Extraction with OpenCVOriented FAST and rotated BRIEF (ORB) 特征是 SLAM 中比较常用的一种图像特征。它的准确率并没有 SIFT 高，但是其计算速度更快，可以满足实时特征提取的需求。ORB 特征还具有旋转、尺度不变性的特点，因此很适合应用在 SLAM 场景中。 ORB 特征由 Key Point 和 Descriptor 两部分组成，其 key point 为改进的 FAST 角点，被称为 Oriented FAST 角点 – 它计算了角点的主方向，可以为后续的 BRIEF descriptor 增加旋转不变性。Descriptor 为改进的 BRIEF 描述子，克服了原始 BRIEF descriptor 在图像旋转时容易丢失的缺点。 FAST Corner DetectorFeatures from Accelerated Segment Test (FAST) 是一种角点检测算法，它检测相邻的像素亮度差异，如果差异较大，则认为该点可能是一个角点。该算法比较简单，因此速度很快。其检测过程如下： 在图像中选择像素点 p，记其亮度为 Ip。 选定阈值 t。 选取其周围半径为 3 的 16 个临近像素点。 若有连续 N 个像素点的亮度与 Ip 的差异大于 t，则认为 p 为特征点。 FAST 没有尺度不变性，可以通过构建图像金字塔的方式来弥补。Oriented FAST 还计算了特征点附近图像的灰度质心，连接图像块的几何中心和质心，将其定义为角点的方向。 BRIEF Descriptor得到角点之后，我们需要“描述”角点的信息，这样才能对不同的角点进行区分，以便于后续做特征点的匹配。Binary Robust Independent Elementary Features (BRIEF) 是一种二进制的描述子，其描述向量由一组 0 / 1 表示，其计算效率很高。 BRIEF 首先对图片做平滑处理以抑制噪声。接着，以关键点为中心，选取一个 patch。在 patch 中选择一对点，如果点 p 的亮度高于点 q，则标记为 1；否则为 0。以这样的方式选取出 128 个像素对，构成了描述向量。像素对的选取是随机的，可以服从 Uniform，Gaussian 等分布。 由于 BRIEF 本身没有旋转不变性，Rotated BRIEF 利用之间计算的关键点方向信息，计算旋转后的 BRIEF 特征来弥补这一缺点。 ORB Feature with OpenCV利用 OpenCV 检测 ORB 特征点并做匹配的代码（C++）如下。特征点匹配选用了最简单的暴力匹配方法，即分别计算两张图中所有的关键点描述向量的距离，选出其中距离最小的一对，认为是一个匹配。由于这里是二进制的描述向量，因此可以采用 Hamming 距离，即不同位的个数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// orb.cpp#include &lt;iostream&gt;#include &lt;opencv2/core/core.hpp&gt;#include &lt;opencv2/features2d/features2d.hpp&gt;#include &lt;opencv2/highgui/highgui.hpp&gt;#include &lt;opencv2/opencv.hpp&gt;using namespace std;using namespace cv;int main() { Mat img1 = imread(&quot;./1.jpg&quot;, CV_LOAD_IMAGE_COLOR); Mat img2 = imread(&quot;./2.jpg&quot;, CV_LOAD_IMAGE_COLOR); cv::resize(img1, img1, Size(), 0.2, 0.2); // make the image smaller cv::resize(img2, img2, Size(), 0.2, 0.2); vector&lt;KeyPoint&gt; kp1, kp2; Mat descriptors1, descriptors2; Ptr&lt;FeatureDetector&gt; detector = ORB::create(); Ptr&lt;DescriptorExtractor&gt; descriptor = ORB::create(); Ptr&lt;DescriptorMatcher&gt; matcher = DescriptorMatcher::create(&quot;BruteForce-Hamming&quot;); detector-&gt;detect(img1, kp1); detector-&gt;detect(img2, kp2); Mat out1; drawKeypoints(img1, kp1, out1, Scalar::all(-1), DrawMatchesFlags::DEFAULT); namedWindow(&quot;ORB 1&quot;, WindowFlags::WINDOW_KEEPRATIO); imshow(&quot;ORB 1&quot;, out1); resizeWindow(&quot;ORB 1&quot;, 800, 600); Mat out2; drawKeypoints(img2, kp2, out2, Scalar::all(-1), DrawMatchesFlags::DEFAULT); namedWindow(&quot;ORB 2&quot;, WindowFlags::WINDOW_KEEPRATIO); imshow(&quot;ORB 2&quot;, out2); resizeWindow(&quot;ORB 2&quot;, 800, 600); descriptor-&gt;compute(img1, kp1, descriptors1); descriptor-&gt;compute(img2, kp2, descriptors2); vector&lt;DMatch&gt; matches; matcher-&gt;match(descriptors1, descriptors2, matches); auto min_max = minmax_element(matches.begin(), matches.end(), [](const DMatch &amp;m1, const DMatch &amp;m2) {return m1.distance &lt; m2.distance;} ); double min_dist = min_max.first-&gt;distance; double max_dist = min_max.second-&gt;distance; vector&lt;DMatch&gt; good_matches; for (int i=0; i&lt;descriptors1.rows; i++) { if (matches[i].distance &lt;= max(2 * min_dist, 40.0)) { good_matches.push_back(matches[i]); } } Mat img_match; Mat img_good; drawMatches(img1, kp1, img2, kp2, matches, img_match); drawMatches(img1, kp1, img2, kp2, good_matches, img_good); imshow(&quot;all&quot;, img_match); imshow(&quot;good&quot;, img_good); waitKey(0); return 0;} Makefile 如下： 12345678910CC = g++CFLAGS = -g -WallSRCS = orb.cppPROG = a.outOPENCV = `pkg-config opencv --cflags --libs`LIBS = $(OPENCV)$(PROG):$(SRCS) $(CC) $(CFLAGS) -o $(PROG) $(SRCS) $(LIBS) Results随手拍了两张照片，相机视角有一个微小的移动。ORB 特征点本身如下： 所有的特征点匹配如下： 手动筛选出一些匹配得较好的特征点如下： 可以看到匹配结果还比较满意。有了特征点的匹配，下一步就可以计算相机的 pose 了。 Reference[1] 视觉 SLAM 十四讲 [2] https://medium.com/data-breach/introduction-to-brief-binary-robust-independent-elementary-features-436f4a31a0e6 [3] https://medium.com/data-breach/introduction-to-fast-features-from-accelerated-segment-test-4ed33dde6d65","link":"/2021/11/05/orb-opencv/"},{"title":"Install PySPQR on M1 Chip Mac","text":"Install PySPQR on M1 Chip MacPySPQR 是稀疏矩阵库 SUITESPARSEQR 的 Python 封装。通过 QR 矩阵分解，我们可以高效求解 Ax = b 的线性问题。由于 PySPQR 只是一层封装，因此在安装成功后，使用时会先用 cffi (C Foreign Function Interface) 库来编译 C 文件。 SuiteSparseQR_C.h Not Found我遇到的第一个问题是 SuiteSparseQR_C.h: No such file or directory。这个问题在 GitHub issue 中也有提到，但在 mac 上的解决方法可能不太一样。 首先我们要安装 Ceres-Solver，这是一个 Google 开发的最小二乘问题的求解库。通过 Homebrew 很容易安装： 1brew install ceres-solver 由于一直在做 SLAM 问题，所以这个库我已经安装过了。因此这个头文件是在 Homebrew 的 include 目录中的： 1/opt/homebrew/include 确认文件存在，就说明只是 include path 设置的不对，所以要去 Python Lib 的安装路径下更改 sparseqr_gen.py 的代码，新增一个 include path。由于我是用的 Anaconda 来管理 Python 环境，而 Anaconda 本身又是通过 Homebrew 安装的，因此 Python 库的文件路径如下： 1/opt/homebrew/anaconda3/envs/&lt;your_env_name&gt;/lib/python3.8/site-packages/sparseqr 在原有基础上新增一条 include path： 1include_dirs = [ '/usr/include/suitesparse', join('C:', 'Program Files', 'Python', 'suitesparse'), '/opt/homebrew/include'] 这样头文件找不到的问题就解决了。 Linker error: -lspqr下一个问题是，链接时报错找不到 spqr 库。同样的道理，先从 Homebrew 的 lib 目录确认库存在，再更改 sparseqr_gen.py 中 libraries 变量，指定绝对路径就可以解决。 -arch x86_64上两个问题解决后，编译仍然会失败。仔细看生成的 gcc 命令会发现它在使用 -arch x86_64 编译。这个时候第一反应是应该给 arm64 架构编译，因此我在 sparseqr_gen.py 中修改了环境变量： 1os.environ['ARCHFLAGS'] = '-arch arm64' 但是在编译时，架构参数变成了 -arch arm64 -arch x86_64 。虽然新增了 arm64 架构，但是 x86_64 并没有被消除（而且我也没找到能消除掉的方法）。这时 Linker 会报错说在给 x86_64 的目标文件链接 arm64 的库。 在思考怎样取消对 x86 编译的时候，我注意到任务管理器中 Python 在以 Intel 的模式运行。其实 Anaconda 并没有对 M1 进行适配，它一直在通过 Rosetta2 的方式进行转译。这提示了我可以考虑放弃 arm64 架构，直接通过 Rosetta2 来执行编译后的 x86 文件。 由于 spqr 库是通过 Homebrew 安装 ceres-solver 得到的，但是 ceres-solver 是支持原生运行在 M1 上的，因此要安装 x86 版本的 ceres-solver 并让两者共存。为了做到这一点，首先要安装 x86 版本的 Homebrew： 1arch -x86_64 /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; arm64 架构的 Homebrew 会安装在 /opt 下，而 x86 架构的会安装在 /usr/local 下，这样两者可以共存。之后，再通过 x86 的 Homebrew 安装 ceres-solver： 1arch -x86_64 /usr/local/Homebrew/bin/brew install ceres-solver 这里需要指定 brew 的绝对路径，否则默认仍使用 arm 的 brew 造成冲突。之后就可以更改 library，指定 /usr/local/lib 路径下的 spqr 库。 Dynamic Module最后一个遇到的问题是 Cython 报错： 1Cython Compilation Error: dynamic module does not define module export function 既然动态模块有问题，我就直接指定了 .a 结尾的静态库： 1libraries = ['/usr/local/lib/spqr.a'] 至此问题全部解决。总的来说，由于使用苹果自研的 M1 芯片，在兼容性上确实存在问题。好在 Rosetta2 足够强大，为我们提供了解决问题的途径。而且由于 Rosetta2 表现得非常好，很多时候表面上都感受不到它的存在。","link":"/2022/03/20/pyspqr-install/"},{"title":"How to Print Backtrace for Debugging","text":"How to Print Backtrace for Debugging作为客户端工程师，当我们监控到线上报警需要追查原因的时候，往往需要回捞用户日志。但很多时候日志打得并不十分全面。例如我们查看日志，发现用户出错的原因是某个函数传入的参数不合法，但由于调用方太多，并不知道是哪里在调用的时候传入了错误的值。如果能像 crash report 那样，打印出当前的函数调用栈就好了！ Call Stack在 C 语言中，我们可以使用 #include &lt;execinfo.h&gt; 中的以下两个函数来打印调用栈： 12int backtrace(void** array, int size);char** backtrace_symbols(void* const* array, int size); backtrace 函数会把当前的调用栈地址数组通过 array 返回，而 backtrace_symbols 会返回符号化的调用栈。 具体原理是，当函数调用时会把参数以及 EBP、EIP 寄存器的值压入栈。EBP（Base Pointer）保存当前栈底的地址，EIP（Instruction Pointer）保存下一条要执行的指令的地址，即执行完当前函数后要返回的地址，可以近似认为是调用者的地址。结构如下： 1234567891011121314151617 : : +-----------+ : alignment : +-----------+12(%ebp) | arg2 | +-----------+ 8(%ebp) | arg1 | +-----------+ 4(%ebp) | ret | -----&gt; return address +-----------+ (%ebp) | ebp | -----&gt; previous ebp +-----------+-4(%ebp) | local1 | -----&gt; local vars +-----------+ : alignment : +-----------+ : : 所以，我们通过当前的 EBP 寄存器的值，就可以在栈中找到调用者的地址和调用者的 EBP。再根据调用者的 EBP 又可以找到再上一级的 EBP 和 EIP…… 这样“递归”的寻找，就可以找到所有的 EIP，也就是整个的调用栈。 在 iOS 中，我们可以直接使用 [NSThread callStackSymbols]; 来获取当前线程符号化后的调用栈。 Symbols &amp; dSYM在 Debug 模式下，我们可以很顺畅的打印出带符号的函数调用栈，看起来非常清晰。然而在 Release 模式下，携带符号表会显著增加包大小，所以没有办法做符号化。没有符号表的调用栈打印出来就只有内存的地址，因此完全不可读。如下（遮盖住的内容是项目名称）： dSYM （debug symbols）文件会在编译时产生，其中包含了程序中符号和偏移量之前的映射关系。使用 MachOView 程序可以查看 dSYM 文件中的内容： Symbolization我们打印出来的地址是指令在内存中的地址，然而我们还需要知道程序在内存中被加载的基地址，才能计算出偏移量，进而使用 dSYM 文件做符号化。通过 dyld 可以获得程序加载的 dylib，根据 MachO 程序的格式，header 的地址即为程序的基地址。 12345678910111213141516#include &lt;mach-o/dyld.h&gt;NSString * getImageLoadAddress(){ NSString *strLoadAddress =nil; NSString *strAppName = @&quot;&lt;Your Project Name&gt;&quot;; uint32_t count = _dyld_image_count(); for(uint32_t iImg = 0; iImg &lt; count; iImg++) { const char* szName = _dyld_get_image_name(iImg); if (strstr(szName, strAppName.UTF8String) != NULL) { const struct mach_header* header = _dyld_get_image_header(iImg); strLoadAddress = [NSString stringWithFormat:@&quot;0x%lX&quot;,(uintptr_t)header]; break; } } return strLoadAddress;} 接下来，我们可以使用 atos（address 2 symbol）命令来做符号化。 12cd &lt;Your dSYM file path&gt;xcrun atos -o &lt;Your Project Name&gt;.app.dSYM/Contents/Resources/DWARF/&lt;Your Project Name&gt; -l &lt;Base Address&gt; -arch &lt;Arch&gt; CPU 架构很容易得知，根据机型就可以判断出是 arm64 还是 armv7 。按下回车后会进入输入模式，输入函数调用栈的地址就可以得到符号了。","link":"/2020/08/14/print-backtrace-debug/"},{"title":"Using python-pcl with Python3.6","text":"Using python-pcl with Python3.6PointCloud Library (PCL) 是一个用来处理点云数据的 C++ 库。python-pcl 是一个 Python 的桥接，让我们可以用 Python 调用 PCL 的大多数 API。然而 python-pcl 有些疏于维护，因此并没有办法简单得通过 pip install 的方式安装，会报错。 Environment我的本地开发环境时 Ubuntu 18.04 LTS，通过 Anaconda 使用 Python3.6。使用 Python3.6 的原因是 python-pcl 暂时还不支持更高的 Python 版本。 Installation直接通过 pip install 的方式安装会报错。我们可以通过 APT 进行安装。 1sudo apt install python3-pcl 这个时候，如果直接在 conda 的环境中 import pcl 是会提示找不到模块的。我们需要手动将 package 拷贝到虚拟环境的路径下。 首先寻找 python3-pcl 所处的路径： 1dpkg -L python3-pcl 在我的机器上，路径为 /usr/lib/python3/dist-packages/pcl 。 接下来需要将它拷贝到对应的 conda 环境中。我的环境名为 py36，需要拷贝到的路径为： 1~/anaconda3/envs/py36/lib/python3.6/sites-packages 现在就可以在正常 import 了。 1(py36) luyuan@biorobotics:~$ python -c 'import pcl'","link":"/2021/12/19/python3-pcl/"},{"title":"How to Build and Run VINS-Mobile","text":"How to: Build and Run VINS-MobileVINS-Mono is a SLAM framework developed by researchers at HKUST. The authors also published its mobile version, VINS-Mobile, which can run on iOS devices. Although they provided a pretty good README file to guide us on how to compile and run it, beginners may still feel confused. In this article, I’m going to document all the problems I met, and hopefully, it can be helpful for others. The missing opencv2.frameworkThe authors made some modifications to opencv2, including putting a timestamp into the first 64 bits of a captured image. That’s why we have to download the specific version of OpenCV. If you don’t, first, you will encounter a compilation error of conflict definitions; and second, even you can fix this problem and run the program, the initialization will be stuck at 0%, as the parsed timestamp is wrong. However, the download link provided in the README file is no longer valid. Many people ask about this in GitHub Issues. The authors did provide an alternative way to download the framework on BaiduNetDisk. You may refer to this issue. The problem is that the download speed is super slow, and I have to pay for speedup. I’ve uploaded it to GitHub, and you can download it from here. Someone else also provided a link on GitHub, but it’s not working, don’t use it! SigningNext, we need to go to Signing &amp; Capabilities and select our own developer team to sign the app. Don’t forget also change the Bundle Identifier to your own domain. Update Search PathsIf you installed boost via Homebrew as suggested, you may encounter this problem: 1/VINS-Mobile/ThirdParty/DVision/BRIEF.h:34:10: 'boost/dynamic_bitset.hpp' file not found This is because Homebrew has its own place to store all the header files, and it’s not inside the default search paths of Xcode. Go to Build Settings -&gt; Search Paths and add the following path into it: /opt/homebrew/include. Now you should be able to install it on you iPhone. Unsupported DeviceThis project was developed in 2017, and it’s a long time ago. What I have is an iPhone 12, which is much newer than the supported devices. To add a new device, we need to do the calibration – which means you need to record the camera and IMU data, convert it to ROS bag format, and use Kalibr to do the calibration, which is a lot of work. What’s worse is that you need to measure the translation between the camera and the IMU chip. The authors did this by hand on the PCB, but I don’t really want to open up my iPhone. Luckily, different iPhones have very similar intrinsic and extrinsic parameters, and we can copy from the old parameters for simplicity. And it works well for me. But if we want to have a better result, doing the calibration is still necessary. The parameters are defined in global_param.cpp file, inside the setGlobalParam function. 12345678910111213141516171819202122bool setGlobalParam(DeviceType device){ switch (device) { case iPhone12Pro: // Copied from iPhone7P printf(&quot;Device iPhone12 Pro param\\n&quot;); FOCUS_LENGTH_X = 526.600; FOCUS_LENGTH_Y = 526.678; PX = 243.481; PY = 315.280; SOLVER_TIME = 0.06; FREQ = 3; TIC_X = 0.0; TIC_Y = 0.092; TIC_Z = 0.01; return true; break; case iPhone7P: printf(&quot;Device iPhone7 plus param\\n&quot;); FOCUS_LENGTH_X = 526.600; //.... We need also update the code in deviceName function inside ViewController.mm file. You need check your device name, and add a new else-if statement. 12345678else if(([device compare:@&quot;iPad6,7&quot;] == NSOrderedSame)|| ([device compare:@&quot;iPad6,8&quot;] == NSOrderedSame)){ printf(&quot;Device iPad pro 12.9\\n&quot;); device_type = iPadPro129;} else if ([device compare:@&quot;iPhone13,3&quot;] == NSOrderedSame) { // &quot;iPhone13,3&quot; is the device name of iPhone 12 Pro device_type = iPhone12Pro;} 🎉","link":"/2021/12/04/run-vins-mobile/"},{"title":"Readers / Writers Lock","text":"Readers / Writers Lock在工程实践中，客户端需要从服务端拉取一个配置列表来决定自身的功能表现。几乎所有的 feature 都需要通过 settings 来判断自身的状态，例如是否应该开启本功能（如 A/B Testing），该显示什么样的文案，或是需要打开的 H5 链接是什么。可见，读取 settings 是一个非常高频的操作。在以前的工作中，通过运行 profiling 工具，也确实发现读取 settings 是耗时最久的高频函数。 由于几乎所有的 feature 都需要读取 settings，我们就需要对 settings 加锁来确保线程安全。一个简单的 mutex 就能满足我们对线程安全的需求。然而加锁 / 解锁是比较慢的操作，这是否会有性能提升的空间呢？在实际的场景中，我们知道绝大多数对 settings 的操作都是读取，而写操作（更新 settings）是非常不频繁的。这个时候或许可以考虑使用 Readers / Writers Lock 来优化。 RW Locks在 Readers / Writers Problem 中，writer 必须独占资源；而多个 readers 可以同时读取资源。R / W 问题分为两类： favors readers除非有 writer 得到了访问对象的权限，否则所有的 reader 都不应该等待。如果 writer 正在等待，则后来的 reader 应该插到前面。 favors writers当一个 writer 就绪时，应该尽可能块地给予它访问对象的权限。后来的 reader 应该等待 writer，即使这个 writer 本身也处于等待状态。 我们知道 settings 的更新本身是对时间不敏感的，所以我们只讨论第一种 favors readers 的 case。 Using semaphores on macOS我们在 Linux 上习惯使用 sem_init 函数来初始化一个 semaphore。当它的值为 1 时，就可以用作 mutex。然而 macOS 并不支持该函数。当然为了符合 POSIX 标准，sem_init 的接口还是存在的，可以通过编译。但是该函数的返回值永远是 -1。如果不注意，就会发现所有的锁都不起作用。 在 macOS 上，我们可以通过 sem_open 函数使用 named semaphore，如下： 1mutex = sem_open(&quot;mutex&quot;, O_CREAT, 0777, 1); 第一个参数是 semaphore 的名字。该函数返回的是 semaphore 的指针，这点也和 sem_init 不同。 另外需要注意的是，我们需要在锁使用完成后将其销毁，否则同名的锁下次就会创建失败，因为系统会认为它已经存在了。我们可以通过 sem_unlink 函数来销毁不需要的 semaphore： 1sem_unlink(&quot;mutex&quot;); Timing function为了对比不同锁的性能，我们需要对程序运行时间计时。处于简单的考虑，我们可能会直接使用 clock 函数。然而需要注意的是，clock 返回的是 CPU time，而不是 wall time。在多线程的情况下，使用 CPU time 是错误的。 CPU time 是指 CPU 执行我们的程序所用的时间。在单线程的情况下，它与 wall time 基本一致。在多线程的情况下，假设我们有 4 颗 CPU 核心耗时 1 秒钟执行完任务，那么 CPU time 会是 4，与我们想要的真实时间不一致。 我们可以用 gettimeofday 来获取 wall time： 12345678long start, end;struct timeval timecheck;gettimeofday(&amp;timecheck, NULL);start = (long)timecheck.tv_sec * 1000 + (long)timecheck.tv_usec / 1000;// do something ...gettimeofday(&amp;timecheck, NULL);end = (long)timecheck.tv_sec * 1000 + (long)timecheck.tv_usec / 1000;printf(&quot;%ld milliseconds elapsed\\n&quot;, (end - start)); Implementation简单实用 mutex 的实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt;#include &lt;pthread/pthread.h&gt;#include &lt;semaphore.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/time.h&gt;#define NUM_THREAD 40#define NUM_READ 1#define NUM_LOOP 50000000sem_t *mutex;sem_t *w;long settings = 0;void *read_settings(void *arg) { for (int i = 0; i &lt; NUM_READ; i++) { sem_wait(mutex); for (int j = 0; j &lt; NUM_LOOP; j++) { settings; } sem_post(mutex); }}void *write_settings(void *arg) { sem_wait(mutex); settings += 1; sem_post(mutex);}int main() { int i; pthread_t tid[NUM_THREAD]; sem_unlink(&quot;mutex&quot;); mutex = sem_open(&quot;mutex&quot;, O_CREAT, 0777, 1); sem_unlink(&quot;w&quot;); w = sem_open(&quot;w&quot;, O_CREAT, 0777, 1); long start, end; struct timeval timecheck; gettimeofday(&amp;timecheck, NULL); start = (long)timecheck.tv_sec * 1000 + (long)timecheck.tv_usec / 1000; for (i = 0; i &lt; NUM_THREAD; i++) { if (i % 5 == 0) { pthread_create(tid + i, NULL, write_settings, NULL); } else { pthread_create(tid + i, NULL, read_settings, NULL); } } for (i = 0; i &lt; NUM_THREAD; i++) { pthread_join(tid[i], NULL); } gettimeofday(&amp;timecheck, NULL); end = (long)timecheck.tv_sec * 1000 + (long)timecheck.tv_usec / 1000; printf(&quot;%ld milliseconds elapsed\\n&quot;, (end - start)); return 0;} 我们创建了多个线程，其中读线程比写线程多。使用了一个 int 来模拟要访问的 settings，并用大循环来模拟实际访问资源耗时较久的情况。 读写锁的实现如下： 1234567891011121314151617181920212223242526272829int read_cnt = 0;void *read_settings(void *arg) { for (int i = 0; i &lt; NUM_READ; i++) { sem_wait(mutex); read_cnt++; if (read_cnt == 1) { sem_wait(w); } sem_post(mutex); for (int j = 0; j &lt; NUM_LOOP; j++) { settings; } sem_wait(mutex); read_cnt--; if (read_cnt == 0) { sem_post(w); } sem_post(mutex); }}void *write_settings(void *arg) { sem_wait(w); settings += 1; sem_post(w);} 这里是自己实现的读写锁，也可以通过 pthread 内置的 pthread_rwlock_t 直接使用。可以看到，由于需要维护 reader 的数量，在 reader 的内部也是使用了 mutex 的。因此使用读写锁只在访问资源耗时较久的情况下才有意义。否则如果访问资源本身速度就很快，读写锁和普通的 mutex 就没有区别了，甚至可能会更慢。 Experiment results在 M1 Max 10 核 CPU 的 MacBook Pro 上，分别运行程序多次，求出平均的运行耗时。编译时指定不优化： 1gcc -lpthread -O0 lock.c 结果如下： No lock Mutex R / W lock Time 126 ms 876 ms 130 ms 在这个简单的例子中，读写锁的性能优势明显，与不加锁的理论上界非常接近。","link":"/2021/12/26/rwlock/"},{"title":"macOS上唤起其他程序并获取实时输出","text":"macOS 上唤起其他程序并获得实时输出在开发桌面端程序时，我们偶尔需要调用其他语言写的程序。桥接或者混编当然是比较好的方法，但会比较麻烦。如果可以，让我们自己的程序直接唤起另外一个程序 / 脚本，也是一种不错的选择。这个时候我们就需要两个进程之间互相通信。 两个进程间通信，可以通过一个进程向控制台 print，另外一个从控制台 read 来完成。如果是用 Java 等语言实现，其实比较简单。这里我们谈的是使用 Swift / OC 开发原生应用时，如何实时地获取输出。 场景在这个例子中，我使用 Swift 开发 macOS 的原生应用，它需要调用一个 Python 脚本来跑一些算法。Python 脚本会经常 print 一些值，我们需要时时读取它们。 调用 Python 脚本在工程文件夹新建一个 Python 文件 /Scripts/main.py ，在这里编写算法。这样我们可以通过 Bundle 来获取到这个文件。 在 NSViewController 的 ViewDidLoad 方法中，通过 Process 类来执行其他程序： 1234let task = Process()task.launchPath = &quot;/usr/bin/python&quot;task.arguments = [Bundle.main.path(forResource: &quot;main&quot;, ofType: &quot;py&quot;)!]task.launch() 注意以下几点： NSTask 已经被弃用，应使用 Process。 launchPath 是你在 terminal 中调用的命令（比如，运行 main.py 需要在 terminal 中键入 python main.py，python 是命令，main.py 是参数）。但这里需要绝对路径，python 命令一般在 /usr/bin/ 中，这取决于你具体的环境。 arguments 是参数。我们通过 Bundle 来获取脚本的绝对路径。 调用 task.launch 启动任务。 现在运行程序，可以看到 Python 脚本启动了，且在 Xcode 的控制台中源源不断地 print 信息。 实时获取输出网上的大多数教程只会提及如何获取输出。当然，多数情况我们调用的程序都会很快执行完毕，我们只要获得最后的结果就好了。但是现在，我们的 Python 脚本会一直运行，我们要实时获取输出。 通过 Pipe 来为两个 process 建立一个单工的通信信道： 12let outputPipe = Pipe()task.standardOutput = outputPipe 现在，Python 脚本的 print 已经被转到了 pipe 中，在控制台看不到了。 使用 FileHandle 来处理 Pipe 的输出。先在 NSViewController 类中添加一个新的变量： 1var outFile = FileHandle() 之后： 1outFile = outputPipe.fileHandleForReading 此时已经可以直接获取 outFile 的 data 了。但是我们要的是实时，所以每次 outFile 有数据，都要发送通知： 12NotificationCenter.default.addObserver(self, selector: #selector(onScriptOutputChanged), name: NSNotification.Name.NSFileHandleDataAvailable, object: outFile)outFile.waitForDataInBackgroundAndNotify() 在 onScriptOutputChanged 函数中： 12345678@objc func onScriptOutputChanged() { let data = outFile.availableData let str = String(data: data, encoding: .utf8) if let str = str { print(str) } outFile.waitForDataInBackgroundAndNotify()} 注意，每次接收到通知都要再告诉 outFile 等待并通知一次，否则将只发送一次通知就结束了。 现在运行程序，就可以实时拿到 Python 脚本的输出了。","link":"/2018/05/25/macOS%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%85%B6%E4%BB%96%E7%A8%8B%E5%BA%8F%E5%B9%B6%E8%8E%B7%E5%8F%96%E5%AE%9E%E6%97%B6%E8%BE%93%E5%87%BA/"},{"title":"Linear Color and sRGB","text":"Linear Color and sRGB最近在尝试序列化 SwiftUI，具体来说是把任意的 SwiftUI view 转化成一个 JSON 的模版。由于 SwiftUI 内部的属性都是不对外暴露的，所以只能在 runtime 通过反射（Mirror API）来强行获取内部的属性。例如，如果想保存 Text，就要通过这种方式来获取内部的 string。Swift Playground 和 LLDB 也是通过 Mirror 来在运行时展示对象内部的属性的。 SwiftUI.Color.Resolved在序列化 Color 的时候，我们当然是希望保存其 R、G、B 三个值。在反序列化的时候，把这三个值传给 Color 的构造函数： 1public init(_ colorSpace: Color.RGBColorSpace = .sRGB, red: Double, green: Double, blue: Double, opacity: Double = 1) 但是很容易发现，通过反序列化构造回来的 UI 颜色比正常的 UI 要深一些： 左边是通过反序列化构造的 UI，右边是正常通过 Xcode Preview 显示的 UI。注意看最右边灰色部分，左边明显更深。其余颜色因为是系统颜色，因此序列化时只保存了颜色名称，所以不受影响。 如果我们查看通过 Mirror 反射得到的 RGB 值，就会发现其实它与我们构造 Color 传入的值并不一致： 显然 Color 内部保存的 linear RGB 和我们常用的 RGB 并不一致。那内部是做了哪种变换呢？ Non-linear Transformation我们可以将输入的 R 和内部的 linearRed 的对应关系打印出来： 12345for i in stride(from: 0, to: 1.1, by: 0.01) { let color = Color(red: i, green: 0, blue: 0) let value:Float? = reflectValueByKeys(object: color, keys: [&quot;provider&quot;, &quot;base&quot;, &quot;linearRed&quot;]) print(&quot;\\(i),\\(value!)&quot;)} 这里我写了一个工具函数 reflectValueByKeys 来递归地调用 Mirror，这样比较方便通过一串 label 获取对象内部的属性： 12345678910111213141516func reflectValueByKeys&lt;T&gt;(object: Any, keys: [String]) -&gt; T? { if keys.isEmpty { return nil } let mirror = Mirror(reflecting: object) for child in mirror.children { if child.label == keys[0] { if keys.count &gt; 1 { return reflectValueByKeys(object:child.value, keys:Array(keys[1...])) } else { return child.value as? T } } } return nil} 直接看 print 出来的对应关系，很容易发现这不是一个简单的线性变换： 12345678910110.0,0.00.01,0.00077399380.02,0.00154798760.03,0.00232198140.04,0.0030959751...0.96,0.911407650.97,0.9331070.98,0.95510480.99,0.977402031.0,1.0 把打印出来的结果拷贝到一个文本文件中，我们可以写两行 Python 来可视化这个映射关系（对不起了 SwiftUI Charts，虽然你刚发布但是我懒得升级新系统……） 1234567891011121314151617import matplotlib.pyplot as pltimport numpy as npdata = []with open('./data.txt') as file: for line in file: split = line.split(',') x = float(split[0]) y = float(split[1]) data.append([x, y])data = np.array(data)# plotfig, ax = plt.subplots()ax.plot(data[:, 0], data[:, 1], linewidth=2.0)plt.show() Gamma Correction在物理世界中，如果光强增加一倍，那么亮度也会随之增加一倍。这是一个简单的线性关系。但是在上古时代的 CRT 显像管显示器中，电压增加一倍，亮度并不会等比例增加，而是存在一个 2.2 次方的非线性关系：$$L = U^{2.2}$$这个值被称为 Gamma 值。因此我们常用的 sRGB 色彩空间对它做了一个逆运算，先做 Gamma 矫正，再经过 CRT 显示器天然的变换，最终得到和物理世界一致的正确颜色。 可是现代的显示器早已摒弃了 CRT 技术，为什么还保留了这个 Gamma 值呢？这是因为人眼对较暗的颜色更加敏感（我猜是进化的原因，需要能在暗处观察到捕食者？），因此在数据位数有限的情况下我们希望给较暗的颜色分配更多的存储空间，而忽略亮色。出于编码的原因我们仍然保留了 Gamma 映射。 在 Color 内部存储的其实是线性空间中的 RGB 值，这也是为什么我们看到变量名实际为 linearRed / Green / Blue。当我们变换到 CIE XYZ 空间时，也是在线性空间的基础上做一次线性变换（所有的线性变换都可以用矩阵表示）。因此内部实际存储线性空间的值是合理的。 这个变换的定义如下：$$C_{linear}= \\left{ \\begin{aligned}\\frac{C_{srgb}}{12.92}, \\space C_{srgb} \\leq 0.04045 \\\\left(\\frac{C_{srgb}+0.055}{1.055} \\right)^{2.4}\\end{aligned} \\right.$$所以我们很容易能写出反变换的代码： 123456789private func gammaMappingSRGB(value: Float?) -&gt; Float { guard let value = value else { return 0 } if value &lt; 0.0031308 { return value * 12.92 } return 1.055 * pow(value, (1/2.4)) - 0.055} References[1] CIE Colorimetry: https://medium.com/hipster-color-science/a-beginners-guide-to-colorimetry-401f1830b65a [2] Wikipedia sRGB: https://en.wikipedia.org/wiki/SRGB [3] sRGB: https://www.w3.org/Graphics/Color/sRGB [4] Gamma / Linear / sRGB and Unity: https://zhuanlan.zhihu.com/p/66558476","link":"/2022/06/10/srgb-linear/"},{"title":"Solution to torch.save Taking Too Much Disk Space","text":"Solution to torch.save Taking Too Much Disk Space最近的项目中，需要给图片先做一些预处理。这些预处理的步骤非常消耗 CPU 资源，以至于 GPU 必须要等待 CPU 完成预处理，导致模型的训练速度很慢。为了加快训练速度，就想到先将所有的图片都预处理好，保存起来。这样训练的过程中就可以节省出来预处理的时间了。 问题 1图片预处理本身是按照 batch-size 进行的。但是我们希望最终保存的文件结构和 ImageNet 一致，即一张 ImageNet 的图片对应一个处理好的 tensor.pt 文件。因此需要把一个 batch 中的 tensor 分别存储。于是就写出了这样的代码： 123for b in range(tensors.shape[0]): # iterate a batch tensor = tensors[b] torch.save(tensor, file_path) 运行起来后，发现进度很慢。很快程序就报错了，提示磁盘空间不足。用 du -h 命令一看，仅 ImageNet 中一个类的图片，经过处理后就占用了超过 200G 的磁盘空间。我用的服务器 SSD 只有 512G，很快就撑不住了。 这个问题比较好解决。torch.save 存储的是原始的 tensor，而不是 slice 本身。如果只想存储一个 slice，就需要显式地拷贝一份： 1torch.save(tensor.clone(), file_path) 这样运行速度快了很多，且磁盘占用大幅减少。 问题 2ImageNet 1000 类的图片大概占用 150G 左右的磁盘空间。解决掉问题 1 之后，前 30 类大概占用了 60G。对于试验用的 30 类图片来说是可以接受了，但是如果要拓展到完整的 1000 类，则需要占用约 2T 的空间，显然是不可行的。 经过实验，发现一张约 4kB 的图片，仅仅转换成 tensor 再保存，就会产生 101kB 的文件。这一方面是数据精度的问题，另一方面则是压缩的问题。虽然阅读 torch.save 的源码发现 PyTorch 也有压缩文件，但是并没有看到效果，也没有找到合适的参数来控制它的压缩行为。手动将 101kB 的 .pt 文件再通过 zip 压缩后，发现大小就降到了 4kB 左右。这个压缩的效果就非常令人满意了。 zip我们可以通过 shutil 压缩。shutil 默认是压缩一个文件夹。有人说它不能用来压缩单一的文件，但经过测试，按照如下的写法是可以只压缩单一文件的： 123import shutiltorch.save(tensor, 'test.pt')shutil.make_archive('test.pt', 'zip', './', 'test.pt') unzip可以直接通过 shutil 解压： 12shutil.unpack_archive('test.pt.zip')tensor_read = torch.load('test.pt') 但是这样有个问题，就是需要一个中间的临时文件来装载。用完之后不仅要删除，在多线程处理时还要为每个线程/进程制造一个不同的临时文件，防止冲突。 另外一种方法是直接把文件读到内存中，不依赖一个真正写到磁盘的文件。torch.read 本身也可以接收一个文件当参数，而不一定是文件名： 1234import zipfilearchive = zipfile.ZipFile('test.pt.zip')extracted_file = archive.open('test.pt')tensor_read = torch.load(extracted_file) 性能引入额外的压缩/解压过程会带来额外的开销。只有当这个开销小于预处理本身的开销时才是划算的。对比了一下两种不同的解压缩方法的性能（通过循环 1000 次计时）： Time (seconds) read .pt directly 0.200 shutil unpack 1.627 zipfile open 2.615 发现读到内存中反而还慢一些，不确定是否是因为缓存的缘故，还需要近一步对比。 ToDo应该还可以通过自定义 pickle 的方式来压缩，torch.save 也支持传入一个 pickle module。不过没有尝试。","link":"/2021/03/23/torch-save-too-large/"},{"title":"Understanding MobileNet v2","text":"Understanding MobileNet v2随着深度学习的发展，神经网络为了追求精度，结构越来越深、参数也越来越多。Google 推出的 MobileNet 在 accuracy 和 latency 之间做了平衡，更适合在计算力不足的移动端和嵌入式设备上应用。由于参数量比 ResNet 等网络少了很多，也适合我们在研究初期快速验证想法。 如果只是简单使用 MobileNet，那么 Pytorch 已经内置了现成的实现。但是如果想要在网络的基础上加以改动，则需要我们对 MobileNet 的结构有所了解。 MobileNet v1首先来看一下初代 MobileNet 是如何减轻计算量的。 Standard Convolution传统的卷积操作如下： 假设上一级的输入尺寸为 32x32x3，我们可以用 5 组不同的卷积核去做卷积。每组卷积出来的结果为输出的其中一层。在 stride=1 且有 padding 的情况下，可以得到 32x32x5 的输出。卷积后的尺寸大小计算公式为：$$OutputSize = (InputSize - KernelSize + 2\\cdot Padding)/Stride + 1$$具体过程可以参考 CS231N 的介绍 。 这样的标准卷积所需要的计算量为：$${D_k}^2\\cdot C_i \\cdot C_o \\cdot {D_i}^2$$其中，Dk 为 kernel 的尺寸，Ci 为输入的通道数，Co 为输出的通道数，Di 为输入的 Feature Map 尺寸。 Depthwise Separable ConvolutionMobileNet 提出了一种新的卷积方法 Depthwise Separable Convolution （深度可分离卷积）来减少计算量。它分为两个步骤： Depthwise convolution：不再同时对输入的每个通道一起做卷积，而是分别做 depth 为 1 的卷积。假如输入的通道数为 5，则分别做 5 次卷积。这样下来，卷积后的通道数和输入的通道数一致。 Pointwise convolution：传统的卷积，只不过 kernel size 是 1x1 的。这个步骤可以改变输出的通道数。 这样的计算成本是：$${D_k}^2 \\cdot C_i \\cdot {D_i}^2 + C_i \\cdot C_o \\cdot {D_i}^2$$这样，计算量减少为：$$\\frac{(D_k)^2 \\cdot C_i \\cdot {D_i}^2 + C_i \\cdot C_o \\cdot {D_i}^2}{(D_k)^2\\cdot C_i \\cdot C_o \\cdot {D_i}^2}=\\frac{1}{C_o} + \\frac{1}{(D_k)^2}$$假如 Kernel Size 为 3，那么计算量减少为接近原来的九分之一（输出的通道数一般较大，可忽略该项带来的影响），这带来的计算性能的提升是非常可观的。而精度只下降了一点。 需要注意的是，depthwise conv 和 pointwise conv 后面都要接 Batch Normalization 和 ReLU。 上图中，左边为标准的 3x3 卷积，右边为深度可分离卷积。这里的 ReLU 其实是 ReLU6，即： 1y = min(max(0, x), 6) # 让输出最大不超过6 作者称在低精度的计算中 ReLU6 有更强的鲁棒性。 整体结构和不足MobileNet v1 整体结构如下： 在 ImageNet 上，同样的网络结构下，仅将标准卷积换成 depthwise separable conv，精度损失了 1 个百分点（71.7% 至 70.6%），而参数量从 29.3 Million 显著下降到 4.2 Million。 然而 MobileNet v1 也有不足之处： 首先，其“直筒”形的网络结构影响了精度。后续的 ResNet 等引入了 residual block，通过复用特征带来了分类性能的提升。 其次是 depthwise 卷积的问题。这一点许多资料分析的都不是很清楚，我的个人理解如下（此处存疑）： 在输入 channel 数量较少的情况下（depthwise 卷积操作的 feature map 相对来说维度较少），卷积输出的结果更容易出现 0 或负数。在 channel 数量多的情况下，每层之间的加法更可能把最终的值累加为正数。0 或负数的值通过 ReLU 后梯度为 0，导致反向传播时再也无法进行更新，造成“神经元死亡”。除了可以增加 channel 数量之外，ResNet 等网络的特征复用也有助于缓解这一点。 MobileNet v2MobileNet v2 中，重点解决了 v1 中存在的问题。 改动部分MobileNet v2 中最重要的结构 bottleneck residual block 如下图所示： 后面两部分仍然是熟悉的 depthwise 和 pixelwise 卷积。但是在 v2 中，1x1 的 pixelwise 卷积发挥了不同的作用。在 v1 中，通过 1x1 卷积后 channel 数不是和原来一致，就是扩大为原来的两倍。而在 v2 中，projection 的 1x1 卷积却用来减少 channel 的数量。这也是为什么它被称为 Projection Layer。由于流过网络的数据在这里变少了，所以作者叫它 bottleneck。 回过头来看第一个部分：Expansion Layer。这一层用来增加 channel 个数，即升维。它也是采用了 1x1 的卷积。具体增加几倍是网络的一个超参数，默认为 6 。它做了和 Projection Layer 相反的操作。Expansion 和 Projection 配合，让这个 block 的输入和输出都是低维的 tensor，而中间做卷积的部分维度更高。 另外就是 v2 中引入了和 ResNet 一致的 residual connection 来复用特征。当然这步只在输入和输出维度一致的情况下才存在。 最后一个改动是，在 projection 1x1 的卷积后面没有跟 ReLU 来当作 non - linearity，而是直接去掉了这层 ReLU，这是因为作者提出在低维度下 ReLU 对特征有破坏作用。 细节解释为什么要去掉 projection 后面的 ReLU？ ReLU 在高维空间上的能有效的增加 non - linearity，而在低维空间上会造成特征损失。这里 MobileNetV2 的文章也给了一个说明。 在上图中，输入时一个二维的螺旋线。首先通过一个随机矩阵 T 将二维的数据变换到更高的维度；然后通过一次高维的 ReLU。最后，通过逆矩阵 T^(-1) 将数据变换回二维。可见在低维度的情况下，特征损失较为严重；而在更高的维度下，ReLU 过后的特征保存的较为完好。 在 projection layer 后面，由于维度从高维降低到了低维，这个时候 ReLU 就会有破坏的作用。因此 v2 中去掉了这部分的 ReLU。 Inverted Residual 是什么意思？ ResNet50 中同样有 1x1 的卷积 bottleneck residual block。但是它是先降维再升维的。在 MobileNet 中，是先升维再降维的。因此命名为 Inverted。 这带来的第一个好处是，提升了维度使得卷积操作后跟随的 ReLU 不易出现“神经元死亡”的情况（参考上面）；第二个好处是作者验证得到这样做能占用更少的内存（shortcut between bottlenecks v.s. shortcut between expansions）。 为什么要 Expansion ？ 一般随着网络层数加深，通道数会逐渐变多，而 feature map 的尺寸逐渐变小。MobileNet v1 和 v2 也不例外。通过引入了 bottleneck，我们发现 v2 种的 tensor 尺寸比 v1 中的更小（7x7x320 vs 7x7x1024）。更小的 tensor 会更加节约计算资源。但是如果 channel 数过少，卷积操作不能很好的提取出足够的信息。因此 Expansion Layer 被用来增加 channel 数。由于是通过 1x1 的卷积实现的，因此是网络通过训练，学习到的如何 uncompress data。 References[1] MobileNetV2 原文 https://arxiv.org/pdf/1801.04381.pdf [2] https://machinethink.net/blog/mobilenet-v2/ [3] https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69 [4] https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c [5] https://perper.site/2019/03/04/MobileNet-V2-详解/ [6] https://zhuanlan.zhihu.com/p/67872001 [7] https://www.jianshu.com/p/2eec2b8b885b [8] 知乎讨论 https://www.zhihu.com/question/265709710 [9] ResNet 结构梳理 https://zhuanlan.zhihu.com/p/54289848","link":"/2021/01/08/understand-mobilenetv2/"},{"title":"VSCode sigset_t is Undefined","text":"VSCode sigset_t is Undefined在使用 VSCode 写 signal 相关的代码时，IntelliSense 提示 sigset_t is undefined。 如下图所示： sigset_t 并不在 C99 / C11 standard 里。但是它是包含在 POSIX standard 里的。因此为了避免出现此错误提示，我们需要更改 VSCode C/C++ Extension 的配置。 Ctrl-Shift-P 呼出菜单，选择 C/C++ Edit Configurations (JSON)，将其中的 cStandard 从默认的 c11 改成 gnu99 即可。","link":"/2021/11/13/vscode-sigset/"},{"title":"Time-Frequency Uncertainty","text":"Time-Frequency UncertaintyThe Uncertainty Principle is first proposed by Heisenberg to describe that you can’t precisely measure the position and momentum of a particle at the same time. This principle is well known in quantum physics. It then became a very “general” idea, and can also be used in the field of signal processing. In this article, I will describe the time-frequency uncertainty principle theorem and then show the proof. If the pdf preview is not working, click here to view.","link":"/2021/10/20/time-freq-uncertainty/"},{"title":"A crazy way to dump dynamic views with UIAutomator","text":"A crazy way to dump dynamic views with UIAutomatorDisclaimer: I’m not an expert in Android. This method is not stable. DO NOT use it for production. UIAutomator 是 Android 内置的自动化工具，我们可以用 uiautomator dump 命令来 dump 当前 activity 的 view。 为什么不用其他工具？UIAutomator 似乎会利用 Accessibility 的 view 信息，比起其他工具，dump 出来的 view 会更简洁（一些无关的 view 好像不会被 dump 出来）。其他的工具会事无巨细地把所有 view 都 dump 出来。 缺点如果当前界面有动态试图（视频、动画、甚至是时钟），UIAutomator 就无法工作。这是因为它会先等待主线程进入 idle 状态。如果有持续的动态试图，主线程永远不会进入 idle，那么最终会导致超时报错 (Could not get idle state)。 如果我们去看 Android 源码，可以看到这行代码是导致问题的关键：1uiAutomation.waitForIdle(1000, 1000 * 10);超时导致抛出异常。 解决思路如果能把这行代码去掉，那么就不会抛出异常了。缺点是 UIAutomator 可能拿到错误的 UI 状态，但是这里我并不在意 UI 状态 100% 准确。 我们固然可以重新编译 AOSP，但是这个工作量太大了。有没有更简单的方式去掉这行代码呢？ 可以发现，uiautomator 命令在 /system/bin 路径下，它本身是一个 shell 脚本，实际调用的是 /system/framework/uiautomator.jar。首先通过 adb pull 命令把这个 jar 文件拷贝到宿主机。之后，通过 ByteCode Viewer 工具，我们可以反汇编 Jar 的字节码并找到函数调用的汇编代码。123const-wide/16 v6, 1000const-wide/16 v8, 10000invoke-virtual { v3, v6, v7, v8, v9 }, Landroid/app/UiAutomation;-&gt;waitForIdle(JJ)V点击 View-&gt;Panel-&gt;Smali，选中 Edit 功能，我们可以手动删掉函数调用的汇编，并重新编译成可执行文件。在我的电脑上，直接编译成 Android dex 可执行文件会 crash。因此我们先编译成 jar 文件，之后再用 Android Studio 的 d8 命令（原来 dx 命令的升级版）手动将 jar 文件转换成 dex 文件，再手动和其他文件一起打包成 uiautomator.jar。 我们可以通过 adb push 命令将 jar 拷贝回 /system 路径下。然而 system 默认是只读的，需要 remount 成读写权限。 启动模拟器时增加参数，表示 system 可写，并强制冷启动。不是冷启动的话 系统可能无法正常 boot：1234/Users/luyuan/Library/Android/sdk/emulator/emulator -writable-system @Pixel_3a_API_34_extension_level_7_arm64-v8a -no-snapshot-loadadb rootadb remount 这样，我们可以强制绕过等待 idle 的逻辑，UIAutomator 有一定概率可以 dump 出 view。但是也有一定概率会报错 root node 为空，非常不稳定。不建议再生产环境中使用。","link":"/2023/11/27/uiautomator-dynamic/"},{"title":"What is Gumbel Softmax?","text":"What is Gumbel Softmax?看了几篇博客，都对 Gumbel Softmax 讲解的不是很到位。这里重新总结了一下，希望从“要解决什么问题”的角度把这个 trick 梳理清楚。 随机模型的困难：采样我们常见的深度学习模型是确定的（deterministic）模型，比如一个用于区分猫和狗的 CNN 网络。当网络的参数固定时，同样的输入总是会有同样的输出。然而还有一些场景是需要随机的（stochastic）模型的。这样的模型是有不确定性的，即同样的输入、同样的参数，也会有不一样的输出。 比如在强化学习中训练一个游戏 AI。这个 AI 应当是以一定的概率往前后左右四个方向行走的。假如经过计算，四个方向运动的概率分别是（0.9, 0.05, 0.05, 0.0），那么 AI 不应该永远朝着概率最大的第一个方向运动。在训练过程中，它也应该有 0.05 的概率真的走向第二个方向。又比如在 Learning in the Frequency Domain 论文中，频率通道的动态选择是有一定概率的。即 10 次中可能有 8 次选择了 A 通道，而不是说当概率 &gt; 0.5 时就永远选择 A 通道。 也就是说，我们的模型在训练过程中需要以一定的概率分布进行采样。即给定一个概率分布函数，需要有一个算法来产生各种各样的样本值。一个简单但常用的采样算法是拒绝采样（reject sampling）。 途中，蓝色的线代表了一个我们的目标概率分布函数。这个函数很复杂，因此我们用一个简单的均匀分布（绿色）来把它包围起来。这个时候我们先随机选一个样本点（黄色 x），然后再产生一个随机数 u。当 u 的值落在蓝线下方时，我们接受这个样本点；反之则拒绝。这样被我们接受的样本点就符合目标概率分布了。 刚刚提到产生一个随机数 —— 也就是要对均匀分布进行采样。均匀分布的采样可以通过“线性同余发生器”来实现。这是一种伪随机数发生器。 听起来比较简单，但是在深度学习中，这会带来一个严重的问题：采样的过程显然是不可导的！我们的神经网络没有办法通过反向传播来更新参数了。 Re-parameterization解决采样问题不可导的一个 trick 是重参数化：re-parameterization。以高斯分布为例，假如我们需要对一个 N(mu, sigma) 采样，我们可以把它转化成对 N(0, 1) 采样，然后再缩放。这样就相当于改变了采样的先后顺序，把真正的采样过程移到计算图的边缘，就不影响对参数 mu、sigma 和 x 的导数计算了。 对于反向传播来说，只把采样产生的样本值当成一个确定的常数就可以了。这个 trick 典型的应用例子是 VAE。 Gumbel Max Trick在 Learning in the Frequency Domain 中，动态的通道选择就需要从伯努利过程中采样。针对离散的情况，我们同样需要利用 re-parameterization 来计算导数，就像在上述的连续情形中一样。 我们可以用 Gumbel Max 的方式来实现采样： 假设我们有三个事件的概率，分别为 a1，a2 和 a3。我们希望采样后的输出是一个 one-hot 的编码，例如 [0, 1, 0]，或者 [0, 0, 1]。当然这个输出是要符合 (a1, a2, a3) 的概率分布的。我们引入 Gumbel noise，让噪声和 log(a) 相加，之后做 argmax 得到 one-hot 编码。这个过程和上一节的高斯分布的做法一致，都是把采样的操作放到了计算图的边缘节点，这样就不影响其他分支的导数计算。 计算公式如下：$$z = OneHot(\\mathop{argmax}\\limits_{i}[g_i + log\\alpha_i])$$ Gumbel Noise什么是 Gumbel Noise 呢？Gumbel 分布是一种极值分布。假如说每天测量 100 次心率（假设心率服从正态分布），记录最大的心率。多次观察，那么这个最大的心率就服从 Gumbel 分布。 服从 Gumbel 分布的随机变量可以通过以下公式计算：$$G_i = -log(-log(\\epsilon_i))$$$$\\epsilon_i \\sim Uniform(0, 1)$$ 为什么选择选择 Gumbel Noise 呢？数学上可以证明对每个值加上一个独立标准 Gumbel 噪声后，取最大值，得到的概率密度和 softmax 一致。通过实验，也可以验证如果使用其他的噪声，概率会失真。具体的实验结果和数学证明可以参考这篇文章，证明过程还比较复杂。 Gumbel Softmax上述的 Gumbel Max Trick 以 re-parameterization 的方式解决了采样不可导的问题。但是它又新引入了一个 argmax 的操作，而 argmax 同样是不可导的。解决办法是引入 softmax，来模拟 argmax 运算。$$y_i = \\frac{exp(x_k / \\tau)}{\\Sigma_{i=1}^nexp(x_i / \\tau)}$$ 这里的 $\\tau$ 代表温度，是一个超参数。它用来控制随机性，就像物理学中，温度越高，例子的运动越剧烈，随机性越大一样。 当温度较小时，就非常接近 argmax。当温度较大，也就更接近于均匀分布。 总结 某些情况下我们需要引入随机性，比如动态通道选择中，通道要以一定的概率被选择 / 不选择。而采样过程不可导，无法应用反向传播。 通过 Gumbel Max Trick 这一 re-paramerization 的方式，我们可以绕过采样的步骤。但是又引入了新的不可导运算 argmax。 通过 Gumbel Softmax 可以模拟 argmax 运算，从而解决了导数计算的问题。 References https://arxiv.org/pdf/1611.01144.pdf https://sassafras13.github.io/GumbelSoftmax/ http://amid.fish/humble-gumbel https://www.cnblogs.com/initial-h/p/9468974.html https://neptune.ai/blog/gumbel-softmax-loss-function-guide-how-to-implement-it-in-pytorch","link":"/2021/05/12/what-is-gumbel-softmax/"},{"title":"Faster WarpPolar with PyTorch and GPU","text":"Faster WarpPolar with PyTorch and GPU一般我们都会在笛卡尔坐标系下处理图像。但有的时候，将图片转换到极坐标系下会更有优势。有些研究显示极坐标系下有更好的 rotation invariance 等特性。在我最近的项目中，图像目标区域是一个圆环。直接处理会在圆环内外处理很多无用的像素，白白浪费计算性能。因此我想先把图像变换到极坐标系下，这样目标区域就从圆环变为更好处理的矩形区域。之后再把这个矩形区域交给神经网络进行运算。 Polar CoordinateCartesian 到 Polar 坐标转换的核心是从 (x, y) 到距离和夹角 (rho, phi) 的映射。当然反变换就是反向的映射。如果不显示指定，OpenCV 默认的输出图像宽度为最大半径（maxRadius），高度为 PI maxRadius。显然圆的周长应该为 2 PI * radius，因此实际上内圈是被拉长了的，而外圈是被压缩了的。取这个高度是一个平均值。 OpenCV warpPolar Usage通过 OpenCV 做极坐标的变换是很容易的。可以参考官方文档了解具体参数的含义。 Cartesian to Polar： 1polar_img = cv2.warpPolar(img, (0, 0), (512, 512), 512, cv2.WARP_POLAR_LINEAR + cv2.INTER_LINEAR) 这里我的图像分辨率为 1024x1024。传入 (0, 0) 的目标图像大小表示不显示指定，使用默认值。指定坐标系原点为图像中心，半径为 512。采用线性映射。这样变换后的图像大小为 512x1608。 Polar to Cartesian： 1recon_img = cv2.warpPolar(polar_img, (1024, 1024), (512, 512), 512, cv2.WARP_POLAR_LINEAR + cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP) 这里需要显示指定目标图像的尺寸为 1024x1024。通过给 flag 拼接一个 WARP_INVERSE_MAP 的 mask 表示这里在做反变换。 Move to PyTorch在我的电脑上（i7-9700K），做极坐标变换的速度大约是 200 FPS。这速度并不快。怎么样去提速呢？首先，在我的应用场景中所有的图片都在做同样的变换。但是正常调用 OpenCV 的函数，每次都在重复的计算同样的坐标系映射关系，浪费了很大的算力。我相信许多其他的 Deep Learning 应用也是映射关系不变，只有图片在变化。其次，我们可以把图片的映射用 PyTorch tensor 实现，在 GPU 上进行加速。正好后续的模型也需要 tensor。 具体思路为，预先计算映射关系，并把它转换到 GPU tensor 中缓存下来。可惜 OpenCV 并没有直接暴露出坐标映射的接口，但是我们可以参考 OpenCV 的 C++ 源码写出其对应的 Python 版本。注意，由于这里只计算一次，因此我们并不在意这个步骤的速度，因此无需写出 vectorized 的版本。 正变换： 1234567891011121314151617181920212223242526272829303132class CartToPolarTensor(object): def __init__(self, device=torch.device('cuda:0')): self.mapx, self.mapy = self.build_map() self.mapx_tensor = torch.tensor(self.mapx, device=device).unsqueeze(0) self.mapy_tensor = torch.tensor(self.mapy, device=device).unsqueeze(0) def build_map(self, center=(512, 512), max_radius=512): w = max_radius h = np.round(max_radius * np.pi).astype(int) dsize = (h, w) mapx = np.zeros(dsize, dtype=np.float32) mapy = np.zeros(dsize, dtype=np.float32) Kangle = (2 * np.pi) / h rhos = np.zeros((w,)) Kmag = max_radius / w for rho in range(0, w): rhos[rho] = rho * Kmag for phi in range(0, h): KKy = Kangle * phi cp = np.cos(KKy) sp = np.sin(KKy) for rho in range(0, w): x = rhos[rho] * cp + center[1] y = rhos[rho] * sp + center[0] mapx[phi, rho] = x mapy[phi, rho] = y return mapx, mapy 逆变换： 1234567891011121314151617181920212223242526272829303132333435363738class PolarToCartTensor(object): def __init__(self, device=torch.device('cuda:0')): self.mapx, self.mapy = self.build_map() self.mapx_tensor = torch.tensor(self.mapx, device=device).unsqueeze(0) self.mapy_tensor = torch.tensor(self.mapy, device=device).unsqueeze(0) def build_map(self, dsize=(1024, 1024), max_radius=512, center=(512, 512), src_size=(1608, 512)): w = dsize[1] h = dsize[0] angle_border = 1 ssize_w = src_size[1] ssize_h = src_size[0] - 2 * angle_border mapx = np.zeros(dsize, dtype=np.float32) mapy = np.zeros(dsize, dtype=np.float32) Kangle = 2 * np.pi / ssize_h Kmag = max_radius / ssize_w bufx = np.zeros(w, dtype=np.float32) bufy = np.zeros(w, dtype=np.float32) for x in range(0, w): bufx[x] = x - center[1] for y in range(0, h): for x in range(0, w): bufy[x] = y - center[0] bufp, bufa = cv2.cartToPolar(bufx, bufy, angleInDegrees=False) for x in range(0, w): rho = bufp[x] / Kmag phi = bufa[x] / Kangle mapx[y, x] = rho mapy[y, x] = phi + angle_border return mapx, mapy 通过类属性进行缓存，这样我们只在初始化时预先计算一次映射关系，之后可以全部复用已有的结果。映射关系的计算和 OpenCV 的 C++ 版本完全一致（这里没有考虑 semi-log 的情形，但是很容易补充）。计算完成后，OpenCV 使用了 remap 函数来完成映射。 虽然 PyTorch 本身没有提供 remap 操作，但是第三方库 Kornia 使用 grid_sample 做了实现。import kornia 之后，在每次调用时只需要执行 remap 就可以了： 123def __call__(self, img_tensor): polar = kornia.geometry.transform.remap(img_tensor, self.mapx_tensor, self.mapy_tensor) return polar Speed Test读入图像后，分别用 OpenCV 和我们自己实现的 PyTorch 版本执行 1000 次极坐标变换，耗时如下： Method Time (s) OpenCV (CPU, i7-9700K) 3.513 PyTorch (GPU, RTX 3090) 0.203 所需时间仅为原来的 5.8%，提升很大。更重要的是，在我实际的应用场景下 CPU 的负载会很重。通过把更多的操作转移到 GPU 上，实际的提升应该会更显著。","link":"/2022/12/23/torch-polar-coord/"},{"title":"动态规划法","text":"动态规划法最长公共子序列题目： 求两个字符串 X 和 Y 的最长公共子序列长度。例如：”abcbdab” 和 “bdcaba” 的最长公共子序列之一为 “bcba”，故应输出 4。 思路： 利用动态规划法，在二维数组 c[m+1][n+1] 中保存 $X_i$ 与 $Y_j$ 的最长公共子序列（LCS）的长度，其中 m 和 n 分别代表 X 和 Y 的长度。求解 c 的规则如下： 如果 X[i] == Y[j]，那么 c[i][j] = c[i-1][j-1] + 1。试想：abcd 和 abcEd，因为 d == d，我们又知道 abc 和 abcE 的 LCS 长度为 3，所以这两个字符串的 LCS 长度应为 3+1=4。 如果不等，则 c[i][j] = MAX(c[i-1][j], c[i][j-1])。当前的字符不相等，故为上一次计算结果中较大的那个。 i == 0 或 j == 0 时，为 0。 Java 实现： 1234567891011121314151617181920212223int getLongestCommonSubsequenceLength(String X, String Y) { int m = X.length(); int n = Y.length(); X = &quot; &quot; + X; //在字符串前插入空格 Y = &quot; &quot; + Y; int c[][] = new int[m+1][n+1]; for(int i=1; i&lt;=m; i++) { c[i][0] = 0; } for(int i=1; i&lt;=n; i++) { c[0][i] = 0; } for(int i=1; i&lt;=m; i++) { for(int j=1; j&lt;=n; j++) { if(X.charAt(i) == Y.charAt(j)) { c[i][j] = c[i-1][j-1] + 1; } else { c[i][j] = c[i-1][j] &gt; c[i][j-1] ? c[i-1][j] : c[i][j-1]; } } } return c[m][n];} 为什么要在字符串前插入一个无意义的空格，并把数组长度设为 m+1，n+1 呢？因为 0 列和 0 行被我们全部置零用于满足第三条条件了，所以需要多一行、一列的存储空间。当然不存，手动判断也是可以的。 硬币问题题目： 现有面值为 c1, c2, c3, … , cm 元的 m 种硬币，求支付 n 元时所需硬币的最少枚数。各面值的硬币可任意使用 n 次。 思路： 我们用 C[i] 表示第 i 种硬币的面值。用 T[i][j] 表示使用第 0 至第 i 种硬币支付 j 元时的最少硬币数。 那么，给定某个需要支付的金额 j，求解 T[i][j] 时有两个选择，一时选用第 i 种硬币，二是不用第 i 种硬币，我们选这两者之间较小的方案即可。也就是 T[i][j] = min(T[i-1][j], T[i][j-C[i]] + 1) 。 其中，T[i-1][j] 表示不使用，而 T[i][j-C[i]] 表示使用，所以还要多加上使用的这枚硬币。 但是我们没必要给每种面值都记录一个最优枚数，只需要记录最小的就可以了。因此可化简为 T[j] = min(T[j], T[j-C[i]]+1) 。 Java 实现： 1234567891011121314static int getMinNumOfCoin(int[] C, int amout) { int[] T = new int[amout+1]; for(int i=0; i&lt;T.length; i++) { T[i] = Integer.MAX_VALUE; } T[0] = 0; for(int i=0; i&lt;C.length; i++) { //外层循环遍历了使用第i种硬币 / 不使用第i种硬币的可能 我们只记录最小的情况 for(int j=C[i]; j&lt;=amout; j++) { T[j] = Integer.min(T[j], T[j-C[i]]+1); } } return T[amout];} 背包问题题目： 现有价值分别为 $v_i$, 重量分别为 $w_i$ 的 N 块宝石。作为珠宝大盗的你，最多能背动总重量为 W 的背包。请问你这次盗窃的总收益最多为多少？ 思路： 这道问题是每个物品选或不选的组合，因此被称为 0-1 背包问题。我们用 C[i][w] 表示前 i 个物品装入容量为 w 的背包时的总价值的最大值，递增背包容量 w 至最大值来求解。求出 C[i][w] 的值为以下二者中较大的一个： C[i-1][w - 物品i的重量] + 物品i的价值 C[i-1][w] 第一种即选择 i 的情况，第二种为不选择 i 的情况。 Java 实现： 123456789101112131415161718192021222324252627282930313233343536373839404142public class Main { public static void main(String[] args) throws Exception { Item[] items = new Item[5]; items[1] = new Item(4,2); items[2] = new Item(5,2); items[3] = new Item(2,1); items[4] = new Item(8,3); System.out.println(getMaxValue(items, 5)); } static int getMaxValue(Item[] items, int weight) { int[][] C = new int[items.length][weight+1]; for(int i=0; i&lt;C.length; i++) { for(int j=0; j&lt;C[i].length; j++) { C[i][j] = 0; } } for(int i=1; i&lt;items.length; i++) { for(int j=1; j&lt;=weight; j++) { if(items[i].weight &gt; j) { //不可能选择 } else { C[i][j] = Integer.max(C[i-1][j], C[i-1][j-items[i].weight] + items[i].value); } } } return C[items.length-1][weight]; }}class Item { public int value; public int weight; public Item(int value, int weight) { this.value = value; this.weight = weight; }}","link":"/2018/03/25/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%B3%95/"},{"title":"使用PlutoSDR构建简易通信系统","text":"使用 Pluto SDR 构建简易通信系统作者王路远 电子信息与通信学院 通信工程 1502 班 联系方式：e@wangluyuan.cc 同组人：李星 基本情况我们利用 Pluto SDR 设备，在已有的示例程序 bpsk_demo 的基础上修改，实现了可靠的无线通信系统。两台 Pluto 中，一台作为发射机，另一台作为接收机，可在实际的无线信道中，传输任意长度的文字或文件。为了保证可靠传输，分别实现了简化的停止等待协议和滑动窗口协议。 操作系统：Windows 、 Ubuntu （在 Windows 和 Ubuntu 设备上配置 Pluto 比较容易，按照说明文档操作就可以了。但是我们也尝试了许久在 macOS 上操作 Pluto，但没有成功。表现为：Matlab 下启动程序，报错 image not found。如果你成功在 macOS 上运行了相关程序，请联系我！） 准备工作在默认的库文件 /library/matlab/iio_sys_obj_matlab.m 中，函数 function ret = stepImpl(obj, varargin) 中实现了发射和接收数据，即 12345% Implement the data transmit flowwriteData(obj.libiio_data_in_dev, varargin{1}); % Implement the data capture flow[~, data] = readData(obj.libiio_data_out_dev); 我们认为 Pluto 是拥有一个发送存储器和接收存储器，分别读、写这两个存储器完成发送和接收的功能。单个设备自发自收时，在一个函数里既发送又接收是正确的。但是我们现在要实现多台设备的通信，就需要指定发射机和接收机，也就是分别控制发送和接收。于是需要把 stepImpl 函数拆成两个函数：发送数据函数和接收数据函数： 123456789101112%用来发送数据function writeTxData(obj, varargin) %...... writeData(obj.libiio_data_in_dev, varargin{1});end%用来接收数据function ret = readRxData(obj) varargout = cell(1, obj.out_ch_no + length(obj.iio_dev_cfg.mon_ch)); [~, data] = readData(obj.libiio_data_out_dev); %...... ret=varargout;end 在 bpsk_demo 的文件 /code/matlab/BPSK/transmitter/bpsk_tx_func.m 中，原作者设置了要发送的 128*4 = 512 bit 的数据（原注释有错，应是 bit 而不是 byte）。其中前 480 比特是有用信息（60 个字符），后 32 位用作循环冗余校验（CRC）。由于在其他地方设置了收发的数据长度而不好更改，这里我们就用了这 512 比特作为一个数据帧。为了支持任意长度的数据，需要把给定的不足 60 个字符的消息结尾补没有意义的空白字符填充到 60。 1234567function txdata = bpsk_tx_func(msgStr) %...... for k = length(msgStr)+1 :60 msgStr = [msgStr, char(0)]; end %......end 当发送长消息时，以 60 个字符一切割，在接受到之后只需要抹去最后的空白字符就可以恢复原始消息。 停止等待协议我们实现的停止等待协议是这样的： 帧序号有 0 和 1 两种，在两种之间跳变 每帧的前 3 个字符用作帧序号和其他控制信息。即有效信息从 60 个字符减少到 57 个字符 发送方每次发送一个帧，并开始计时 接收方如果收到一个帧，且该帧的序号是自己期望的，则把收到的帧序号返回，并保存相应数据 发送方如果没有到规定的超时时间（这里是 10 秒）： 持续监听返回值 如果收到自己刚刚发送到的帧序号 发送下一帧 否则 继续监听，直到超时 发送方如果超时，重新传输刚才的帧 滑动窗口协议我们实现的滑动窗口协议是这样的： 发送方和接收方窗口大小均设置为 5 为了避免序号回滚时引起歧义，序号的个数设置为窗口大小的 2 倍，即取 1- 10 发送方维护发送窗口，在等待发送的数据数组上滚动 接收方维护接收窗口，判断收到的数据帧号是否落在自己的窗口内，并酌情保存数据 接收方发现有一段序号连续的数据后（顺序正常），滑动自己的窗口，并返回这些连续的数据中的最大序号 发送方一次发完从上次发送的位置到窗口末尾中的所有数据，并开始计时 发送方如果没有到规定的超时时间（这里是 10 秒） 持续监听返回值 如果收到的帧序号落在自己的发送窗口中，且与之前收到的帧序号不一样 滑动窗口并开始发送下一串数据 否则 继续监听，直到超时 发送方如果超时，重新传输窗口中的所有数据 （这是我们在讨论两种协议时打的草稿，当时忘记带草稿纸，只好用抽纸应急:P） 传输文件一旦可靠的传输文字的系统构建完成，传输文件遍不再是问题。我们使用 Base64 编码，将二进制文件编码成字符串，就可以使用之前的通信系统来传输任意的文件了。 需要注意的是，Base64 编码的字符集中不包含空白字符，因此不会与截取末尾空白字符的操作方法产生冲突。 效果发送方将下图成功发送给接收方，该图片大小约为 3 kB。 发送过程中，控制台打印如下消息： 从上图可以看到，发送方先收到 4， 后收到 9，于是发送窗口滑动，一次性发送五条消息。 从上图可以看到，由于全部消息已经发完，即使收到的序号发生改变，窗口也不再继续滑动。最后双方挥手再见，退出程序。平均发送速度为 49.8558 bps。 不足因为时间比较仓促（我要赴美国参加冬令营活动，李星即将去做手术），我们的程序还有一些不足。其中最主要的一点是发送数据的速度比较缓慢。我们分析的原因主要是，Pluto 每次接收数据都需要一定的时间，而发送的速度很快。有可能发送只用了一瞬间，而恰好这段时间接收方还在读取上次的数据，就错过了消息，导致丢包率非常严重，每次都不得不等待超时重传。我们对发送方发送的速度做了延迟，即同样的内容延长发送时间，效果有所改善，但仍不尽人意，两者不能进行很好的同步。目前我们还没找到比较好的解决方案。 当然，改善发送速率也可以降低超时时间（现在的 10 秒是为了方便观察实验现象）；采用多进制的调制方式，如 4PSK、16QAM 等；增大包体积（因为误码率不算太高，而丢包率很高）还有增大滑动窗口大小等。 遇到的困难 在 macOS 上程序一直报错，还没有解决。最后我们使用了 Windows 和 Ubuntu 操作系统。 公开的资料太少，上手不容易。不过在和同学讨论后得到解决，在写协议逻辑的时候还是很愉快的。 发送方频繁接收到自己刚刚发送的数据，而很少收到接收方回复的消息。也就是应该接受的消息完全被淹没在自己发送的消息里了。为了确定是干扰导致的，我们先用同轴线将两台 Pluto 的 Rx 和 Tx 分别连在了一起。有线的状态下，电磁波基本都被屏蔽在导线内，这个问题果然不存在了。确定问题的原因后，我们修改了发送和接收所用的载波频率，发送和接收就不再互相干扰了。) 总结和收获做这样一件事情确实比较有挑战性。主要原因是网上公开的资料太少，无论是官方 Wiki 还是厂家提供的资料，帮助都比较小。再加上之前也没有使用过同类的 SDR 产品，开始确实比较懵。不过后来在自习阅读了厂家提供的示例代码，又和同学讨论过后，逐渐就能开始编写逻辑了。 我和李星同学大概花了一天半的时间来实际的编写逻辑代码，时间确实比较紧张，不过收获也很多。从头到位设计可靠传输的协议实在太有意思了。事实上我们在写代码的时候完全没有翻看计算机网络的数据，也基本没有查找什么资料。因为时间过的比较久了，不少协议的细节我们都记不清楚了，于是就自己思考传输的过程中会出现什么差错，讨论解决这些问题的办法。有的时候会突然恍然大悟，想明白为什么前辈要这样设计！通过这次实验，熟悉了 SDR 设备、对通信原理中的理论知识有了一个落地，更是大大增强了对计算机网络的理解。 期待以后还能有机会用 Pluto SDR 做一些更复杂、更有意思的东西。 其他本项目的完整代码托管在了 GitHub 上：https://github.com/BeBeBerr/Pluto-Network 此文章发布在了我的 Blog 上，欢迎查看。","link":"/2018/01/29/%E4%BD%BF%E7%94%A8PlutoSDR%E6%9E%84%E5%BB%BA%E7%AE%80%E6%98%93%E9%80%9A%E4%BF%A1%E7%B3%BB%E7%BB%9F/"},{"title":"用Swift写算法-搜索","text":"用 Swift 写算法——搜索线性搜索简介： 线性搜索是从数组的头开始顺次访问各元素，检查该元素值是否与目标值相等。一旦相等就返回该元素位置并结束搜索。线性搜索算法的效率很低，但适用于任何形式的数据。 Swift 实现： 12345678func linearSearch(array: [Int], key: Int) -&gt; Int? { for (i, each) in array.enumerated() { if each == key { return i } } return nil} 分析： 线性搜索的时间复杂度为 $O(n)$ 。 二分搜索简介： 二分搜索可以利用数据的大小进行高速搜索。每执行一次，搜索的范围都会减半，因此可以在极短的时间内完成搜索，不过需要数据有序。 Swift 实现： 123456789101112131415func binarySearch(array: [Int], key: Int) -&gt; Int? { var leftIndex = 0 var rightIndex = array.count - 1 while leftIndex &lt;= rightIndex { let midIndex = (rightIndex + leftIndex) / 2 if array[midIndex] &gt; key { rightIndex = midIndex - 1 } else if array[midIndex] &lt; key { leftIndex = midIndex + 1 } else { return midIndex } } return nil} 分析： 二分查找法每次搜索范围都会减半，在最坏的情况下大概需要 $log_2n$ 次，时间复杂度为 $O(logn)$ 。 在最坏的情况下，对比线性搜索和二分搜索： 元素数 线性搜索次数 二分搜索次数 100 100 7 10000 10000 14 1000000 1000000 20 这里默认传入的数组有序。在一般情况下，可以考虑先对数组排序，然后进行二分搜索。不过，考虑到数据的体积，一般需要使用高等排序法。 散列法简介： 在散列法中，各元素存储的位置由散列函数决定。这种算法只需要将元素的关键字代入散列函数，就可以计算出它的位置。对特定形式的数据有极高的搜索效率。 分析： 散列法的要点在于散列函数的选取和冲突时的处理方法。如果忽略冲突的情况，时间复杂度仅为 $O(1)$。","link":"/2017/07/12/%E7%94%A8Swift%E5%86%99%E7%AE%97%E6%B3%95-%E6%90%9C%E7%B4%A2/"},{"title":"用Swift写算法-初等排序","text":"用 Swift 写算法——初等排序插入排序法简介： 就像打扑克时整理牌的顺序一样，将牌一张张地抽出来，再插入到已经排列好的牌的适当位置中。重复这个动作直到插入最后一张牌。 Swift 实现： 1234567891011func insertionSort(array: inout [Int]) { for i in 1..&lt;array.count { let v = array[i] var j = i - 1 while j &gt;= 0 &amp;&amp; array[j] &gt; v { array[j + 1] = array[j] j -= 1 } array[j + 1] = v }} 分析： 我们从第二个元素开始，往后遍历数组。这个元素左边的序列是已排序的；右边是未排序的。我们在已排序的部分中，从大的元素向小的元素滑动，直到遇到小于当前元素的位置。也就是说，这个位置左边（含这个位置）的元素都小于当前元素；右边都大于当前元素。在滑动的过程中，所有遇到的元素都往后挪动一位以腾出插入的空间（第一次滑动当前元素就被覆盖掉了）。 在插入排序中，不相邻的元素不会交换位置，因此是稳定的。在最坏的情况下，每 i 个循环都需要移动数组元素 i 次，总共需要：$$1+2+3+\\cdots+(N-1) = \\frac{N\\times(N-1)}{2}$$故时间复杂度是 $O(n^2)$。 如果输入已经是升序排列，那么插入排序法只需要比较而不用移动，故可以快速地完成相对有序数列的排序。 冒泡排序法简介： 冒泡排序法让数组元素像水中的气泡一样逐渐上浮，而达到排序的目的。有些人也把冒泡排序法称为”沉底排序法“。 Swift 实现： 12345678910111213141516func bubbleSort(array: inout [Int]) { var flag = true while flag { flag = false var i = array.count - 1 while i &gt; 0 { if array[i - 1] &gt; array[i] { let temp = array[i] array[i] = array[i - 1] array[i - 1] = temp flag = true } i -= 1 } }} 分析： 每次循环中，都从右往左遍历，遇到顺序相反的元素就交换二者的位置。这样，每次都把最小的泡泡推到最左边。重复这个操作知道所有的元素都符合要求为止。可以看到，这样在数组左边就形成了一个有序的子列，每次循环有序子列的元素个数就增加一个，且没有比这个子列里的元素更小的元素。因此我们可以利用这一点，去减少循环的次数（循环到有序子列尾就可以直接进行下次循环），这也被称为“改进的冒泡排序法”。 冒泡排序法只对相邻的两个反序元素进行交换，因此也是稳定的。需要注意，如果把判断条件改为“大于等于（小于等于）”，则算法会失去稳定性。 在最坏的情况下，冒泡排序法会对相邻的元素（未排序部分）进行以下次比较：$$(N-1)+(N-2)+\\cdots+1=\\frac{N^2-N}{2}$$因此时间复杂度是 $O(n^2)$。 选择排序法简介： 选择排序法在每个计算步骤中，选择出最小的数放到前面，进而完成排序。 Swift 实现： 12345678910111213func selectionSort(array: inout [Int]) { for i in 0..&lt;array.count { var minj = i for j in i..&lt;array.count { if array[j] &lt; array[minj] { minj = j } } let temp = array[i] array[i] = array[minj] array[minj] = temp }} 分析： 在循环的过程中，minj 的值会不断地被后面的（更小时元素的下标）覆盖，这样在每次排序中，不相邻的元素会被交换，因此是不稳定的算法。 选择排序法需要经过以下次比较：$$(N-1)+(N-2)+\\cdots+1=\\frac{N^2-N}{2}$$因此时间复杂度是 $O(n^2)$。 希尔排序法简介： 希尔排序法循环地调用间隔为 g 的插入排序法，每次缩小 g 的范围进而完成排序。 Swift 实现 123456789101112131415161718func shellSort(array: inout [Int]) { let G = [4,3,1] for each in G { insertionSort(array: &amp;array, g: each) }}func insertionSort(array: inout [Int], g: Int) { for i in g..&lt;array.count { var v = array[i] var j = i - g while j &gt;= 0 &amp;&amp; array[j] &gt; v { array[j + g] = array[j] j = j - g } array[j + g] = v }} 分析： 前面已经分析过，插入排序法能较为快速地对比较有序的数组进行排序。希尔排序法就是发挥了插入排序法的优势，让数组一步步地变得越来越有序。不断地缩小插入排序法的间隔（间隔越大，插入排序法所需要交互的次数就越小，也就越快完成）直到间隔为 1。间隔为 1 时（退化成普通的插入排序法），数组已经基本有序了，因此效率较高。 每次的间隔 g 的取值对希尔排序法的效率至关重要。对于如何选择 G，人们已经进行了许多研究。例如：当 $g = 1,4,13,40,121\\cdots$ 时，即 $g_{n+1} = 3g_n+1$ 时，算法的复杂度基本维持在 $O(n^{1.25})$。","link":"/2017/07/11/%E7%94%A8Swift%E5%86%99%E7%AE%97%E6%B3%95-%E5%88%9D%E7%AD%89%E6%8E%92%E5%BA%8F/"},{"title":"用Swift写算法-递归和分治法","text":"用 Swift 写算法——递归和分治法分治法简介将问题分解，通过求解局部性的小问题来解决原本的问题，这种技巧叫分治法。实现分治法需要使用递归，其主要步骤如下： 将问题分割成局部问题 （Divide） 递归地求解局部问题 （Slove） 将局部问题的解整合，解决原问题 （Conquer） 应用-穷举搜索题目： 现有数列 A 和 整数 m。请编写一程序，判断 A 中任意几个元素相加是否能得到 m。A 中每个数只能用一次。 Swift 实现： 12345678910111213let array = [1,5,7,10,21]func solve(i: Int, m: Int) -&gt; Bool { if m == 0 { return true } if i &gt;= array.count { return false } let res = solve(i: i + 1, m: m) || solve(i: i + 1, m: m - array[i]) return res}solve(i: 0, m: 8) 分析： 我们把问题分解成两个更小的局部问题：选择当前元素／不选择当前元素的情况下搜索。如此递归下去，便能解决原问题。 检查所有排列组合需要使用两个递归函数，时间复杂度为 $O(2^n)$ ，因此 n 不能太大。 应用-科赫曲线题目： 编写一程序，输入整数 n，输出科赫曲线的顶点坐标。 科赫曲线是一种广为人知的不规则碎片形。该图形具有递归结构，可以通过如下方法画出： 给定线段三等分 以三等分点作出正三角形 对新产生的线段重复上述操作 设端点为（0，0）和（100，0） Swift 实现： 1234567891011121314151617func koch(deep:Int, a:(Double, Double), b:(Double, Double)) { if deep == 0 { return } let left = ((b.0 - a.0)/3.0 + a.0, (b.1 - a.1)/3.0 + a.1) let right = ((a.0 + 2.0 * b.0)/3.0, (a.1 + 2.0*b.1)/3.0) let mid = ((right.0 - left.0)*cos(1.0/3.0*Double.pi) - (right.1 - left.1)*sin(1.0/3.0*Double.pi) + left.0, (right.0 - left.0)*sin(1.0/3.0*Double.pi) - (right.1 - left.1)*cos(1.0/3.0*Double.pi) + left.1) koch(deep: deep - 1, a: a, b: left) print(left) koch(deep: deep - 1, a: left, b: mid) print(mid) koch(deep: deep - 1, a: mid, b: right) print(right) koch(deep: deep - 1, a: right, b: b)}koch(deep: 2, a: (0,0), b: (100,0)) 分析： 每次都计算出左、中、右三个点的坐标，然后逐层递归。把最原始的问题化成端点到左，左到中，中到右，右到端点这些规模较小的子问题，同时，递归层级递减，直到 0。","link":"/2017/07/14/%E7%94%A8Swift%E5%86%99%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92%E5%92%8C%E5%88%86%E6%B2%BB%E6%B3%95/"},{"title":"What are Dynamic Libraries ?","text":"What are Dynamic Libraries ?Ref: Overview of Dynamic Libraries 动态库会在使用时动态地加载到内存中。在 Linux 上，动态库以 .so 结尾，在 macOS 上是 .dylib，而在 Windows 上是 .dll。 Usage以 macOS 为例，首先新建两个文件 lib.c 和 lib.h。 12//lib.hvoid lib_print(); 12345//lib.c#include &lt;stdio.h&gt;void lib_print() { printf(&quot;Hello World from lib!&quot;);} 然后编译出 .dylib 文件： gcc -dynamiclib lib.c -o libtest.dylib 编写 main.c 文件来验证一下： 12345#include &quot;lib.h&quot;int main() { lib_print(); return 0;} 编译的时候指定要链接的动态库： gcc main.c -L. -ltest -o main 标准的动态库都以 lib 开头，如这里的 libtest.dylib 。如果不以 lib 开头，linker 就找不到它。 Load on Runtime在编译时制定要链接的动态库，这种用法看起来和静态库差不多。但动态库之所以动态的一个原因正是它可以在运行时动态地加载。 修改 main.c 文件： 1234567891011#include &lt;dlfcn.h&gt;#include &quot;lib.h&quot;typedef void(*Func)();int main() { void *lib_handle = dlopen(&quot;libtest.dylib&quot;, RTLD_LAZY); Func lib_func = dlsym(lib_handle, &quot;lib_print&quot;); lib_func(); return 0;} 其中，dlopen 用于装载和链接一个动态库，而 dlsym 会返回 symbol 的地址。 .dylib vs .a 动态链接会降低包体积 将静态的事情放在动态来做，会拖慢程序的运行速度。但是 Apple 提供了 shared library cache 来做缓存。 即使有缓存，仍需要查找 Procedure Linkage Table (PLT) 表。这个表记录了之前已经调用过的函数的地址。 Function Interposingdyld 提供了一般的 loader 没有的功能：函数拦截。这样我们可以轻松地 Hook 其他动态库中的函数（比如系统调用）。而在 Linux 中，Hook 系统调用就麻烦些。 出自 Mac OS X and iOS Internals: To the Apple’s Core 中的替换掉 malloc 和 free 的例子在互联网上已经泛滥，这里就不再赘述。在这个例子中，我们 Hook 掉之前 lib.c 重的 lib_print 函数。 新建一个 libhook.c 文件。 12345678910111213//libhook.c#include &lt;stdio.h&gt;#include &quot;lib.h&quot;#define DYLD_INTERPOSE(_replacment,_replacee) \\ __attribute__((used)) static struct{ const void* replacment; const void* replacee; } _interpose_##_replacee \\ __attribute__ ((section (&quot;__DATA,__interpose&quot;))) = { (const void*)(unsigned long)&amp;_replacment, (const void*)(unsigned long)&amp;_replacee };void another_print() { printf(&quot;www.wangluyuan.cc&quot;);}DYLD_INTERPOSE(another_print, lib_print) 中间的宏定义来源于 /include/mach-o/dyld-interposing.h 中。我们把它编译成一个动态库： gcc -dynamiclib libhook.c -o libhook.dylib -L. -ltest 然后，通过 dyld 的环境变量，将这个动态库强制插入已经编译好的 main 程序中： DYLD_INSERT_LIBRARIES=libhook.dylib ./main 123456//main.c#include &quot;lib.h&quot;int main() { lib_print(); return 0;} 我们会发现 lib_print 的实现已经被替换了，而 main 对此毫不知情，表示很无辜。","link":"/2019/09/18/what-are-dynamic-libraries/"},{"title":"用Swift写算法-高等排序","text":"用 Swift 写算法——高等排序面对大量的数据，使用复杂度为 $O(n^2)$ 的初等排序法将失去实用价值，为此我们必须引入速度更快的高等排序算法。 归并排序Swift 实现： 12345678910111213141516171819202122232425262728293031323334func mergeSort(array: inout [Int], left: Int, right: Int) { if left + 1 &lt; right { let mid = (left + right) / 2 mergeSort(array: &amp;array, left: left, right: mid) mergeSort(array: &amp;array, left: mid, right: right) merge(array: &amp;array, left: left, mid: mid, right: right) }}func merge(array: inout [Int], left: Int, mid: Int, right: Int) { let n1 = mid - left let n2 = right - mid var L = [Int]() var R = [Int]() for i in 0..&lt;n1 { L.append(array[left + i]) } for i in 0..&lt;n2 { R.append(array[mid + i]) } L.append(Int.max) R.append(Int.max) var i = 0 var j = 0 for k in left..&lt;right { if L[i] &lt;= R[j] { array[k] = L[i] i += 1 } else { array[k] = R[j] j += 1 } }} 分析： 借助分治法的思路，我们将解决问题的方案分为以下步骤： 分割：将数组对半分成两个部分 求解：对两个局部数组分别执行归并排序 整合：将排序完毕的局部数组整合成一个数组 函数 merge() 是算法的基础。它的作用是将两个分别有序的数组，合并成一个整体有序的数组。为了方便实现，在两个数组末端各插入一个“无穷大”的数。由于两个小数组都已经有序，所以合并只需要分别依次比较大小，然后先行往大数组中插入较小的数就可以了。复杂度为 $O(n1+n2)$ 。 在归并排序法中，我们递归地对数组进行分割，直到仅剩下一个元素。此时，只一个元素的数组是有序的。在一个元素的状态下，由于不满足条件，函数开始返回。返回时，调用了 merge() ，对有序的数组进行拼接。这样，经过不断的拼接，最终整体有序。 一般来讲，n 个数需要递归 $O(logn)$ 层，每层执行归并又需要线性的复杂度，因此归并排序的时间复杂度为 $O(nlogn)$。 归并排序法不会交换两个不相邻的元素位置，在合并时，只需要保证前半部分的优先级高于后半部分，就能保持稳定。 归并排序高速、稳定，但是在递归的过程中需要占用递归所需的内存空间。 tips：把控递归的过程，一个重要的方法是画出递归的层次图。画图时，牢牢记住同样层次的递归画在同样的深度下就可以了。 快速排序Swift 实现： 123456789101112131415161718192021222324func quickSort(array: inout [Int], p: Int, r: Int) { if p &lt; r { let q = partition(array: &amp;array, p: p, r: r) quickSort(array: &amp;array, p: p, r: q-1) quickSort(array: &amp;array, p: q+1, r: r) }}func partition(array: inout [Int], p: Int, r: Int) -&gt; Int { let x = array[r] var i = p - 1 for j in p..&lt;r { if array[j] &lt;= x { i += 1 let temp = array[j] array[j] = array[i] array[i] = temp } } let temp = array[r] array[r] = array[i+1] array[i+1] = temp return i+1} 分析： 快速排序的核心是 partition() 函数，它的作用是将数组 array[p...r] 进行分割。使得前半部分的元素均小于等于某个元素 array[q] ，后半部分的元素均大于 array[q] ，并返回下标 q。 在快速排序法中，通过分割函数讲数组一分为二，之后分别对前后两部分再次进行分割。不断地分割下去，最终数组会趋于有序。 如果快速排序在分割的过程中恰好能选择到中间值，那么效率将达到最高。一般而言快速排序的平局复杂度为 $O(nlogn)$ ，是多数情况下最高效的排序算法。在这个实现中，分割寒暑选择的基准数是一个固定的值，所以在有些情况下效率会很低（比如数组已经有序）。我们可以将其改为随机选择，或者抽样平均。 快速排序在分割的过程中会交换不相邻的元素，因此是不稳定的排序算法。但是它除了占用递归的内存，不需要开辟额外的存储空间，因此是一种内部排序（原地排序）算法。 计数排序（桶排序）Swift 实现： 123456789101112131415161718192021222324252627func countingSort(A: [Int], k: Int) -&gt; [Int] { var C = [Int]() for i in 0..&lt;k { C.append(0) } for j in 0..&lt;A.count { C[A[j]] += 1 } for i in 0..&lt;k { if i &gt; 0 { C[i] += C[i-1] } } var B = A var j = A.count - 1 while j &gt;= 0 { B[C[A[j]] - 1] = A[j] C[A[j]] -= 1 j -= 1 } return B} 分析： 计数排序的特点是使用了一个计数数组 C（桶）。它统计各元素出现的次数，然后再求出各元素的累积和。因此 C[x] 的值代表 A 中小于等于 x 的元素个数，借此我们就得到了排序后各元素应出现的位置。 从末尾开始选择，计数排序就是稳定的。计数排序的时间复杂度仅为 $O(n+k)$ ，线性。但是它不仅需要额外的内存空间，也需要保证 A 中元素非负，要求比较高。","link":"/2017/08/01/%E7%94%A8Swift%E5%86%99%E7%AE%97%E6%B3%95-%E9%AB%98%E7%AD%89%E6%8E%92%E5%BA%8F/"},{"title":"在macOS下安装gem5模拟器","text":"在 macOS 下安装 gem5 模拟器Gem5 是一款 CPU 模拟器，一般用于计算机体系架构的研究工作。Gem5 可以用来模拟多种 CPU 架构，如 Alpha，ARM，SPARC，MIPS，当然还有x86。它同时支持 Linux / macOS 系统。 依赖以下为必要的依赖： g++ Python 2.7 SCons 这是一个 build 管理工具，类似于 make zlib 这是一个数据压缩库。如果已经安装了 Xcode 命令行工具就已经包含了。如果没有，运行 xcode-select --install 安装 Xcode 命令行工具。 GNU m4 宏处理器 以下为推荐安装的依赖： protobuf pydot 在 Mac 下，使用 homebrew 安装这些依赖较为简单。基本上 brew install &lt;name&gt; 就可以搞定了。 下载源代码Gem5 模拟器开放了源代码，且需要我们自己编译。通过 Git 把源码下载下来： 1git clone https://gem5.googlesource.com/public/gem5 当然也可以使用其他的版本控制工具下载。 编译Gem5 使用 SCons 作为 build 管理工具。用法是 build/&lt;config&gt;/&lt;binary&gt; 。Gem5 提供了多种版本，比如： debug opt prof perf fast 一般常用的是 opt 版本，这是带 debugging 和优化的版本。prof 和 perf 版本提供了性能分析支持，不过一般不常用。而且，编译 prof 版本可以成功，但是运行时会抛出 __dyld section not supported 异常。这是因为新版的 LLVM 已经不再支持 dyld 了。所以还是建议使用 opt 版本。如果我们需要 x86 架构的话： 1scons build/X86/gem5.opt 编译耗时还是比较久的，需要耐心等待，可以去健个身之类的。 运行最后可以跑一下自带的 hello world 程序，来验证 gem5 是否可用： 1build/X86/gem5.opt configs/example/se.py -c tests/test-progs/hello/bin/x86/linux/hello 如果屏幕上成功打印出 Hello world! 就代表可以正常使用 gem5 模拟器了。","link":"/2019/03/03/%E5%9C%A8macOS%E4%B8%8B%E5%AE%89%E8%A3%85gem5%E6%A8%A1%E6%8B%9F%E5%99%A8/"},{"title":"解决Leak分析闪退问题","text":"解决内存泄露分析导致的App闪退我们在解决应用内存泄露的问题时，常常要用到 Instruments 调试工具的 Leak Check 工具。然而，有时打开 Leak Check，应用就闪退了，导致无法调试。 这似乎是 Xcode 的一个 bug。解决方法很简单：打开 Allocations 分析工具（而不是 Leaks）、点击右上角 + 按钮添加 Leaks 工具就可以了。","link":"/2018/04/27/%E8%A7%A3%E5%86%B3Leak%E5%88%86%E6%9E%90%E9%97%AA%E9%80%80%E9%97%AE%E9%A2%98/"},{"title":"让Xcode控制台打印彩色文字","text":"让 Xcode 控制台打印彩色文字让控制台打印彩色文字可以帮助我们更清晰地调试程序，但 Xcode 本身是不支持这一特性的。我们需要借助 XcodeColors 这款插件。 安装插件去 Github 上找到 XcodeColors 并把项目下载下来。用 Xcode 把工程打开，run 一下 XcodeColors target，插件就会自动被安装好。这个时候重启 Xcode，把 target 切换到 TestXcodeColors，再 run 一次来测试插件是否被成功安装了。这个时候我们会发现并没有打印出来带有颜色的信息，而是打印了许多掺杂了转义字符的字符串。虽然尝试没有成功，但我们得以知道它的原理就是利用转义字符来确定字符串的颜色，所以我们后续的使用中只要向字符串中也添加上这些转义字符，就可以控制打印的颜色了。 让插件可用由于之前曾经出现过有人利用 Xcode 插件添加恶意代码的行为，苹果自 Xcode8 起，就禁用了第三方插件功能。如果一定要用的话，就需要利用一些工具手动打开。这个过程较为繁琐，也可能会导致 Xcode 不安全。不过我们可以用 update_xcode_plugins 工具来简化流程。 首先要升级一下 ruby 环境： 1curl -L https://get.rvm.io | bash -s stable 之后列出最新的 ruby 版本： 1rvm list known 在列表中，可以看到当前最新的 ruby 版本是 2.4.1。接下来安装该版本的 ruby： 1rvm install 2.4.1 成功后，通过 Gem 安装 update_xcode_plugins： 1sudo gem install update_xcode_plugins 之后就可以更新已经安装过的插件了。虽然之前的插件不能运行，但其实是已经安装成功了的： 1update_xcode_plugins 最后，解除掉 Xcode 的签名： 1update_xcode_plugins --unsign 这可能会导致 Xcode 没有办法进行上架操作。需要上架时，应当恢复 Xcode 的签名(未尝试)： 1update_xcode_plugins --restore 这个时候再重启 Xcode，就会询问师傅哦加载插件包，选择 Load Bundle 即可。 使用先打开 XcodeColors： 1setenv(&quot;XcodeColors&quot;, &quot;YES&quot;, 0); 然后可以定义一些宏来帮助我们打印颜色信息： 123#define XCODE_COLORS_ESCAPE @&quot;\\033[&quot;#define XCODE_COLORS_RESET XCODE_COLORS_ESCAPE @&quot;;&quot;#define LogRed(frmt, ...) NSLog((XCODE_COLORS_ESCAPE @&quot;fg255,0,0;&quot; frmt XCODE_COLORS_RESET), ##__VA_ARGS__) 就可以像 NSLog 一样使用了： 1LogRed(@&quot;Sprocket error: %@&quot;, error); 我们可以看到，控制台打印的文字颜色变为红色了。 最后虽然打印带有颜色的信息会非常清晰，但我们可以看到，第一非常麻烦，尤其是上架时还需要把 Xcode 签名恢复。二是这会带来安全风险，之前正是由于 XcodeGhost 等事件才让苹果封杀第三方插件的。总体来说，并不推荐这么做。","link":"/2018/06/15/%E8%AE%A9Xcode%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%89%93%E5%8D%B0%E5%BD%A9%E8%89%B2%E6%96%87%E5%AD%97/"},{"title":"解决Unacceptable Content-Type问题","text":"解决 Unacceptable Content-Type最近在通过 API 的形式访问腾讯云的 COS 服务时，一直请求失败。通过 po error 命令打印出 AFNetworking 回调方法中的 NSError 对象，控制台输出如下： 1234567891011(lldb)po errorError Domain=com.alamofire.error.serialization.response Code=-1016 &quot;Request failed: unacceptable content-type: application/x-www-form-urlencoded&quot; UserInfo={NSLocalizedDescription=Request failed: unacceptable content-type: application/x-www-form-urlencoded, NSErrorFailingURLKey=https://my.url, com.alamofire.serialization.response.error.data=&lt;mydata&gt;, com.alamofire.serialization.response.error.response=&lt;NSHTTPURLResponse: 0x608000037600&gt; { URL: https://my.url } { Status Code: 200, Headers { //...... &quot;Content-Type&quot; = ( &quot;application/x-www-form-urlencoded&quot; ); Server = ( &quot;tencent-cos&quot; ); //......} }} 比较奇怪的一点是，可以看到腾讯云返回的 Status Code 是 200，而且如果查看 error 的 userinfo 信息 error.userInfo[@&quot;com.alamofire.serialization.response.error.data&quot;] ，是可以看到返回的 HTTP Body 信息的。这说明我们的请求是成功了的，毕竟正确的数据已经返回了，只是 AFNetworking 认为失败了。 错误原因根据报错信息，可以看到错误的原因是 unacceptable content-type: application/x-www-form-urlencoded 。也就是腾讯云返回给我们的 content type 并不能被 AFNetworking 解析。而事实上这个接口中，返回的 body 信息本身就是我们需要的二进制数据，并不需要解析。因此要解决这个问题，只需要让 AFNetworking 不认为这是个错误就可以了，思路就是让它认为 application/x-www-form-urlencoded 是可以接受的。 添加 Content-Type最直接的想法，就是我们取出 AFNetworking 支持的 content-type 集合，再把腾讯云的这个值添加进去： 123NSMutableSet *set = [manager.responseSerializer.acceptableContentTypes mutableCopy];[set addObject:@&quot;application/x-www-form-urlencoded&quot;];manager.responseSerializer.acceptableContentTypes = [set copy]; 再次运行，果然不再报错说不接受 content-type 了，而是换了个新的错误： 1Error Domain=NSCocoaErrorDomain Code=3840 &quot;JSON text did not start with array or object and option to allow fragments not set.&quot; UserInfo={NSDebugDescription=JSON text did not start with array or object and option to allow fragments not set.} 新的错误信息提示我们 JSON 格式不正确。但是，腾讯云的这个接口并不会返回结构化的数据，body 里面只是二进制数据。而且，就算要返回被编码的信息，也是 XML 的，并不是 JSON。如果 AFNetworking 以 JSON 的格式去解析，当然会产生错误。 要解决这个问题，靠直觉就不够了，需要看看 AFNetworking 的源码。 寻找问题根源我们跳转到 acceptableContentTypes 的定义中，在 AFURLResponseSerialization.m 文件中，可以看到这样一个函数： 1234567891011121314151617- (BOOL)validateResponse:(NSHTTPURLResponse *)response data:(NSData *)data error:(NSError * __autoreleasing *)error{ BOOL responseIsValid = YES; NSError *validationError = nil; if (response &amp;&amp; [response isKindOfClass:[NSHTTPURLResponse class]]) { if (self.acceptableContentTypes &amp;&amp; ![self.acceptableContentTypes containsObject:[response MIMEType]] &amp;&amp; !([response MIMEType] == nil &amp;&amp; [data length] == 0)) { //...... responseIsValid = NO; } //...... } //...... return responseIsValid;} 可以看到它确实有在判断接收到的 MIME type 是不是被包含在 acceptableContentTypes 里面的。由于我们刚才的添加，这里是可以被验证通过的，之前的思路肯定是正确的。就需要找到哪个地方产生了新问题。 查看 AFHTTPSessionManager 的实现，可以看到这两个初始化方法： 1234567891011121314151617+ (instancetype)manager { return [[[self class] alloc] initWithBaseURL:nil];}- (instancetype)initWithBaseURL:(NSURL *)url sessionConfiguration:(NSURLSessionConfiguration *)configuration{ self = [super initWithSessionConfiguration:configuration]; if (!self) { return nil; } //...... self.requestSerializer = [AFHTTPRequestSerializer serializer]; self.responseSerializer = [AFJSONResponseSerializer serializer]; return self;} 原来，在我们通过 AFHTTPSessionManager *manager = [AFHTTPSessionManager manager]; 方法初始化 manager 的时候，它的 responseSerializer 就被设置成了 AFJSONResponseSerializer 。终于找到了问题的根源！ 当然，这种错误是由于我们的接口返回的不是 JSON 数据导致的。如果你的接口返回的是 JSON，那么问题应该在上一步就已经解决了。 解决问题我们只需要把 manager 的 responseSerializer 换掉就可以了： 1manager.responseSerializer = [[AFHTTPResponseSerializer alloc] init]; 使用 HTTPResponseSerializer，不需要它来解析 JSON。 再次运行程序，就可以成功拿到数据了。 附录腾讯云的 API 在签名时需要做 md5 / SHA-1 / HMAC - SHA1 等加密算法。正确可用的实现不太好找，故将这几种算法代码附在这里： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#import &lt;CommonCrypto/CommonDigest.h&gt;#import &lt;CommonCrypto/CommonHMAC.h&gt;- (NSString*)sha1WithStr :(NSString*)string{ NSString * test =string; const char *cstr = [test cStringUsingEncoding:NSUTF8StringEncoding]; NSData *data = [NSData dataWithBytes:cstr length:test.length]; uint8_t digest[CC_SHA1_DIGEST_LENGTH]; CC_SHA1(data.bytes, (int)data.length, digest); NSMutableString* output = [NSMutableString stringWithCapacity:CC_SHA1_DIGEST_LENGTH * 2]; for(int i = 0; i &lt; CC_SHA1_DIGEST_LENGTH; i++) [output appendFormat:@&quot;%02x&quot;, digest[i]]; return output;}- (NSString *)hmac:(NSString *)plaintext withKey:(NSString *)key{ const char *cKey = [key cStringUsingEncoding:NSASCIIStringEncoding]; const char *cData = [plaintext cStringUsingEncoding:NSASCIIStringEncoding]; unsigned char cHMAC[CC_SHA1_DIGEST_LENGTH]; CCHmac(kCCHmacAlgSHA1, cKey, strlen(cKey), cData, strlen(cData), cHMAC); NSData *HMACData = [NSData dataWithBytes:cHMAC length:sizeof(cHMAC)]; const unsigned char *buffer = (const unsigned char *)[HMACData bytes]; NSMutableString *HMAC = [NSMutableString stringWithCapacity:HMACData.length * 2]; for (int i = 0; i &lt; HMACData.length; ++i){ [HMAC appendFormat:@&quot;%02x&quot;, buffer[i]]; } return HMAC;}- (NSString*)md5WithData:(NSData *)data{ unsigned char result[16]; CC_MD5( data.bytes, (CC_LONG)data.length, result ); // This is the md5 call return [NSString stringWithFormat: @&quot;%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x&quot;, result[0], result[1], result[2], result[3], result[4], result[5], result[6], result[7], result[8], result[9], result[10], result[11], result[12], result[13], result[14], result[15] ];}","link":"/2018/07/13/%E8%A7%A3%E5%86%B3Unacceptable-Content-Type/"},{"title":"Terminologies in Programatic Advertising","text":"Terminologies in Programatic Advertising在做一些商业化相关的项目时，经常听到其他部门的同事讲一些程序化广告方面的术语，让人一头雾水。这篇博客就来整理一下常见的术语和它们的含义，这样以后就能愉快的和别人交(zhuang)流(bi)啦😊 术语解析 ARPU Average Revenue Per User，每用户平均收入。指一段时间内，平均每个活跃用户为应用创造的收入。如果按天计算的话，又被称为 ARPUDAU。 ARPU = 总收益 / 活跃用户数。 ARPPU Average Revenue Per Paying User，每付费用户平均收益。 和 ARPU 的区别只在于分母改为了付费用户数。 ARPU = ARPPU * 付费用户比例。 累计 ARPU 以一段时间为单位，如 1 天、7 天、14 天等，用户对应用累计产生的收益。比如，1 号下载游戏的 100 名用户，在接下来的 30 天内，平均每人对游戏带来了多少收入。 累计 ARPU 会是一个逐渐增长的曲线。 LT Life Time，生命周期。用户从第一次到最后一次参与使用 App 的总时长。一般按月计算平均值。 LTV Life Time Value，客户终生价值。是公司从用户所有的活动中，所收到全部经济效益的总和。 可以想到，累计 ARPU 会逐渐逼近 LTV，LTV 是累计 ARPU 的上界。 ROI Return On Investment，投资回报率。 CPI Cost Per Install，单次安装成本。 当累计 ARPU 逐渐增长，终于超过 CPI 的时候，就代表着花钱买的量开始盈利了。从此 ROI &gt; 1。 CPM Cost Per Mille，千次展示成本。Mille is Latin for “thousands”。广告展示 1000 次所支付的金额。广告在用户面前完整播放一次，即为一次展示。 CPM = （成本 / 总展示量）* 1000 eCPM Effective Cost Per Mille，虽然字面意思是“有效的千次展示成本”，但实际意思是 1000 次展示可获得的收入。 CPM 是广告主说的，而 eCPM 是媒体说的。例如，可口可乐在抖音上投广告，CPM 是指可口可乐买这个广告位花了多少钱，eCPM 是抖音跟可口可乐说，你在我这展示广告能挣多少钱。 eCPM 反映了流量的价值，用于评估广告的收益能力。 CPA Cost Per Action，用户每次行为成本。 按用户每次行为计价，比如安装、下载、加入购物车等。 RTB Real Time Bidding，实时竞价，也叫 Open Auction，公开竞价。 在用户发起网络请求到网页被展示出来的几毫秒中，对广告位置进行实时拍卖。出价高者可以获得广告位。 DSP Demand-Side Platform，需求方平台。为需求方提供实时竞价的投放平台。 广告主可以在 DSP 上管理预算、出价、定向条件等。 ADN Ad Network，广告网盟。可以理解为媒体代理公司，为广告主采购媒体方流量。 中间商赚差价～ SSP Supply-Side Platform，供应方平台。 服务于媒体方。 DNU Daily New Users，每日新用户。 Header Bidding 头部竞价，也叫 Pre-Bidding 或 Advance Bidding。 发布方可以优先把竞价机会发送给多个合作伙伴（买方）。 PDB Private Direct Buy，私有直接购买。 流量需求方用确定的价格买断固定、优质的媒体资源，然后进行程序化广告的精准定向投放。这是国内比较主流的私有交易方式。 CTR Click Through Rate，广告点击率。 CTR = (Click / Impression) * 100% CVR Click Value Rate，点击转化率。 广告转化次数的占比。可以是注册数、订单数等。 TA Target Audience ，目标受众。 Viewability 广告可视度。 有的广告位置比较偏僻，如果用户不滚动页面，广告就无法进入其视野。而按照曝光计价的广告，不管用户是否实际看到广告，都会被计入曝光。可视度指广告出现在可见区域的曝光量，占总曝光量的比例。 Bounce Rate 跳出率，指只浏览了落地页（Landing Page）就离开的比例。 APA Active Payment Account，活跃付费用户数。","link":"/2020/02/22/terms-in-programatic-ad/"},{"title":"调试JSCore小技巧","text":"调试 JSCore 小技巧在编写 iOS 和 JavaScript 交互的代码时，调试起来实在令人头大。但其实有一个小技巧可以帮助我们调试： 打开 Safari，点击“开发”选项。如果没有顶部菜单栏没有开发选项，则先去“偏好设置”，“高级”中打开“显示开发菜单”。 选择“模拟器”，点击“自动显示 JSContext 的网页检查器”。 重新运行程序，检查器就会自动弹出来了。 苹果爸爸太给力了！！","link":"/2019/02/10/%E8%B0%83%E8%AF%95JSCore%E5%B0%8F%E6%8A%80%E5%B7%A7/"},{"title":"设计模式-创建型模式","text":"设计模式-创建型模式对象模版模式对象模版模式是最简单的一种设计模式，即使用类和结构体创建对象，而不是使用零散的变量、变量数组或元组来保存信息。使用对象模版模式可以将数据与操作数据的方法封装在一起，从而隐藏接口的内部实现，松散耦合。 原型模式原型模式是指用已有的对象作为原型，通过克隆的方式来创建新的对象，而不是通过初始化函数。这样可以将创建对象的代码隐藏，无需知道创建新的对象需要用到哪些类或结构体。当初始化的开销很大，或是想要降低对模版的依赖时，就可以使用此模式。 当使用值类型时，Swift 会自动使用原型模式。而当我们使用引用类型时，就需要让类继承 NSObject 并遵循 NSCopying 协议，实现其中的 copyWithZone 方法来定义如何复制对象。需要注意在复制对象时使用深拷贝还是浅拷贝。 单例模式单例模式可以确保某个类型的对象在应用程序中只出现一个实例。单例模式的实现与所使用的语言密切相关。 在 Swift 中，可以使用全局常量来实现单例模式： 12345678//Logger.swiftlet globalLogger = Logger()final class Logger { fileprivate init() { //required to stop instances being created by code in other files. } //...} Swift 的全局常量是惰性初始化的，且能保证线程安全。只有在第一次访问全局常量时才会初始化，且只初始化一次。即使在另外的线程中读取，也只会创建一个实例。 我们使用 final 关键字来修饰类，来防止子类的创建。把 init 函数前面加上 fileprivate 来阻止 Logger.swift 以外的地方的代码来创建实例。通过 let 关键字来声明对象，可以防止引用的指向被修改。这样就实现了一个单例。 当然还有更简单的实现方法： 1234final class Logger { static let sharedLogger = Logger() private init() {}} Cocoa 中许多地方都使用了单例模式，比如 UIApplication 的 sharedApplication。 对象池模式对象池模式是单例模式的一种变体，不同的是它提供了多个完全相同的对象，而非单个对象。使用时应该从对象池中取出对象，使用它完成任务后再归还给对象池。在归还以前，其他组件将不能使用它。 举例来说明，图书馆中绝大多数书都不止一本，但是范围又是有限定的。创建或复制 Book 对象并不能使图书馆的藏书量真的增多，这个时候就应该使用对象池来管理图书。 123456789101112131415161718192021class Pool&lt;T&gt; { private var data = [T]() init(items: [T]) { for eachItem in items { data.append(eachItem) } } func getFromPool() -&gt; T? { var result: T? if data.count &gt; 0 { result = data.removeAtIndex(0) } return result } func returnToPool(item: T) { data.append(item) }} 我们维护了一个队列来管理对象池。需要注意的是，如果程序中使用了多线程，则需要做好数据的保护。 Cocoa 中，UITableView 维护了一个 UITableViewCell 的对象池来节省内存开销。 工厂方法模式当多个类遵循同一个协议，或是继承自同一个基类，而我们需要根据条件选择一个类来初始化对象时，就可以使用工厂方法模式。工厂方法模式同意了实现类的选取逻辑，从而避免了相关逻辑散布在整个程序中，调用组件无需了解实现类即选取实现类的过程。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//RentalCar.swiftclass RentalCar { fileprivate var name = &quot;&quot; fileprivate var passengers = 0 fileprivate init(name: String, passengers: Int) { self.name = name self.passengers = passengers } final var name: String { get { return name } } final var passengers: Int { get { return passengers } } class func createRentalCar(passengers: Int) -&gt; RentalCar? { var car: RentalCar? switch passengers { case 0...3: car = Compact() case 4...8: car = SUV() default: car = nil } return car }}class Compact: RentalCar { fileprivate init() { super.init(name: &quot;Golf&quot;, passengers: 3) }}class SUV: RentalCar { fileprivate init() { super.init(name: &quot;Range Rover&quot;, passengers: 8) }}//CarSelector.swiftclass CarSelector { class func selectCar(passengers: Int) -&gt; String? { return RentalCar.createRentalCar(passengers)?.name }} 抽象工厂模式当调用组件需要一组互相协作的对象，又不需要关心这些对象的具体协作方式时，就可以使用抽象工厂模式。 当调用抽象工厂去创建对象时，抽象工厂会检查请求，然后选择一个具体工厂，使用具体工厂创建对象并返回给调用组件。 建造者模式建造者模式用于分离对象的创建和配置。调用组件负责提供配置对象的数据，把数据传给中间人建造者，建造者再去创建对象。这样调用者就无需过多掌握其使用的对象的信息，而默认配置可以集中放置在建造者中。如果创建对象需要进行复杂的配置，就可以使用这种模式。 12345678910111213141516171819202122232425262728293031323334353637383940class Burger { let pickles: Bool //泡菜 let mayo: Bool //蛋黄酱 let lettuce: Bool //生菜 let ketchup: Bool init(pickles: Bool, mayo: Bool, lettuce: Bool, ketchup: Bool) { self.pickles = pickles self.mayo = mayo self.lettuce = lettuce self.ketchup = ketchup }}class BurgerBuilder { private var pickles = false private var mayo = false private var lettuce = true private var ketchup = true func setPickles(choice: Bool) { self.pickles = choice } func setMayo(choice: Bool) { self.mayo = choice } func setLettuce(choice: Bool) { self.lettuce = choice } func setKetchup(choice: Bool) { self.ketchup = choice } func buildBurger() -&gt; Burger { return Burget(pickles: picklse, mayo: mayo, lettuce: lettuce, ketchup: ketchup) }}","link":"/2018/05/16/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"},{"title":"阿里一面凉了之旅","text":"阿里一面凉了之旅昨天才投的阿里巴巴，要我做的测评和在线编程题还没做，今天居然就打电话来面试了！真是猝不及防。在听我bb了半天项目经验，又问了点其他的 iOS 知识之后，面试官说：“我们来考察一下编程的思想吧！”。我说：“来吧！”，然后，然后我就跪了。。。 事情是这样的面试官：“这道题很常见，你之前也可能听说过。” 我：“嗯，您说。” 面试官：“给你 1、2、5 三种面值的硬币，凑成 10，一共有多少种组合？” 我：“嗯。。。。我之前没听说过。。。。。让我想一下。。。。” 于是我在脑海中抽象了一下题目描述： 现有面值分别为 $v_i$ 的 N 种硬币，需要凑成 V 元，每种硬币使用次数不限，求一共有多少种凑法？ 我：“嗯。。。。最直观的想法就是暴力求解。。。” 面试官：“怎么暴力求解呢？” 我：“嗯。。。。估计要用到递归。。。”（内心OS：这样复杂度好高啊） 面试官：“怎么递归呢？” 我：“嗯。。。。每种硬币加加加，然后超过范围就退回到上一种状态。。。然后尝试下一种”（内心OS：复杂度好高！估计要用动态规划来优化下，咋搞呢） 面试官：“能说一下代码会有哪些结构吗？” 我：“*……&amp;*@!@#)(&amp;&amp;)”（我也不知道我瞎说了些啥，反正答得很烂） 再又聊了一点点别的东西之后， 面试官：“好的，我会如实反映这次面试的情况。应该会在一周之内联系你，如果两周都没有联系你，那就不用再等了。” 我（带着哭腔）：“好的我清楚了T^T” 挂掉电话之后卧槽！这不就是一个动态规划吗！我咋这都没想出来！让我写一下代码！ 思路： 我们需要数组 T[i][j] 表示用前 i 种硬币凑出 j 元时所有的组合数。 逐步增加 j 至 V，计算 T[i][j] 的规则如下： 遍历第 i 种硬币使用的个数，从 0（不使用）到不超过 V 的个数，记录为 k。当前硬币面值记为 v。 ​ T[i][j] += T[i-1][j-k*v] 也就是我们考虑第 i 种硬币使用 1 个、2 个、3 个的情况，每种情况的组合数分别对应不使用这种硬币时，减去这种硬币当前凑出的面值的组合数，做一个累加就可以了。 Java实现： 123456789101112131415161718192021222324252627public class Main { public static void main(String[] args) throws Exception { int[] C = {1,2,5}; System.out.println(getTotoalCombinationCount(C, 10)); } static int getTotoalCombinationCount(int[] C, int value) { int T[][] = new int[C.length+1][value+1]; for(int i=0; i&lt;=C.length; i++) { for(int j=0; j&lt;=value; j++) { if(j==0) { T[i][j] = 1; } else { T[i][j] = 0; } } } for(int i=1; i&lt;=C.length; i++) { for(int j=1; j&lt;=value; j++) { int v = C[i-1]; for(int k=0; k*v &lt;= j; k++) { T[i][j] += T[i - 1][j - k*v]; } } } return T[C.length][value]; }} 需要注意的是，我们需要给二维数组 T 一个合适的初始值。当 j == 0 时，也就是需要凑成 0 元钱的时候，无论硬币有多少种，我们都有 1 种凑法：那就是不用凑。 从这个故事我们学到了这道题确实很简单，而且又是我刚刚才学过的动态规划法。事实上我挂掉电话后用了不到半个小时就写出来了。也许是刚学过动态规划还不太熟练、也许是面试时太紧张、也许是面试过程中大脑傻掉了，反正答的很不好，还是自己太菜啊！面试官特意说两个星期内没收到后续结果就是凉了，估计是在暗示我真的凉了吧。。。我自己是感觉凉了。。 痛定思痛吧！继续努力！为找到实习而奋斗！ 如果万一没凉……虽然概率趋近于 0，但如果万一我没凉，还收到了后续面试的通知的话……我就用阿里的支付宝给贫困山区的小朋友捐 10 块钱辣条钱！ 4.7 Update: 震惊！居然没凉！已捐款10元。","link":"/2018/03/27/%E9%98%BF%E9%87%8C%E4%B8%80%E9%9D%A2%E5%87%89%E4%BA%86%E4%B9%8B%E6%97%85/"}],"tags":[{"name":"OKR","slug":"OKR","link":"/tags/OKR/"},{"name":"AFNetworking","slug":"AFNetworking","link":"/tags/AFNetworking/"},{"name":"JSCore","slug":"JSCore","link":"/tags/JSCore/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"Flutter","slug":"Flutter","link":"/tags/Flutter/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"C/C++","slug":"C-C","link":"/tags/C-C/"},{"name":"perf","slug":"perf","link":"/tags/perf/"},{"name":"Computer Organization","slug":"Computer-Organization","link":"/tags/Computer-Organization/"},{"name":"Obj-C","slug":"Obj-C","link":"/tags/Obj-C/"},{"name":"RaspberryPi","slug":"RaspberryPi","link":"/tags/RaspberryPi/"},{"name":"SQLite","slug":"SQLite","link":"/tags/SQLite/"},{"name":"RunLoop","slug":"RunLoop","link":"/tags/RunLoop/"},{"name":"Swift","slug":"Swift","link":"/tags/Swift/"},{"name":"Promise","slug":"Promise","link":"/tags/Promise/"},{"name":"MultiThreading","slug":"MultiThreading","link":"/tags/MultiThreading/"},{"name":"Robotics","slug":"Robotics","link":"/tags/Robotics/"},{"name":"SLAM","slug":"SLAM","link":"/tags/SLAM/"},{"name":"Probability","slug":"Probability","link":"/tags/Probability/"},{"name":"network","slug":"network","link":"/tags/network/"},{"name":"Operating System","slug":"Operating-System","link":"/tags/Operating-System/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"iOS","slug":"iOS","link":"/tags/iOS/"},{"name":"Design Patterns","slug":"Design-Patterns","link":"/tags/Design-Patterns/"},{"name":"ffmpeg","slug":"ffmpeg","link":"/tags/ffmpeg/"},{"name":"DSP","slug":"DSP","link":"/tags/DSP/"},{"name":"First-Aid","slug":"First-Aid","link":"/tags/First-Aid/"},{"name":"Kibana","slug":"Kibana","link":"/tags/Kibana/"},{"name":"SDR","slug":"SDR","link":"/tags/SDR/"},{"name":"X11","slug":"X11","link":"/tags/X11/"},{"name":"Front End","slug":"Front-End","link":"/tags/Front-End/"},{"name":"LLVM","slug":"LLVM","link":"/tags/LLVM/"},{"name":"Computer Vision","slug":"Computer-Vision","link":"/tags/Computer-Vision/"},{"name":"Code Coverage","slug":"Code-Coverage","link":"/tags/Code-Coverage/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"WebGL","slug":"WebGL","link":"/tags/WebGL/"},{"name":"Computer Graphics","slug":"Computer-Graphics","link":"/tags/Computer-Graphics/"},{"name":"Layout","slug":"Layout","link":"/tags/Layout/"},{"name":"UITableView","slug":"UITableView","link":"/tags/UITableView/"},{"name":"CoreAnimation","slug":"CoreAnimation","link":"/tags/CoreAnimation/"},{"name":"CoreBluetooth","slug":"CoreBluetooth","link":"/tags/CoreBluetooth/"},{"name":"AutoLayout","slug":"AutoLayout","link":"/tags/AutoLayout/"},{"name":"misc","slug":"misc","link":"/tags/misc/"},{"name":"Animation","slug":"Animation","link":"/tags/Animation/"},{"name":"Gesture","slug":"Gesture","link":"/tags/Gesture/"},{"name":"Push","slug":"Push","link":"/tags/Push/"},{"name":"CocoaPods","slug":"CocoaPods","link":"/tags/CocoaPods/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"macOS","slug":"macOS","link":"/tags/macOS/"},{"name":"Point Cloud","slug":"Point-Cloud","link":"/tags/Point-Cloud/"},{"name":"PyTorch","slug":"PyTorch","link":"/tags/PyTorch/"},{"name":"CNN","slug":"CNN","link":"/tags/CNN/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"OpenCV","slug":"OpenCV","link":"/tags/OpenCV/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"PlutoSDR","slug":"PlutoSDR","link":"/tags/PlutoSDR/"},{"name":"dyld","slug":"dyld","link":"/tags/dyld/"},{"name":"gem5","slug":"gem5","link":"/tags/gem5/"},{"name":"Instruments","slug":"Instruments","link":"/tags/Instruments/"},{"name":"Xcode","slug":"Xcode","link":"/tags/Xcode/"},{"name":"AD","slug":"AD","link":"/tags/AD/"},{"name":"Interview","slug":"Interview","link":"/tags/Interview/"}],"categories":[]}